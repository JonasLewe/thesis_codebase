{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f7e818",
   "metadata": {},
   "source": [
    "## This notebook is currently used for saving best models based on their IoU performance on the segmented validation and test data (22.03.22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5081fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix seeds for random numbers first!\n",
    "\n",
    "seed_value=1\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "# for later versions: \n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from tensorflow.keras import backend as K\n",
    "#session_conf = tensorflow.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "#sess = tensorflow.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "#K.set_session(sess)\n",
    "# for later versions:\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb76ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import PIL\n",
    "import numpy as np\n",
    "from PIL import ImageOps, ImageDraw, ImageFont\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from collections import Counter\n",
    "from skimage.transform import resize\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, jaccard_score, f1_score, make_scorer, confusion_matrix, accuracy_score, precision_score, recall_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cfbdda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow imports\n",
    "import mltb.keras\n",
    "from numba import cuda\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.models import load_model, Model, Sequential\n",
    "from tensorflow.keras.layers import Dropout, Conv2D, MaxPooling2D, GlobalMaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.applications import VGG19, VGG16, ResNet50, EfficientNetB7\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb5294",
   "metadata": {},
   "source": [
    "## Define Callbacks and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f31fc79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./saved_models'):\n",
    "    os.makedirs('./saved_models')\n",
    "if not os.path.exists('./saved_models/checkpoints'):\n",
    "    os.makedirs('./saved_models/checkpoints')\n",
    "# Callback Definition\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint('./saved_models/checkpoints/base_model.h5',\n",
    "                                                 monitor='val_loss', \n",
    "                                                 mode='auto', verbose=2,\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=True)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./saved_models/logs', profile_batch=0)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "886e2279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcAndLogF1Score(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, valid_data_generator):\n",
    "        super(CalcAndLogF1Score, self).__init__()\n",
    "        self.validation_data = valid_data_generator\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_steps_per_epoch = np.math.ceil(self.validation_data.samples / self.validation_data.batch_size)\n",
    "        \n",
    "        predict = self.model.predict(self.validation_data, steps=val_steps_per_epoch)\n",
    "        val_predict = [1 * (x[0]>=0.5) for x in predict]\n",
    "        \n",
    "        val_targ = self.validation_data.classes\n",
    "\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='macro')\n",
    "        _val_recall = recall_score(val_targ, val_predict, average='macro')\n",
    "        _val_precision = precision_score(val_targ, val_predict, average='macro')\n",
    "\n",
    "        logs['val_f1'] = _val_f1\n",
    "        logs['val_recall'] = _val_recall\n",
    "        logs['val_precision'] = _val_precision\n",
    "        print(f\" — val_f1: {_val_f1:.4f} — val_precision: {_val_precision:.4f} — val_recall: {_val_recall:.4f}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eb00cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaccardScoreCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Computes the Jaccard score and logs the results to TensorBoard.\"\"\"\n",
    "\n",
    "    def __init__(self, model, valid_data_generator, log_dir):\n",
    "        self.model = model\n",
    "        self.validation_data = valid_data_generator\n",
    "        self.keras_metric = tf.keras.metrics.Mean(\"jaccard_score\")\n",
    "        self.epoch = 0\n",
    "        self.summary_writer = tf.summary.create_file_writer(os.path.join(log_dir, model.name))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs=None):\n",
    "        self.epoch += 1\n",
    "        self.keras_metric.reset_states()\n",
    "        \n",
    "        val_steps_per_epoch = np.math.ceil(self.validation_data.samples/self.validation_data.batch_size)\n",
    "        \n",
    "        predict = self.model.predict(self.validation_data, steps=val_steps_per_epoch)\n",
    "        val_predict = [1 * (x[0]>=0.5) for x in predict]\n",
    "        \n",
    "        val_targ = self.validation_data.classes\n",
    "        \n",
    "        jaccard_value = jaccard_score(val_predict, val_targ, average=None)\n",
    "        self.keras_metric.update_state(jaccard_value)\n",
    "        self._write_metric(self.keras_metric.name, self.keras_metric.result().numpy().astype(float))\n",
    "\n",
    "    def _write_metric(self, name, value):\n",
    "        with self.summary_writer.as_default():\n",
    "            tf.summary.scalar(name, value, step=self.epoch,)\n",
    "            self.summary_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "410db04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1_Metric(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model, valid_data_generator, filepath='./saved_models'):\n",
    "        self.model = model\n",
    "        self.validation_data = valid_data_generator\n",
    "        self.file_path = filepath\n",
    "                \n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "        \n",
    "        # check if model already exists\n",
    "        for fname in os.listdir(self.file_path):\n",
    "            if fname.endswith('.h5'):\n",
    "                self.best_val_f1 = float(fname.split('_')[-2])\n",
    "                print(f\"Previous f1_score: {self.best_val_f1}\")\n",
    "            else:\n",
    "                self.best_val_f1 = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_steps_per_epoch = np.math.ceil(self.validation_data.samples/self.validation_data.batch_size)\n",
    "        predict = self.model.predict(self.validation_data, steps=val_steps_per_epoch)\n",
    "        val_predict = [1 * (x[0]>=0.5) for x in predict]\n",
    "        val_targ = self.validation_data.classes\n",
    "        \n",
    "        _val_f1 = f1_score(val_targ, val_predict)\n",
    "        _val_recall = recall_score(val_targ, val_predict)\n",
    "        _val_precision = precision_score(val_targ, val_predict)\n",
    "        \n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print(f\"_val_f1: {_val_f1:.4f}, _val_precision: {_val_precision:.4f}, _val_recall: {_val_recall:.4f}\")\n",
    "        print(f\"max f1: {max(self.val_f1s):.4f}\")\n",
    "        if _val_f1 > self.best_val_f1:\n",
    "            \n",
    "            # check if model already exists\n",
    "            for fname in os.listdir(self.file_path):\n",
    "                if fname.endswith('.h5'):\n",
    "                    if (_val_f1 > float(fname.split('_')[-2])):\n",
    "                        os.remove(f\"{self.file_path}/{fname}\")\n",
    "                        self.model.save(f\"{self.file_path}/base_model_{_val_f1:.4f}_.h5\", overwrite=True)\n",
    "            \n",
    "            self.best_val_f1 = _val_f1\n",
    "            print(f\"best f1: {self.best_val_f1:.4f}\")\n",
    "        else:\n",
    "            print(f\"val f1: {_val_f1:.4f}, but not the best f1\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "393183bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "056fceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_gpu_mem():# clear GPU memory\n",
    "    K.clear_session()\n",
    "    #cuda.select_device(0)\n",
    "    #cuda.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a1e7f7",
   "metadata": {},
   "source": [
    "## Define Grad-CAM methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdb24cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path, show=True):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img_tensor[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor # np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69fa3859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 224x224\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (224, 224, 3)\n",
    "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 224, 224, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de3d653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10cf758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_superimposed_gradcam_img(img, heatmap, cam_path=\"cam.jpg\", alpha=0.8):\n",
    "    # Load the original image\n",
    "    #img = keras.preprocessing.image.load_img(img_path)\n",
    "    img = img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = array_to_img(superimposed_img)\n",
    "    \n",
    "    # Save the superimposed image\n",
    "    # superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    #display(Image(cam_path))\n",
    "    #show(superimposed_img)\n",
    "    \n",
    "    return superimposed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13ea92ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_display(display, text, src_img, superimposed_img, img_name, preds):\n",
    "    text = f'IMG_NAME: {img_name}\\nPrediction: {preds}'\n",
    "    images = [src_img, superimposed_img]\n",
    "    \n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "    \n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    new_img = PIL.Image.new('RGB', (total_width, max_height))\n",
    "    \n",
    "    x_offset = 0\n",
    "    for im in images:\n",
    "        new_img.paste(im, (x_offset,0))\n",
    "        x_offset += im.size[0]\n",
    "    new_img = ImageOps.expand(new_img, border=50, fill=(255,255,255))\n",
    "    new_img = new_img.resize(tuple(i*2 for i in new_img.size), resample=PIL.Image.BOX)\n",
    "    draw = ImageDraw.Draw(new_img)\n",
    "    font = ImageFont.truetype(\"FONTS/arial.ttf\", 40)\n",
    "    if text:\n",
    "        draw.text((10,0),text,(0,0,0),font=font)\n",
    "    if display:\n",
    "        show_img(new_img)\n",
    "    new_img.save(f'./cam_images/{img_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ddb0d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_pipeline(ROOT_DIR, img_name, json_img, IMAGE_SIZE, model_loaded, last_conv_layer_name, display=True, text=True):\n",
    "    img_path = os.path.join(ROOT_DIR, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, IMAGE_SIZE)\n",
    "    img = PIL.Image.fromarray(img)\n",
    "    \n",
    "    # Prepare image for class prediction\n",
    "    img_array = get_img_array(img_path, size=IMAGE_SIZE)\n",
    "    # Remove last layer's softmax\n",
    "    model_loaded.layers[-1].activation = None\n",
    "    \n",
    "    # Print what the top predicted class is\n",
    "    \n",
    "    new_image = load_image(img_path, show=False)\n",
    "\n",
    "    # check prediction\n",
    "    # pred = model.predict(new_image)\n",
    "    preds = model_loaded.predict(new_image)\n",
    "    #print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
    "    \n",
    "    # Generate class activation heatmap\n",
    "    heatmap = generate_gradcam_heatmap(img_array, model_loaded, last_conv_layer_name)\n",
    "    \n",
    "    if display:\n",
    "        superimposed_img = get_superimposed_gradcam_img(img, heatmap)\n",
    "        json_img = json_img.resize(IMAGE_SIZE, PIL.Image.ANTIALIAS)\n",
    "        cam_display(display, text, json_img, superimposed_img, img_name, preds)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c413b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_and_draw(ROOT_DIR, img_name, IMAGE_SIZE):\n",
    "    img_path = os.path.join(ROOT_DIR, img_name)\n",
    "    # print(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # img = cv2.resize(img, IMAGE_SIZE)\n",
    "    img = PIL.Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    return img, draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9be7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_img_name(json_file_name):\n",
    "    if ('_OLV' not in json_file_name):\n",
    "        img_name = f\"{json_file_name.split('.')[0]}_OLV.jpg\"\n",
    "    else:\n",
    "        img_name = f\"{json_file_name.split('.')[0]}.jpg\"\n",
    "    return img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7593323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_json_polygons(img_name, json_file_name, ROOT_DIR, IMAGE_SIZE):    \n",
    "    img, draw = get_img_and_draw(ROOT_DIR, img_name, IMAGE_SIZE)\n",
    "    \n",
    "    # Opening JSON file\n",
    "    json_path = os.path.join(JSON_DIR, json_file_name)\n",
    "    with open(json_path) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "\n",
    "    # iterate over all olivine polygons\n",
    "    num_of_polygons = len(json_data['shapes'])\n",
    "    for i in range(num_of_polygons): # iterate over different olivine crystals\n",
    "        polygon_coordinates = [tuple(x) for x in json_data['shapes'][i]['points']]\n",
    "        # print(polygon_coordinates)\n",
    "        polygon_coordinates.append(polygon_coordinates[0]) # polygon needs to be closed\n",
    "        for j in range(len(polygon_coordinates)-1): # iterate over coordinates of single crystal\n",
    "            draw.line(polygon_coordinates[j] + polygon_coordinates[j+1], fill='red', width=3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19c02c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iou_score(y_true, y_pred):\n",
    "    intersection = np.logical_and(y_true, y_pred)\n",
    "    union = np.logical_or(y_true, y_pred)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    #print(f\"IoU score: {iou_score:.2f}\")\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2cdf77",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed04457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define basic cnn model\n",
    "def define_base_model_legacy(learn_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(224, 224, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', name='last_conv_layer'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # compile model\n",
    "    # opt = SGD(lr=0.001, momentum=0.9)\n",
    "    opt = Adam(learning_rate=learn_rate)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "617fd42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define basic cnn model\n",
    "def define_base_model(learn_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(224, 224, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', name='last_conv_layer'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # compile model\n",
    "    # opt = SGD(lr=0.001, momentum=0.9)\n",
    "    opt = Adam(learning_rate=learn_rate)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[METRICS])#metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0be0067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_vanilla_vgg_model(image_shape=(224, 224, 3), index=22):\n",
    "    # load model\n",
    "    model = VGG16(include_top=False, input_shape=image_shape)\n",
    "    # mark loaded layers as not trainable\n",
    "    for layer in model.layers:#[:index]:\n",
    "        layer.trainable = False\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    output = Dense(1, activation='sigmoid')(class1)\n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    # compile model\n",
    "    #opt = SGD(lr=0.001, momentum=0.9)\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b6d0349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_vgg_model(image_shape=(224, 224, 3), index=22):\n",
    "    base_model = VGG19(include_top=False, weights='imagenet', input_shape=image_shape)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    # base_model.trainable = False # freeze layers from pretrained model\n",
    "\n",
    "    model = Sequential()\n",
    "    #model = Model(inputs=base_model.input, outputs=base_model.layers[-1].output) # copy all layers from base_model\n",
    "    model.add(Rescaling(1./255,input_shape = image_shape))\n",
    "    for layer in base_model.layers[1:-1]: # loop through convolution layers\n",
    "        model.add(layer)\n",
    "    model.add(base_model.get_layer('block5_pool')) # add final maxpooling2D layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,activation=('relu'))) \n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(128,activation=('relu')))\n",
    "    model.add(Dropout(.2))\n",
    "    \n",
    "    # Final layer\n",
    "    model.add(Dense(1,activation=('sigmoid'),name=\"activation_1\"))\n",
    "    \n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f1e7a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness(model_name='base', epochs=50, batch_size=32, index=22, verbose=1):\n",
    "    # define model\n",
    "    if model_name == 'base':\n",
    "        model = define_base_model()\n",
    "    elif model_name == 'vgg':\n",
    "        model = define_vanilla_vgg_model()\n",
    "    \n",
    "    # create data generators\n",
    "    train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
    "                                       #rotation_range=40,\n",
    "                                       #width_shift_range=0.2,\n",
    "                                       #height_shift_range=0.2,\n",
    "                                       #shear_range=0.2,\n",
    "                                       #zoom_range=0.2,\n",
    "                                       #brightness_range=[0.1,1],\n",
    "                                       #horizontal_flip=True,\n",
    "                                       #fill_mode='nearest'\n",
    "                                      )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    \n",
    "    # prepare iterators\n",
    "    train_generator = train_datagen.flow_from_directory('thin_section_dataset/train/',\n",
    "                                                 class_mode='binary',\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 target_size=(224, 224))\n",
    "    \n",
    "    val_generator = val_datagen.flow_from_directory('thin_section_dataset/validation/',\n",
    "                                               class_mode='binary', \n",
    "                                               color_mode='rgb',\n",
    "                                               batch_size=batch_size, \n",
    "                                               target_size=(224, 224))\n",
    "    \n",
    "    # calculate class weights\n",
    "    counter = Counter(train_generator.classes)\n",
    "    max_val = float(max(counter.values()))\n",
    "    class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}\n",
    "    \n",
    "    ### Debug info ###\n",
    "    print(f\"\\nClasses: {train_generator.class_indices}\")\n",
    "    print(f\"Class Weights: {class_weights}\")\n",
    "    print(f\"Class Distribution: {dict(counter)}\\n\")\n",
    "    # fit model\n",
    "    history = model.fit(train_generator, \n",
    "                        steps_per_epoch=len(train_generator), \n",
    "                        validation_data=val_generator, \n",
    "                        validation_steps=len(val_generator),\n",
    "                        class_weight=class_weights,\n",
    "                        epochs=epochs, \n",
    "                        verbose=verbose,\n",
    "                        callbacks=[\n",
    "                            #F1_Metric(model, val_generator),\n",
    "                            #JaccardScoreCallback(model, val_generator, './saved_models/logs'),\n",
    "                            #mltb.keras.BinaryClassifierMetricsCallback(val_generator, val_generator.classes, 1),\n",
    "                            #CalcAndLogF1Score(valid_data_generator=val_generator),\n",
    "                            #early_stopping,\n",
    "                            tensorboard_callback,\n",
    "                        ])\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca61df74",
   "metadata": {},
   "source": [
    "## Train Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2cf4da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_DIR = \"./olivine_polygon_label_files/\"\n",
    "ROOT_DIR = \"./Olivine_Images/\"\n",
    "IMAGE_SIZE = (224,224)\n",
    "json_files = os.listdir(JSON_DIR)\n",
    "true_label_folder = \"./data_dataset_voc/SegmentationClass\"\n",
    "saved_model_path = './saved_models/best_iou'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "516e6d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 5s 302ms/step - loss: 22.1160 - tp: 70.0000 - fp: 201.0000 - tn: 162.0000 - fn: 50.0000 - accuracy: 0.4803 - precision: 0.2583 - recall: 0.5833 - auc: 0.5352 - val_loss: 0.6972 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.5313\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 1.0508 - tp: 91.0000 - fp: 264.0000 - tn: 99.0000 - fn: 29.0000 - accuracy: 0.3934 - precision: 0.2563 - recall: 0.7583 - auc: 0.5178 - val_loss: 0.7182 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.5656\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 1.0313 - tp: 90.0000 - fp: 246.0000 - tn: 117.0000 - fn: 30.0000 - accuracy: 0.4286 - precision: 0.2679 - recall: 0.7500 - auc: 0.6020 - val_loss: 0.5975 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6572\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 1.0523 - tp: 56.0000 - fp: 111.0000 - tn: 252.0000 - fn: 64.0000 - accuracy: 0.6377 - precision: 0.3353 - recall: 0.4667 - auc: 0.5795 - val_loss: 0.7113 - val_tp: 25.0000 - val_fp: 77.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2524 - val_precision: 0.2451 - val_recall: 1.0000 - val_auc: 0.6092\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 1.0341 - tp: 95.0000 - fp: 260.0000 - tn: 103.0000 - fn: 25.0000 - accuracy: 0.4099 - precision: 0.2676 - recall: 0.7917 - auc: 0.5749 - val_loss: 0.6737 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6262\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 1.0954 - tp: 58.0000 - fp: 165.0000 - tn: 198.0000 - fn: 62.0000 - accuracy: 0.5300 - precision: 0.2601 - recall: 0.4833 - auc: 0.5211 - val_loss: 0.6972 - val_tp: 25.0000 - val_fp: 68.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3398 - val_precision: 0.2688 - val_recall: 1.0000 - val_auc: 0.6400\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 1.0147 - tp: 97.0000 - fp: 230.0000 - tn: 133.0000 - fn: 23.0000 - accuracy: 0.4762 - precision: 0.2966 - recall: 0.8083 - auc: 0.6319 - val_loss: 0.7191 - val_tp: 23.0000 - val_fp: 64.0000 - val_tn: 14.0000 - val_fn: 2.0000 - val_accuracy: 0.3592 - val_precision: 0.2644 - val_recall: 0.9200 - val_auc: 0.7090\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 1.0258 - tp: 70.0000 - fp: 170.0000 - tn: 193.0000 - fn: 50.0000 - accuracy: 0.5445 - precision: 0.2917 - recall: 0.5833 - auc: 0.5900 - val_loss: 0.6877 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.7182\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 1.0012 - tp: 98.0000 - fp: 201.0000 - tn: 162.0000 - fn: 22.0000 - accuracy: 0.5383 - precision: 0.3278 - recall: 0.8167 - auc: 0.6503 - val_loss: 0.6143 - val_tp: 18.0000 - val_fp: 36.0000 - val_tn: 42.0000 - val_fn: 7.0000 - val_accuracy: 0.5825 - val_precision: 0.3333 - val_recall: 0.7200 - val_auc: 0.7079\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 1.0257 - tp: 100.0000 - fp: 216.0000 - tn: 147.0000 - fn: 20.0000 - accuracy: 0.5114 - precision: 0.3165 - recall: 0.8333 - auc: 0.6362 - val_loss: 0.6984 - val_tp: 23.0000 - val_fp: 63.0000 - val_tn: 15.0000 - val_fn: 2.0000 - val_accuracy: 0.3689 - val_precision: 0.2674 - val_recall: 0.9200 - val_auc: 0.6803\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 1.0368 - tp: 43.0000 - fp: 101.0000 - tn: 262.0000 - fn: 77.0000 - accuracy: 0.6315 - precision: 0.2986 - recall: 0.3583 - auc: 0.5623 - val_loss: 0.6927 - val_tp: 20.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 5.0000 - val_accuracy: 0.4175 - val_precision: 0.2667 - val_recall: 0.8000 - val_auc: 0.7172\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.9968 - tp: 96.0000 - fp: 203.0000 - tn: 160.0000 - fn: 24.0000 - accuracy: 0.5300 - precision: 0.3211 - recall: 0.8000 - auc: 0.6569 - val_loss: 0.6850 - val_tp: 20.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 5.0000 - val_accuracy: 0.4563 - val_precision: 0.2817 - val_recall: 0.8000 - val_auc: 0.7095\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9953 - tp: 78.0000 - fp: 137.0000 - tn: 226.0000 - fn: 42.0000 - accuracy: 0.6294 - precision: 0.3628 - recall: 0.6500 - auc: 0.6628 - val_loss: 0.7379 - val_tp: 23.0000 - val_fp: 63.0000 - val_tn: 15.0000 - val_fn: 2.0000 - val_accuracy: 0.3689 - val_precision: 0.2674 - val_recall: 0.9200 - val_auc: 0.7449\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.9968 - tp: 52.0000 - fp: 87.0000 - tn: 276.0000 - fn: 68.0000 - accuracy: 0.6791 - precision: 0.3741 - recall: 0.4333 - auc: 0.6446 - val_loss: 0.6844 - val_tp: 22.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 3.0000 - val_accuracy: 0.5437 - val_precision: 0.3333 - val_recall: 0.8800 - val_auc: 0.7469\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.8978 - tp: 88.0000 - fp: 137.0000 - tn: 226.0000 - fn: 32.0000 - accuracy: 0.6501 - precision: 0.3911 - recall: 0.7333 - auc: 0.7393 - val_loss: 0.5925 - val_tp: 17.0000 - val_fp: 25.0000 - val_tn: 53.0000 - val_fn: 8.0000 - val_accuracy: 0.6796 - val_precision: 0.4048 - val_recall: 0.6800 - val_auc: 0.7446\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8837 - tp: 99.0000 - fp: 169.0000 - tn: 194.0000 - fn: 21.0000 - accuracy: 0.6066 - precision: 0.3694 - recall: 0.8250 - auc: 0.7383 - val_loss: 0.6467 - val_tp: 22.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 3.0000 - val_accuracy: 0.4951 - val_precision: 0.3099 - val_recall: 0.8800 - val_auc: 0.7641\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.9195 - tp: 98.0000 - fp: 188.0000 - tn: 175.0000 - fn: 22.0000 - accuracy: 0.5652 - precision: 0.3427 - recall: 0.8167 - auc: 0.7376 - val_loss: 0.6352 - val_tp: 16.0000 - val_fp: 20.0000 - val_tn: 58.0000 - val_fn: 9.0000 - val_accuracy: 0.7184 - val_precision: 0.4444 - val_recall: 0.6400 - val_auc: 0.7674\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.9242 - tp: 77.0000 - fp: 111.0000 - tn: 252.0000 - fn: 43.0000 - accuracy: 0.6812 - precision: 0.4096 - recall: 0.6417 - auc: 0.7308 - val_loss: 0.6501 - val_tp: 18.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 7.0000 - val_accuracy: 0.5534 - val_precision: 0.3158 - val_recall: 0.7200 - val_auc: 0.7721\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.8954 - tp: 86.0000 - fp: 120.0000 - tn: 243.0000 - fn: 34.0000 - accuracy: 0.6812 - precision: 0.4175 - recall: 0.7167 - auc: 0.7547 - val_loss: 0.6266 - val_tp: 20.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 5.0000 - val_accuracy: 0.5922 - val_precision: 0.3509 - val_recall: 0.8000 - val_auc: 0.7810\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.8568 - tp: 94.0000 - fp: 145.0000 - tn: 218.0000 - fn: 26.0000 - accuracy: 0.6460 - precision: 0.3933 - recall: 0.7833 - auc: 0.7714 - val_loss: 0.6292 - val_tp: 22.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 3.0000 - val_accuracy: 0.5728 - val_precision: 0.3492 - val_recall: 0.8800 - val_auc: 0.8054\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.8240 - tp: 91.0000 - fp: 128.0000 - tn: 235.0000 - fn: 29.0000 - accuracy: 0.6749 - precision: 0.4155 - recall: 0.7583 - auc: 0.7867 - val_loss: 0.6006 - val_tp: 21.0000 - val_fp: 18.0000 - val_tn: 60.0000 - val_fn: 4.0000 - val_accuracy: 0.7864 - val_precision: 0.5385 - val_recall: 0.8400 - val_auc: 0.8205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.8053 - tp: 98.0000 - fp: 119.0000 - tn: 244.0000 - fn: 22.0000 - accuracy: 0.7081 - precision: 0.4516 - recall: 0.8167 - auc: 0.8020 - val_loss: 0.6116 - val_tp: 15.0000 - val_fp: 13.0000 - val_tn: 65.0000 - val_fn: 10.0000 - val_accuracy: 0.7767 - val_precision: 0.5357 - val_recall: 0.6000 - val_auc: 0.7897\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.7700 - tp: 95.0000 - fp: 88.0000 - tn: 275.0000 - fn: 25.0000 - accuracy: 0.7660 - precision: 0.5191 - recall: 0.7917 - auc: 0.8310 - val_loss: 0.6003 - val_tp: 16.0000 - val_fp: 15.0000 - val_tn: 63.0000 - val_fn: 9.0000 - val_accuracy: 0.7670 - val_precision: 0.5161 - val_recall: 0.6400 - val_auc: 0.8097\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8068 - tp: 98.0000 - fp: 86.0000 - tn: 277.0000 - fn: 22.0000 - accuracy: 0.7764 - precision: 0.5326 - recall: 0.8167 - auc: 0.8304 - val_loss: 0.6832 - val_tp: 19.0000 - val_fp: 25.0000 - val_tn: 53.0000 - val_fn: 6.0000 - val_accuracy: 0.6990 - val_precision: 0.4318 - val_recall: 0.7600 - val_auc: 0.7831\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.7237 - tp: 98.0000 - fp: 98.0000 - tn: 265.0000 - fn: 22.0000 - accuracy: 0.7516 - precision: 0.5000 - recall: 0.8167 - auc: 0.8479 - val_loss: 0.5209 - val_tp: 20.0000 - val_fp: 15.0000 - val_tn: 63.0000 - val_fn: 5.0000 - val_accuracy: 0.8058 - val_precision: 0.5714 - val_recall: 0.8000 - val_auc: 0.8292\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.7497 - tp: 98.0000 - fp: 117.0000 - tn: 246.0000 - fn: 22.0000 - accuracy: 0.7122 - precision: 0.4558 - recall: 0.8167 - auc: 0.8248 - val_loss: 0.5749 - val_tp: 18.0000 - val_fp: 17.0000 - val_tn: 61.0000 - val_fn: 7.0000 - val_accuracy: 0.7670 - val_precision: 0.5143 - val_recall: 0.7200 - val_auc: 0.8036\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.7308 - tp: 99.0000 - fp: 102.0000 - tn: 261.0000 - fn: 21.0000 - accuracy: 0.7453 - precision: 0.4925 - recall: 0.8250 - auc: 0.8487 - val_loss: 0.5157 - val_tp: 10.0000 - val_fp: 6.0000 - val_tn: 72.0000 - val_fn: 15.0000 - val_accuracy: 0.7961 - val_precision: 0.6250 - val_recall: 0.4000 - val_auc: 0.7826\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8212 - tp: 89.0000 - fp: 86.0000 - tn: 277.0000 - fn: 31.0000 - accuracy: 0.7578 - precision: 0.5086 - recall: 0.7417 - auc: 0.8171 - val_loss: 0.7593 - val_tp: 25.0000 - val_fp: 57.0000 - val_tn: 21.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4466 - val_precision: 0.3049 - val_recall: 1.0000 - val_auc: 0.8618\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.7657 - tp: 93.0000 - fp: 82.0000 - tn: 281.0000 - fn: 27.0000 - accuracy: 0.7743 - precision: 0.5314 - recall: 0.7750 - auc: 0.8418 - val_loss: 0.7373 - val_tp: 24.0000 - val_fp: 31.0000 - val_tn: 47.0000 - val_fn: 1.0000 - val_accuracy: 0.6893 - val_precision: 0.4364 - val_recall: 0.9600 - val_auc: 0.8385\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.7524 - tp: 97.0000 - fp: 81.0000 - tn: 282.0000 - fn: 23.0000 - accuracy: 0.7847 - precision: 0.5449 - recall: 0.8083 - auc: 0.8445 - val_loss: 0.6647 - val_tp: 18.0000 - val_fp: 17.0000 - val_tn: 61.0000 - val_fn: 7.0000 - val_accuracy: 0.7670 - val_precision: 0.5143 - val_recall: 0.7200 - val_auc: 0.8279\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.6971 - tp: 95.0000 - fp: 71.0000 - tn: 292.0000 - fn: 25.0000 - accuracy: 0.8012 - precision: 0.5723 - recall: 0.7917 - auc: 0.8653 - val_loss: 0.8036 - val_tp: 22.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 3.0000 - val_accuracy: 0.5728 - val_precision: 0.3492 - val_recall: 0.8800 - val_auc: 0.8154\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.6594 - tp: 98.0000 - fp: 75.0000 - tn: 288.0000 - fn: 22.0000 - accuracy: 0.7992 - precision: 0.5665 - recall: 0.8167 - auc: 0.8821 - val_loss: 0.6466 - val_tp: 19.0000 - val_fp: 19.0000 - val_tn: 59.0000 - val_fn: 6.0000 - val_accuracy: 0.7573 - val_precision: 0.5000 - val_recall: 0.7600 - val_auc: 0.7621\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.6323 - tp: 100.0000 - fp: 61.0000 - tn: 302.0000 - fn: 20.0000 - accuracy: 0.8323 - precision: 0.6211 - recall: 0.8333 - auc: 0.8972 - val_loss: 0.7315 - val_tp: 22.0000 - val_fp: 24.0000 - val_tn: 54.0000 - val_fn: 3.0000 - val_accuracy: 0.7379 - val_precision: 0.4783 - val_recall: 0.8800 - val_auc: 0.8003\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.6386 - tp: 94.0000 - fp: 44.0000 - tn: 319.0000 - fn: 26.0000 - accuracy: 0.8551 - precision: 0.6812 - recall: 0.7833 - auc: 0.9003 - val_loss: 0.5983 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 65.0000 - val_fn: 11.0000 - val_accuracy: 0.7670 - val_precision: 0.5185 - val_recall: 0.5600 - val_auc: 0.7333\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.6253 - tp: 97.0000 - fp: 61.0000 - tn: 302.0000 - fn: 23.0000 - accuracy: 0.8261 - precision: 0.6139 - recall: 0.8083 - auc: 0.8955 - val_loss: 0.5963 - val_tp: 17.0000 - val_fp: 16.0000 - val_tn: 62.0000 - val_fn: 8.0000 - val_accuracy: 0.7670 - val_precision: 0.5152 - val_recall: 0.6800 - val_auc: 0.7608\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.5923 - tp: 111.0000 - fp: 84.0000 - tn: 279.0000 - fn: 9.0000 - accuracy: 0.8075 - precision: 0.5692 - recall: 0.9250 - auc: 0.9145 - val_loss: 0.5706 - val_tp: 16.0000 - val_fp: 15.0000 - val_tn: 63.0000 - val_fn: 9.0000 - val_accuracy: 0.7670 - val_precision: 0.5161 - val_recall: 0.6400 - val_auc: 0.7695\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.5208 - tp: 101.0000 - fp: 54.0000 - tn: 309.0000 - fn: 19.0000 - accuracy: 0.8489 - precision: 0.6516 - recall: 0.8417 - auc: 0.9288 - val_loss: 0.5545 - val_tp: 13.0000 - val_fp: 11.0000 - val_tn: 67.0000 - val_fn: 12.0000 - val_accuracy: 0.7767 - val_precision: 0.5417 - val_recall: 0.5200 - val_auc: 0.7608\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 208ms/step - loss: 0.4678 - tp: 108.0000 - fp: 48.0000 - tn: 315.0000 - fn: 12.0000 - accuracy: 0.8758 - precision: 0.6923 - recall: 0.9000 - auc: 0.9416 - val_loss: 0.6489 - val_tp: 13.0000 - val_fp: 12.0000 - val_tn: 66.0000 - val_fn: 12.0000 - val_accuracy: 0.7670 - val_precision: 0.5200 - val_recall: 0.5200 - val_auc: 0.6951\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.4580 - tp: 102.0000 - fp: 32.0000 - tn: 331.0000 - fn: 18.0000 - accuracy: 0.8965 - precision: 0.7612 - recall: 0.8500 - auc: 0.9468 - val_loss: 0.7227 - val_tp: 17.0000 - val_fp: 13.0000 - val_tn: 65.0000 - val_fn: 8.0000 - val_accuracy: 0.7961 - val_precision: 0.5667 - val_recall: 0.6800 - val_auc: 0.7477\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.4502 - tp: 111.0000 - fp: 51.0000 - tn: 312.0000 - fn: 9.0000 - accuracy: 0.8758 - precision: 0.6852 - recall: 0.9250 - auc: 0.9476 - val_loss: 0.6618 - val_tp: 14.0000 - val_fp: 11.0000 - val_tn: 67.0000 - val_fn: 11.0000 - val_accuracy: 0.7864 - val_precision: 0.5600 - val_recall: 0.5600 - val_auc: 0.7269\n",
      "Calculated mean IoU: 0.3581\n",
      "IoU from saved model: 0.3378\n",
      "Model with updated IoU has been saved.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 5s 305ms/step - loss: 28.3759 - tp: 93.0000 - fp: 223.0000 - tn: 218.0000 - fn: 52.0000 - accuracy: 0.5307 - precision: 0.2943 - recall: 0.6414 - auc: 0.5645 - val_loss: 0.6946 - val_tp: 22.0000 - val_fp: 70.0000 - val_tn: 8.0000 - val_fn: 3.0000 - val_accuracy: 0.2913 - val_precision: 0.2391 - val_recall: 0.8800 - val_auc: 0.4359\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0543 - tp: 76.0000 - fp: 208.0000 - tn: 155.0000 - fn: 44.0000 - accuracy: 0.4783 - precision: 0.2676 - recall: 0.6333 - auc: 0.5100 - val_loss: 0.6995 - val_tp: 25.0000 - val_fp: 77.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2524 - val_precision: 0.2451 - val_recall: 1.0000 - val_auc: 0.5269\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0266 - tp: 105.0000 - fp: 292.0000 - tn: 71.0000 - fn: 15.0000 - accuracy: 0.3644 - precision: 0.2645 - recall: 0.8750 - auc: 0.6336 - val_loss: 0.7039 - val_tp: 24.0000 - val_fp: 66.0000 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.3495 - val_precision: 0.2667 - val_recall: 0.9600 - val_auc: 0.6403\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0145 - tp: 74.0000 - fp: 145.0000 - tn: 218.0000 - fn: 46.0000 - accuracy: 0.6046 - precision: 0.3379 - recall: 0.6167 - auc: 0.6216 - val_loss: 0.6918 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.7010\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 1.0062 - tp: 92.0000 - fp: 180.0000 - tn: 183.0000 - fn: 28.0000 - accuracy: 0.5694 - precision: 0.3382 - recall: 0.7667 - auc: 0.6455 - val_loss: 0.6450 - val_tp: 22.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 3.0000 - val_accuracy: 0.4466 - val_precision: 0.2895 - val_recall: 0.8800 - val_auc: 0.6862\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9062 - tp: 104.0000 - fp: 169.0000 - tn: 194.0000 - fn: 16.0000 - accuracy: 0.6170 - precision: 0.3810 - recall: 0.8667 - auc: 0.7345 - val_loss: 0.6292 - val_tp: 21.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 4.0000 - val_accuracy: 0.4854 - val_precision: 0.3000 - val_recall: 0.8400 - val_auc: 0.6826\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 209ms/step - loss: 0.9491 - tp: 107.0000 - fp: 217.0000 - tn: 146.0000 - fn: 13.0000 - accuracy: 0.5238 - precision: 0.3302 - recall: 0.8917 - auc: 0.6779 - val_loss: 0.6674 - val_tp: 23.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.3883 - val_precision: 0.2738 - val_recall: 0.9200 - val_auc: 0.6677\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8723 - tp: 98.0000 - fp: 135.0000 - tn: 228.0000 - fn: 22.0000 - accuracy: 0.6749 - precision: 0.4206 - recall: 0.8167 - auc: 0.7612 - val_loss: 0.6408 - val_tp: 22.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 3.0000 - val_accuracy: 0.4466 - val_precision: 0.2895 - val_recall: 0.8800 - val_auc: 0.6826\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8854 - tp: 105.0000 - fp: 182.0000 - tn: 181.0000 - fn: 15.0000 - accuracy: 0.5921 - precision: 0.3659 - recall: 0.8750 - auc: 0.7549 - val_loss: 0.7075 - val_tp: 22.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 3.0000 - val_accuracy: 0.4078 - val_precision: 0.2750 - val_recall: 0.8800 - val_auc: 0.7010\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.9342 - tp: 103.0000 - fp: 184.0000 - tn: 179.0000 - fn: 17.0000 - accuracy: 0.5839 - precision: 0.3589 - recall: 0.8583 - auc: 0.7256 - val_loss: 0.6218 - val_tp: 18.0000 - val_fp: 33.0000 - val_tn: 45.0000 - val_fn: 7.0000 - val_accuracy: 0.6117 - val_precision: 0.3529 - val_recall: 0.7200 - val_auc: 0.7100\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8921 - tp: 92.0000 - fp: 132.0000 - tn: 231.0000 - fn: 28.0000 - accuracy: 0.6687 - precision: 0.4107 - recall: 0.7667 - auc: 0.7599 - val_loss: 0.6519 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.6974\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.8722 - tp: 105.0000 - fp: 155.0000 - tn: 208.0000 - fn: 15.0000 - accuracy: 0.6480 - precision: 0.4038 - recall: 0.8750 - auc: 0.7752 - val_loss: 0.7053 - val_tp: 22.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 3.0000 - val_accuracy: 0.4078 - val_precision: 0.2750 - val_recall: 0.8800 - val_auc: 0.6969\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.8355 - tp: 98.0000 - fp: 121.0000 - tn: 242.0000 - fn: 22.0000 - accuracy: 0.7039 - precision: 0.4475 - recall: 0.8167 - auc: 0.7772 - val_loss: 0.6707 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.6915\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.8538 - tp: 99.0000 - fp: 168.0000 - tn: 195.0000 - fn: 21.0000 - accuracy: 0.6087 - precision: 0.3708 - recall: 0.8250 - auc: 0.7476 - val_loss: 0.6602 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.6926\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.8452 - tp: 98.0000 - fp: 133.0000 - tn: 230.0000 - fn: 22.0000 - accuracy: 0.6791 - precision: 0.4242 - recall: 0.8167 - auc: 0.7749 - val_loss: 0.6685 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.6895\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.8850 - tp: 97.0000 - fp: 136.0000 - tn: 227.0000 - fn: 23.0000 - accuracy: 0.6708 - precision: 0.4163 - recall: 0.8083 - auc: 0.7419 - val_loss: 0.6936 - val_tp: 22.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 3.0000 - val_accuracy: 0.4078 - val_precision: 0.2750 - val_recall: 0.8800 - val_auc: 0.6915\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.8829 - tp: 104.0000 - fp: 188.0000 - tn: 175.0000 - fn: 16.0000 - accuracy: 0.5776 - precision: 0.3562 - recall: 0.8667 - auc: 0.7346 - val_loss: 0.6333 - val_tp: 21.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 4.0000 - val_accuracy: 0.4951 - val_precision: 0.3043 - val_recall: 0.8400 - val_auc: 0.6931\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8681 - tp: 107.0000 - fp: 188.0000 - tn: 175.0000 - fn: 13.0000 - accuracy: 0.5839 - precision: 0.3627 - recall: 0.8917 - auc: 0.7500 - val_loss: 0.6672 - val_tp: 22.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 3.0000 - val_accuracy: 0.4078 - val_precision: 0.2750 - val_recall: 0.8800 - val_auc: 0.6818\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.8259 - tp: 97.0000 - fp: 143.0000 - tn: 220.0000 - fn: 23.0000 - accuracy: 0.6563 - precision: 0.4042 - recall: 0.8083 - auc: 0.7789 - val_loss: 0.6875 - val_tp: 22.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.4369 - val_precision: 0.2857 - val_recall: 0.8800 - val_auc: 0.7005\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8496 - tp: 106.0000 - fp: 165.0000 - tn: 198.0000 - fn: 14.0000 - accuracy: 0.6294 - precision: 0.3911 - recall: 0.8833 - auc: 0.7780 - val_loss: 0.6196 - val_tp: 18.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 7.0000 - val_accuracy: 0.5631 - val_precision: 0.3214 - val_recall: 0.7200 - val_auc: 0.6572\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8459 - tp: 93.0000 - fp: 121.0000 - tn: 242.0000 - fn: 27.0000 - accuracy: 0.6936 - precision: 0.4346 - recall: 0.7750 - auc: 0.7851 - val_loss: 0.6551 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.6956\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9599 - tp: 102.0000 - fp: 179.0000 - tn: 184.0000 - fn: 18.0000 - accuracy: 0.5921 - precision: 0.3630 - recall: 0.8500 - auc: 0.7416 - val_loss: 0.6681 - val_tp: 22.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.4369 - val_precision: 0.2857 - val_recall: 0.8800 - val_auc: 0.6897\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8810 - tp: 84.0000 - fp: 111.0000 - tn: 252.0000 - fn: 36.0000 - accuracy: 0.6957 - precision: 0.4308 - recall: 0.7000 - auc: 0.7749 - val_loss: 0.6747 - val_tp: 23.0000 - val_fp: 57.0000 - val_tn: 21.0000 - val_fn: 2.0000 - val_accuracy: 0.4272 - val_precision: 0.2875 - val_recall: 0.9200 - val_auc: 0.7246\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8254 - tp: 104.0000 - fp: 166.0000 - tn: 197.0000 - fn: 16.0000 - accuracy: 0.6232 - precision: 0.3852 - recall: 0.8667 - auc: 0.7827 - val_loss: 0.6242 - val_tp: 22.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 3.0000 - val_accuracy: 0.5340 - val_precision: 0.3284 - val_recall: 0.8800 - val_auc: 0.7310\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.7803 - tp: 103.0000 - fp: 135.0000 - tn: 228.0000 - fn: 17.0000 - accuracy: 0.6853 - precision: 0.4328 - recall: 0.8583 - auc: 0.8128 - val_loss: 0.6588 - val_tp: 23.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 2.0000 - val_accuracy: 0.4854 - val_precision: 0.3108 - val_recall: 0.9200 - val_auc: 0.7751\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.7404 - tp: 99.0000 - fp: 122.0000 - tn: 241.0000 - fn: 21.0000 - accuracy: 0.7039 - precision: 0.4480 - recall: 0.8250 - auc: 0.8306 - val_loss: 0.6206 - val_tp: 21.0000 - val_fp: 34.0000 - val_tn: 44.0000 - val_fn: 4.0000 - val_accuracy: 0.6311 - val_precision: 0.3818 - val_recall: 0.8400 - val_auc: 0.7759\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.7138 - tp: 102.0000 - fp: 107.0000 - tn: 256.0000 - fn: 18.0000 - accuracy: 0.7412 - precision: 0.4880 - recall: 0.8500 - auc: 0.8489 - val_loss: 0.6084 - val_tp: 19.0000 - val_fp: 26.0000 - val_tn: 52.0000 - val_fn: 6.0000 - val_accuracy: 0.6893 - val_precision: 0.4222 - val_recall: 0.7600 - val_auc: 0.7800\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.7972 - tp: 86.0000 - fp: 92.0000 - tn: 271.0000 - fn: 34.0000 - accuracy: 0.7391 - precision: 0.4831 - recall: 0.7167 - auc: 0.8196 - val_loss: 0.7235 - val_tp: 23.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 2.0000 - val_accuracy: 0.4951 - val_precision: 0.3151 - val_recall: 0.9200 - val_auc: 0.8169\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.7615 - tp: 88.0000 - fp: 107.0000 - tn: 256.0000 - fn: 32.0000 - accuracy: 0.7122 - precision: 0.4513 - recall: 0.7333 - auc: 0.8194 - val_loss: 0.6495 - val_tp: 22.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 3.0000 - val_accuracy: 0.5534 - val_precision: 0.3385 - val_recall: 0.8800 - val_auc: 0.8131\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.7211 - tp: 103.0000 - fp: 110.0000 - tn: 253.0000 - fn: 17.0000 - accuracy: 0.7371 - precision: 0.4836 - recall: 0.8583 - auc: 0.8607 - val_loss: 0.7255 - val_tp: 23.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 2.0000 - val_accuracy: 0.4757 - val_precision: 0.3067 - val_recall: 0.9200 - val_auc: 0.8087\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.7226 - tp: 95.0000 - fp: 84.0000 - tn: 279.0000 - fn: 25.0000 - accuracy: 0.7743 - precision: 0.5307 - recall: 0.7917 - auc: 0.8475 - val_loss: 0.7227 - val_tp: 23.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 2.0000 - val_accuracy: 0.4757 - val_precision: 0.3067 - val_recall: 0.9200 - val_auc: 0.8154\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.7218 - tp: 105.0000 - fp: 120.0000 - tn: 243.0000 - fn: 15.0000 - accuracy: 0.7205 - precision: 0.4667 - recall: 0.8750 - auc: 0.8528 - val_loss: 0.7291 - val_tp: 23.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 2.0000 - val_accuracy: 0.5146 - val_precision: 0.3239 - val_recall: 0.9200 - val_auc: 0.8100\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.6579 - tp: 107.0000 - fp: 104.0000 - tn: 259.0000 - fn: 13.0000 - accuracy: 0.7578 - precision: 0.5071 - recall: 0.8917 - auc: 0.8819 - val_loss: 0.6514 - val_tp: 22.0000 - val_fp: 32.0000 - val_tn: 46.0000 - val_fn: 3.0000 - val_accuracy: 0.6602 - val_precision: 0.4074 - val_recall: 0.8800 - val_auc: 0.7928\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.6247 - tp: 102.0000 - fp: 81.0000 - tn: 282.0000 - fn: 18.0000 - accuracy: 0.7950 - precision: 0.5574 - recall: 0.8500 - auc: 0.8929 - val_loss: 0.7590 - val_tp: 22.0000 - val_fp: 40.0000 - val_tn: 38.0000 - val_fn: 3.0000 - val_accuracy: 0.5825 - val_precision: 0.3548 - val_recall: 0.8800 - val_auc: 0.7838\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.5665 - tp: 109.0000 - fp: 71.0000 - tn: 292.0000 - fn: 11.0000 - accuracy: 0.8302 - precision: 0.6056 - recall: 0.9083 - auc: 0.9106 - val_loss: 0.6942 - val_tp: 21.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 4.0000 - val_accuracy: 0.5922 - val_precision: 0.3559 - val_recall: 0.8400 - val_auc: 0.7705\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.6167 - tp: 103.0000 - fp: 65.0000 - tn: 298.0000 - fn: 17.0000 - accuracy: 0.8302 - precision: 0.6131 - recall: 0.8583 - auc: 0.9064 - val_loss: 0.7403 - val_tp: 17.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 8.0000 - val_accuracy: 0.5534 - val_precision: 0.3091 - val_recall: 0.6800 - val_auc: 0.6615\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.6882 - tp: 95.0000 - fp: 94.0000 - tn: 269.0000 - fn: 25.0000 - accuracy: 0.7536 - precision: 0.5026 - recall: 0.7917 - auc: 0.8724 - val_loss: 0.6942 - val_tp: 23.0000 - val_fp: 30.0000 - val_tn: 48.0000 - val_fn: 2.0000 - val_accuracy: 0.6893 - val_precision: 0.4340 - val_recall: 0.9200 - val_auc: 0.7713\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.6152 - tp: 104.0000 - fp: 77.0000 - tn: 286.0000 - fn: 16.0000 - accuracy: 0.8075 - precision: 0.5746 - recall: 0.8667 - auc: 0.8988 - val_loss: 0.7186 - val_tp: 21.0000 - val_fp: 32.0000 - val_tn: 46.0000 - val_fn: 4.0000 - val_accuracy: 0.6505 - val_precision: 0.3962 - val_recall: 0.8400 - val_auc: 0.7690\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.5702 - tp: 106.0000 - fp: 78.0000 - tn: 285.0000 - fn: 14.0000 - accuracy: 0.8095 - precision: 0.5761 - recall: 0.8833 - auc: 0.9078 - val_loss: 0.9001 - val_tp: 24.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 1.0000 - val_accuracy: 0.5922 - val_precision: 0.3692 - val_recall: 0.9600 - val_auc: 0.8174\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.5879 - tp: 107.0000 - fp: 83.0000 - tn: 280.0000 - fn: 13.0000 - accuracy: 0.8012 - precision: 0.5632 - recall: 0.8917 - auc: 0.9142 - val_loss: 0.8874 - val_tp: 21.0000 - val_fp: 35.0000 - val_tn: 43.0000 - val_fn: 4.0000 - val_accuracy: 0.6214 - val_precision: 0.3750 - val_recall: 0.8400 - val_auc: 0.7282\n",
      "Calculated mean IoU: 0.4550\n",
      "IoU from saved model: 0.3581\n",
      "Model with updated IoU has been saved.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 4s 273ms/step - loss: 38.5833 - tp: 82.0000 - fp: 220.0000 - tn: 221.0000 - fn: 63.0000 - accuracy: 0.5171 - precision: 0.2715 - recall: 0.5655 - auc: 0.5319 - val_loss: 0.7490 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.7072\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 1.0406 - tp: 67.0000 - fp: 177.0000 - tn: 186.0000 - fn: 53.0000 - accuracy: 0.5238 - precision: 0.2746 - recall: 0.5583 - auc: 0.5437 - val_loss: 0.6911 - val_tp: 22.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 3.0000 - val_accuracy: 0.5146 - val_precision: 0.3188 - val_recall: 0.8800 - val_auc: 0.7074\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 1.0462 - tp: 61.0000 - fp: 151.0000 - tn: 212.0000 - fn: 59.0000 - accuracy: 0.5652 - precision: 0.2877 - recall: 0.5083 - auc: 0.5557 - val_loss: 0.6700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6736\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 1.0293 - tp: 11.0000 - fp: 21.0000 - tn: 342.0000 - fn: 109.0000 - accuracy: 0.7308 - precision: 0.3438 - recall: 0.0917 - auc: 0.6170 - val_loss: 0.6812 - val_tp: 16.0000 - val_fp: 23.0000 - val_tn: 55.0000 - val_fn: 9.0000 - val_accuracy: 0.6893 - val_precision: 0.4103 - val_recall: 0.6400 - val_auc: 0.7369\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.9260 - tp: 74.0000 - fp: 127.0000 - tn: 236.0000 - fn: 46.0000 - accuracy: 0.6418 - precision: 0.3682 - recall: 0.6167 - auc: 0.7059 - val_loss: 0.6731 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.6892\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.9289 - tp: 78.0000 - fp: 128.0000 - tn: 235.0000 - fn: 42.0000 - accuracy: 0.6480 - precision: 0.3786 - recall: 0.6500 - auc: 0.7235 - val_loss: 0.6276 - val_tp: 21.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 4.0000 - val_accuracy: 0.5146 - val_precision: 0.3134 - val_recall: 0.8400 - val_auc: 0.7254\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.9778 - tp: 109.0000 - fp: 221.0000 - tn: 142.0000 - fn: 11.0000 - accuracy: 0.5197 - precision: 0.3303 - recall: 0.9083 - auc: 0.7001 - val_loss: 0.7154 - val_tp: 24.0000 - val_fp: 66.0000 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.3495 - val_precision: 0.2667 - val_recall: 0.9600 - val_auc: 0.6874\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.9027 - tp: 86.0000 - fp: 137.0000 - tn: 226.0000 - fn: 34.0000 - accuracy: 0.6460 - precision: 0.3857 - recall: 0.7167 - auc: 0.7275 - val_loss: 0.7166 - val_tp: 22.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 3.0000 - val_accuracy: 0.4078 - val_precision: 0.2750 - val_recall: 0.8800 - val_auc: 0.7082\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.9576 - tp: 97.0000 - fp: 187.0000 - tn: 176.0000 - fn: 23.0000 - accuracy: 0.5652 - precision: 0.3415 - recall: 0.8083 - auc: 0.7179 - val_loss: 0.7201 - val_tp: 23.0000 - val_fp: 64.0000 - val_tn: 14.0000 - val_fn: 2.0000 - val_accuracy: 0.3592 - val_precision: 0.2644 - val_recall: 0.9200 - val_auc: 0.7059\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.9615 - tp: 82.0000 - fp: 147.0000 - tn: 216.0000 - fn: 38.0000 - accuracy: 0.6170 - precision: 0.3581 - recall: 0.6833 - auc: 0.6970 - val_loss: 0.7021 - val_tp: 23.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 2.0000 - val_accuracy: 0.4369 - val_precision: 0.2911 - val_recall: 0.9200 - val_auc: 0.7097\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.9302 - tp: 90.0000 - fp: 145.0000 - tn: 218.0000 - fn: 30.0000 - accuracy: 0.6377 - precision: 0.3830 - recall: 0.7500 - auc: 0.7104 - val_loss: 0.6606 - val_tp: 20.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 5.0000 - val_accuracy: 0.5340 - val_precision: 0.3175 - val_recall: 0.8000 - val_auc: 0.7167\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9086 - tp: 77.0000 - fp: 109.0000 - tn: 254.0000 - fn: 43.0000 - accuracy: 0.6853 - precision: 0.4140 - recall: 0.6417 - auc: 0.7343 - val_loss: 0.6396 - val_tp: 21.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 4.0000 - val_accuracy: 0.4951 - val_precision: 0.3043 - val_recall: 0.8400 - val_auc: 0.7287\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.8701 - tp: 102.0000 - fp: 155.0000 - tn: 208.0000 - fn: 18.0000 - accuracy: 0.6418 - precision: 0.3969 - recall: 0.8500 - auc: 0.7628 - val_loss: 0.6942 - val_tp: 23.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.4175 - val_precision: 0.2840 - val_recall: 0.9200 - val_auc: 0.7215\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8603 - tp: 97.0000 - fp: 146.0000 - tn: 217.0000 - fn: 23.0000 - accuracy: 0.6501 - precision: 0.3992 - recall: 0.8083 - auc: 0.7550 - val_loss: 0.6370 - val_tp: 21.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 4.0000 - val_accuracy: 0.5146 - val_precision: 0.3134 - val_recall: 0.8400 - val_auc: 0.7413\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.9304 - tp: 100.0000 - fp: 168.0000 - tn: 195.0000 - fn: 20.0000 - accuracy: 0.6108 - precision: 0.3731 - recall: 0.8333 - auc: 0.7309 - val_loss: 0.7323 - val_tp: 23.0000 - val_fp: 63.0000 - val_tn: 15.0000 - val_fn: 2.0000 - val_accuracy: 0.3689 - val_precision: 0.2674 - val_recall: 0.9200 - val_auc: 0.7282\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9402 - tp: 60.0000 - fp: 81.0000 - tn: 282.0000 - fn: 60.0000 - accuracy: 0.7081 - precision: 0.4255 - recall: 0.5000 - auc: 0.7193 - val_loss: 0.6968 - val_tp: 23.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 2.0000 - val_accuracy: 0.4563 - val_precision: 0.2987 - val_recall: 0.9200 - val_auc: 0.7382\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9272 - tp: 80.0000 - fp: 120.0000 - tn: 243.0000 - fn: 40.0000 - accuracy: 0.6687 - precision: 0.4000 - recall: 0.6667 - auc: 0.7142 - val_loss: 0.6797 - val_tp: 20.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 5.0000 - val_accuracy: 0.4660 - val_precision: 0.2857 - val_recall: 0.8000 - val_auc: 0.7367\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8902 - tp: 90.0000 - fp: 145.0000 - tn: 218.0000 - fn: 30.0000 - accuracy: 0.6377 - precision: 0.3830 - recall: 0.7500 - auc: 0.7464 - val_loss: 0.6911 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.7462\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8968 - tp: 85.0000 - fp: 122.0000 - tn: 241.0000 - fn: 35.0000 - accuracy: 0.6749 - precision: 0.4106 - recall: 0.7083 - auc: 0.7379 - val_loss: 0.7002 - val_tp: 22.0000 - val_fp: 57.0000 - val_tn: 21.0000 - val_fn: 3.0000 - val_accuracy: 0.4175 - val_precision: 0.2785 - val_recall: 0.8800 - val_auc: 0.7526\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.8820 - tp: 103.0000 - fp: 170.0000 - tn: 193.0000 - fn: 17.0000 - accuracy: 0.6128 - precision: 0.3773 - recall: 0.8583 - auc: 0.7521 - val_loss: 0.6637 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.7574\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8763 - tp: 108.0000 - fp: 173.0000 - tn: 190.0000 - fn: 12.0000 - accuracy: 0.6170 - precision: 0.3843 - recall: 0.9000 - auc: 0.7641 - val_loss: 0.7806 - val_tp: 23.0000 - val_fp: 65.0000 - val_tn: 13.0000 - val_fn: 2.0000 - val_accuracy: 0.3495 - val_precision: 0.2614 - val_recall: 0.9200 - val_auc: 0.7441\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8798 - tp: 95.0000 - fp: 153.0000 - tn: 210.0000 - fn: 25.0000 - accuracy: 0.6315 - precision: 0.3831 - recall: 0.7917 - auc: 0.7567 - val_loss: 0.6451 - val_tp: 20.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 5.0000 - val_accuracy: 0.5922 - val_precision: 0.3509 - val_recall: 0.8000 - val_auc: 0.7474\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.8501 - tp: 97.0000 - fp: 140.0000 - tn: 223.0000 - fn: 23.0000 - accuracy: 0.6625 - precision: 0.4093 - recall: 0.8083 - auc: 0.7729 - val_loss: 0.6494 - val_tp: 20.0000 - val_fp: 31.0000 - val_tn: 47.0000 - val_fn: 5.0000 - val_accuracy: 0.6505 - val_precision: 0.3922 - val_recall: 0.8000 - val_auc: 0.7664\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8528 - tp: 101.0000 - fp: 149.0000 - tn: 214.0000 - fn: 19.0000 - accuracy: 0.6522 - precision: 0.4040 - recall: 0.8417 - auc: 0.7686 - val_loss: 0.6699 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.7741\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8740 - tp: 89.0000 - fp: 117.0000 - tn: 246.0000 - fn: 31.0000 - accuracy: 0.6936 - precision: 0.4320 - recall: 0.7417 - auc: 0.7579 - val_loss: 0.6656 - val_tp: 22.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 3.0000 - val_accuracy: 0.5049 - val_precision: 0.3143 - val_recall: 0.8800 - val_auc: 0.7751\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.7954 - tp: 105.0000 - fp: 147.0000 - tn: 216.0000 - fn: 15.0000 - accuracy: 0.6646 - precision: 0.4167 - recall: 0.8750 - auc: 0.7914 - val_loss: 0.6354 - val_tp: 22.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 3.0000 - val_accuracy: 0.5922 - val_precision: 0.3607 - val_recall: 0.8800 - val_auc: 0.7772\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8338 - tp: 104.0000 - fp: 147.0000 - tn: 216.0000 - fn: 16.0000 - accuracy: 0.6625 - precision: 0.4143 - recall: 0.8667 - auc: 0.7943 - val_loss: 0.6346 - val_tp: 21.0000 - val_fp: 31.0000 - val_tn: 47.0000 - val_fn: 4.0000 - val_accuracy: 0.6602 - val_precision: 0.4038 - val_recall: 0.8400 - val_auc: 0.7713\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8224 - tp: 89.0000 - fp: 114.0000 - tn: 249.0000 - fn: 31.0000 - accuracy: 0.6998 - precision: 0.4384 - recall: 0.7417 - auc: 0.7952 - val_loss: 0.6247 - val_tp: 22.0000 - val_fp: 32.0000 - val_tn: 46.0000 - val_fn: 3.0000 - val_accuracy: 0.6602 - val_precision: 0.4074 - val_recall: 0.8800 - val_auc: 0.7736\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.7583 - tp: 101.0000 - fp: 120.0000 - tn: 243.0000 - fn: 19.0000 - accuracy: 0.7122 - precision: 0.4570 - recall: 0.8417 - auc: 0.8239 - val_loss: 0.6028 - val_tp: 20.0000 - val_fp: 23.0000 - val_tn: 55.0000 - val_fn: 5.0000 - val_accuracy: 0.7282 - val_precision: 0.4651 - val_recall: 0.8000 - val_auc: 0.7659\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.7466 - tp: 99.0000 - fp: 118.0000 - tn: 245.0000 - fn: 21.0000 - accuracy: 0.7122 - precision: 0.4562 - recall: 0.8250 - auc: 0.8382 - val_loss: 0.6560 - val_tp: 22.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 3.0000 - val_accuracy: 0.6117 - val_precision: 0.3729 - val_recall: 0.8800 - val_auc: 0.7651\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.7089 - tp: 101.0000 - fp: 107.0000 - tn: 256.0000 - fn: 19.0000 - accuracy: 0.7391 - precision: 0.4856 - recall: 0.8417 - auc: 0.8528 - val_loss: 0.6438 - val_tp: 22.0000 - val_fp: 34.0000 - val_tn: 44.0000 - val_fn: 3.0000 - val_accuracy: 0.6408 - val_precision: 0.3929 - val_recall: 0.8800 - val_auc: 0.7690\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.7546 - tp: 95.0000 - fp: 97.0000 - tn: 266.0000 - fn: 25.0000 - accuracy: 0.7474 - precision: 0.4948 - recall: 0.7917 - auc: 0.8332 - val_loss: 0.7388 - val_tp: 23.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 2.0000 - val_accuracy: 0.5534 - val_precision: 0.3433 - val_recall: 0.9200 - val_auc: 0.7638\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.7678 - tp: 94.0000 - fp: 109.0000 - tn: 254.0000 - fn: 26.0000 - accuracy: 0.7205 - precision: 0.4631 - recall: 0.7833 - auc: 0.8228 - val_loss: 0.5781 - val_tp: 17.0000 - val_fp: 18.0000 - val_tn: 60.0000 - val_fn: 8.0000 - val_accuracy: 0.7476 - val_precision: 0.4857 - val_recall: 0.6800 - val_auc: 0.7851\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.7559 - tp: 90.0000 - fp: 99.0000 - tn: 264.0000 - fn: 30.0000 - accuracy: 0.7329 - precision: 0.4762 - recall: 0.7500 - auc: 0.8230 - val_loss: 0.6190 - val_tp: 21.0000 - val_fp: 29.0000 - val_tn: 49.0000 - val_fn: 4.0000 - val_accuracy: 0.6796 - val_precision: 0.4200 - val_recall: 0.8400 - val_auc: 0.7751\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.7272 - tp: 97.0000 - fp: 83.0000 - tn: 280.0000 - fn: 23.0000 - accuracy: 0.7805 - precision: 0.5389 - recall: 0.8083 - auc: 0.8533 - val_loss: 0.7127 - val_tp: 23.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 2.0000 - val_accuracy: 0.5146 - val_precision: 0.3239 - val_recall: 0.9200 - val_auc: 0.7913\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.8143 - tp: 86.0000 - fp: 100.0000 - tn: 263.0000 - fn: 34.0000 - accuracy: 0.7226 - precision: 0.4624 - recall: 0.7167 - auc: 0.8009 - val_loss: 0.6419 - val_tp: 23.0000 - val_fp: 28.0000 - val_tn: 50.0000 - val_fn: 2.0000 - val_accuracy: 0.7087 - val_precision: 0.4510 - val_recall: 0.9200 - val_auc: 0.7951\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.7502 - tp: 95.0000 - fp: 100.0000 - tn: 263.0000 - fn: 25.0000 - accuracy: 0.7412 - precision: 0.4872 - recall: 0.7917 - auc: 0.8413 - val_loss: 0.6347 - val_tp: 17.0000 - val_fp: 28.0000 - val_tn: 50.0000 - val_fn: 8.0000 - val_accuracy: 0.6505 - val_precision: 0.3778 - val_recall: 0.6800 - val_auc: 0.7133\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.7313 - tp: 93.0000 - fp: 98.0000 - tn: 265.0000 - fn: 27.0000 - accuracy: 0.7412 - precision: 0.4869 - recall: 0.7750 - auc: 0.8448 - val_loss: 0.6436 - val_tp: 23.0000 - val_fp: 28.0000 - val_tn: 50.0000 - val_fn: 2.0000 - val_accuracy: 0.7087 - val_precision: 0.4510 - val_recall: 0.9200 - val_auc: 0.7805\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.6926 - tp: 105.0000 - fp: 94.0000 - tn: 269.0000 - fn: 15.0000 - accuracy: 0.7743 - precision: 0.5276 - recall: 0.8750 - auc: 0.8650 - val_loss: 0.6366 - val_tp: 21.0000 - val_fp: 28.0000 - val_tn: 50.0000 - val_fn: 4.0000 - val_accuracy: 0.6893 - val_precision: 0.4286 - val_recall: 0.8400 - val_auc: 0.7618\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.6928 - tp: 95.0000 - fp: 100.0000 - tn: 263.0000 - fn: 25.0000 - accuracy: 0.7412 - precision: 0.4872 - recall: 0.7917 - auc: 0.8558 - val_loss: 0.6608 - val_tp: 18.0000 - val_fp: 28.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.6602 - val_precision: 0.3913 - val_recall: 0.7200 - val_auc: 0.7223\n",
      "Calculated mean IoU: 0.5512\n",
      "IoU from saved model: 0.455\n",
      "Model with updated IoU has been saved.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 5s 300ms/step - loss: 15.7240 - tp: 76.0000 - fp: 226.0000 - tn: 215.0000 - fn: 69.0000 - accuracy: 0.4966 - precision: 0.2517 - recall: 0.5241 - auc: 0.5303 - val_loss: 0.6934 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 1.0486 - tp: 70.0000 - fp: 158.0000 - tn: 205.0000 - fn: 50.0000 - accuracy: 0.5694 - precision: 0.3070 - recall: 0.5833 - auc: 0.5392 - val_loss: 0.6956 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 1.0437 - tp: 113.0000 - fp: 353.0000 - tn: 10.0000 - fn: 7.0000 - accuracy: 0.2547 - precision: 0.2425 - recall: 0.9417 - auc: 0.4993 - val_loss: 0.6990 - val_tp: 25.0000 - val_fp: 77.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2524 - val_precision: 0.2451 - val_recall: 1.0000 - val_auc: 0.5128\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 1.0328 - tp: 56.0000 - fp: 116.0000 - tn: 247.0000 - fn: 64.0000 - accuracy: 0.6273 - precision: 0.3256 - recall: 0.4667 - auc: 0.5861 - val_loss: 0.6815 - val_tp: 5.0000 - val_fp: 10.0000 - val_tn: 68.0000 - val_fn: 20.0000 - val_accuracy: 0.7087 - val_precision: 0.3333 - val_recall: 0.2000 - val_auc: 0.6213\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 1.0097 - tp: 52.0000 - fp: 97.0000 - tn: 266.0000 - fn: 68.0000 - accuracy: 0.6584 - precision: 0.3490 - recall: 0.4333 - auc: 0.6543 - val_loss: 0.7183 - val_tp: 25.0000 - val_fp: 68.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3398 - val_precision: 0.2688 - val_recall: 1.0000 - val_auc: 0.5651\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 1.0104 - tp: 109.0000 - fp: 270.0000 - tn: 93.0000 - fn: 11.0000 - accuracy: 0.4182 - precision: 0.2876 - recall: 0.9083 - auc: 0.6457 - val_loss: 0.6179 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4497\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.9978 - tp: 90.0000 - fp: 169.0000 - tn: 194.0000 - fn: 30.0000 - accuracy: 0.5880 - precision: 0.3475 - recall: 0.7500 - auc: 0.6920 - val_loss: 0.6273 - val_tp: 18.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 7.0000 - val_accuracy: 0.5243 - val_precision: 0.3000 - val_recall: 0.7200 - val_auc: 0.6090\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.9941 - tp: 80.0000 - fp: 168.0000 - tn: 195.0000 - fn: 40.0000 - accuracy: 0.5694 - precision: 0.3226 - recall: 0.6667 - auc: 0.6393 - val_loss: 0.6845 - val_tp: 21.0000 - val_fp: 59.0000 - val_tn: 19.0000 - val_fn: 4.0000 - val_accuracy: 0.3883 - val_precision: 0.2625 - val_recall: 0.8400 - val_auc: 0.6264\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.9589 - tp: 84.0000 - fp: 128.0000 - tn: 235.0000 - fn: 36.0000 - accuracy: 0.6605 - precision: 0.3962 - recall: 0.7000 - auc: 0.7049 - val_loss: 0.6892 - val_tp: 21.0000 - val_fp: 57.0000 - val_tn: 21.0000 - val_fn: 4.0000 - val_accuracy: 0.4078 - val_precision: 0.2692 - val_recall: 0.8400 - val_auc: 0.6585\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.9571 - tp: 89.0000 - fp: 152.0000 - tn: 211.0000 - fn: 31.0000 - accuracy: 0.6211 - precision: 0.3693 - recall: 0.7417 - auc: 0.7127 - val_loss: 0.7037 - val_tp: 24.0000 - val_fp: 63.0000 - val_tn: 15.0000 - val_fn: 1.0000 - val_accuracy: 0.3786 - val_precision: 0.2759 - val_recall: 0.9600 - val_auc: 0.6259\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.9225 - tp: 68.0000 - fp: 113.0000 - tn: 250.0000 - fn: 52.0000 - accuracy: 0.6584 - precision: 0.3757 - recall: 0.5667 - auc: 0.7169 - val_loss: 0.6308 - val_tp: 20.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 5.0000 - val_accuracy: 0.5049 - val_precision: 0.3030 - val_recall: 0.8000 - val_auc: 0.6674\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8828 - tp: 101.0000 - fp: 156.0000 - tn: 207.0000 - fn: 19.0000 - accuracy: 0.6377 - precision: 0.3930 - recall: 0.8417 - auc: 0.7494 - val_loss: 0.6948 - val_tp: 23.0000 - val_fp: 60.0000 - val_tn: 18.0000 - val_fn: 2.0000 - val_accuracy: 0.3981 - val_precision: 0.2771 - val_recall: 0.9200 - val_auc: 0.6628\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.8919 - tp: 103.0000 - fp: 186.0000 - tn: 177.0000 - fn: 17.0000 - accuracy: 0.5797 - precision: 0.3564 - recall: 0.8583 - auc: 0.7504 - val_loss: 0.6875 - val_tp: 22.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.4369 - val_precision: 0.2857 - val_recall: 0.8800 - val_auc: 0.6664\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8877 - tp: 98.0000 - fp: 166.0000 - tn: 197.0000 - fn: 22.0000 - accuracy: 0.6108 - precision: 0.3712 - recall: 0.8167 - auc: 0.7270 - val_loss: 0.6355 - val_tp: 22.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 3.0000 - val_accuracy: 0.5437 - val_precision: 0.3333 - val_recall: 0.8800 - val_auc: 0.6636\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8937 - tp: 98.0000 - fp: 164.0000 - tn: 199.0000 - fn: 22.0000 - accuracy: 0.6149 - precision: 0.3740 - recall: 0.8167 - auc: 0.7216 - val_loss: 0.7721 - val_tp: 25.0000 - val_fp: 68.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3398 - val_precision: 0.2688 - val_recall: 1.0000 - val_auc: 0.6533\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.9807 - tp: 75.0000 - fp: 150.0000 - tn: 213.0000 - fn: 45.0000 - accuracy: 0.5963 - precision: 0.3333 - recall: 0.6250 - auc: 0.6594 - val_loss: 0.8301 - val_tp: 25.0000 - val_fp: 75.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2718 - val_precision: 0.2500 - val_recall: 1.0000 - val_auc: 0.6731\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 1.0116 - tp: 67.0000 - fp: 134.0000 - tn: 229.0000 - fn: 53.0000 - accuracy: 0.6128 - precision: 0.3333 - recall: 0.5583 - auc: 0.6305 - val_loss: 0.7181 - val_tp: 24.0000 - val_fp: 62.0000 - val_tn: 16.0000 - val_fn: 1.0000 - val_accuracy: 0.3883 - val_precision: 0.2791 - val_recall: 0.9600 - val_auc: 0.6497\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.9224 - tp: 93.0000 - fp: 164.0000 - tn: 199.0000 - fn: 27.0000 - accuracy: 0.6046 - precision: 0.3619 - recall: 0.7750 - auc: 0.7103 - val_loss: 0.6266 - val_tp: 13.0000 - val_fp: 25.0000 - val_tn: 53.0000 - val_fn: 12.0000 - val_accuracy: 0.6408 - val_precision: 0.3421 - val_recall: 0.5200 - val_auc: 0.6441\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9020 - tp: 95.0000 - fp: 162.0000 - tn: 201.0000 - fn: 25.0000 - accuracy: 0.6128 - precision: 0.3696 - recall: 0.7917 - auc: 0.7339 - val_loss: 0.6980 - val_tp: 21.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 4.0000 - val_accuracy: 0.4466 - val_precision: 0.2838 - val_recall: 0.8400 - val_auc: 0.6587\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9391 - tp: 89.0000 - fp: 153.0000 - tn: 210.0000 - fn: 31.0000 - accuracy: 0.6190 - precision: 0.3678 - recall: 0.7417 - auc: 0.7200 - val_loss: 0.6668 - val_tp: 20.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 5.0000 - val_accuracy: 0.4854 - val_precision: 0.2941 - val_recall: 0.8000 - val_auc: 0.6679\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9569 - tp: 114.0000 - fp: 238.0000 - tn: 125.0000 - fn: 6.0000 - accuracy: 0.4948 - precision: 0.3239 - recall: 0.9500 - auc: 0.7267 - val_loss: 0.7386 - val_tp: 23.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.4175 - val_precision: 0.2840 - val_recall: 0.9200 - val_auc: 0.6728\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.9141 - tp: 92.0000 - fp: 136.0000 - tn: 227.0000 - fn: 28.0000 - accuracy: 0.6605 - precision: 0.4035 - recall: 0.7667 - auc: 0.7259 - val_loss: 0.6275 - val_tp: 15.0000 - val_fp: 31.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.6019 - val_precision: 0.3261 - val_recall: 0.6000 - val_auc: 0.6915\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.8904 - tp: 87.0000 - fp: 142.0000 - tn: 221.0000 - fn: 33.0000 - accuracy: 0.6377 - precision: 0.3799 - recall: 0.7250 - auc: 0.7472 - val_loss: 0.7007 - val_tp: 23.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 2.0000 - val_accuracy: 0.4466 - val_precision: 0.2949 - val_recall: 0.9200 - val_auc: 0.6921\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.9010 - tp: 86.0000 - fp: 111.0000 - tn: 252.0000 - fn: 34.0000 - accuracy: 0.6998 - precision: 0.4365 - recall: 0.7167 - auc: 0.7588 - val_loss: 0.6548 - val_tp: 18.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 7.0000 - val_accuracy: 0.5146 - val_precision: 0.2951 - val_recall: 0.7200 - val_auc: 0.6872\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8541 - tp: 103.0000 - fp: 157.0000 - tn: 206.0000 - fn: 17.0000 - accuracy: 0.6398 - precision: 0.3962 - recall: 0.8583 - auc: 0.7665 - val_loss: 0.6498 - val_tp: 19.0000 - val_fp: 40.0000 - val_tn: 38.0000 - val_fn: 6.0000 - val_accuracy: 0.5534 - val_precision: 0.3220 - val_recall: 0.7600 - val_auc: 0.6933\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8510 - tp: 92.0000 - fp: 125.0000 - tn: 238.0000 - fn: 28.0000 - accuracy: 0.6832 - precision: 0.4240 - recall: 0.7667 - auc: 0.7802 - val_loss: 0.6182 - val_tp: 18.0000 - val_fp: 35.0000 - val_tn: 43.0000 - val_fn: 7.0000 - val_accuracy: 0.5922 - val_precision: 0.3396 - val_recall: 0.7200 - val_auc: 0.6964\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9042 - tp: 102.0000 - fp: 168.0000 - tn: 195.0000 - fn: 18.0000 - accuracy: 0.6149 - precision: 0.3778 - recall: 0.8500 - auc: 0.7337 - val_loss: 0.6299 - val_tp: 18.0000 - val_fp: 32.0000 - val_tn: 46.0000 - val_fn: 7.0000 - val_accuracy: 0.6214 - val_precision: 0.3600 - val_recall: 0.7200 - val_auc: 0.6974\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.8272 - tp: 97.0000 - fp: 121.0000 - tn: 242.0000 - fn: 23.0000 - accuracy: 0.7019 - precision: 0.4450 - recall: 0.8083 - auc: 0.7818 - val_loss: 0.6395 - val_tp: 19.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 6.0000 - val_accuracy: 0.5631 - val_precision: 0.3276 - val_recall: 0.7600 - val_auc: 0.6974\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8668 - tp: 105.0000 - fp: 142.0000 - tn: 221.0000 - fn: 15.0000 - accuracy: 0.6749 - precision: 0.4251 - recall: 0.8750 - auc: 0.7928 - val_loss: 0.6892 - val_tp: 21.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 4.0000 - val_accuracy: 0.4175 - val_precision: 0.2727 - val_recall: 0.8400 - val_auc: 0.6808\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.8452 - tp: 103.0000 - fp: 164.0000 - tn: 199.0000 - fn: 17.0000 - accuracy: 0.6253 - precision: 0.3858 - recall: 0.8583 - auc: 0.7725 - val_loss: 0.6102 - val_tp: 16.0000 - val_fp: 24.0000 - val_tn: 54.0000 - val_fn: 9.0000 - val_accuracy: 0.6796 - val_precision: 0.4000 - val_recall: 0.6400 - val_auc: 0.6787\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8053 - tp: 91.0000 - fp: 117.0000 - tn: 246.0000 - fn: 29.0000 - accuracy: 0.6977 - precision: 0.4375 - recall: 0.7583 - auc: 0.7923 - val_loss: 0.6570 - val_tp: 18.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 7.0000 - val_accuracy: 0.5340 - val_precision: 0.3051 - val_recall: 0.7200 - val_auc: 0.6787\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.8269 - tp: 102.0000 - fp: 151.0000 - tn: 212.0000 - fn: 18.0000 - accuracy: 0.6501 - precision: 0.4032 - recall: 0.8500 - auc: 0.7912 - val_loss: 0.6480 - val_tp: 22.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 3.0000 - val_accuracy: 0.5728 - val_precision: 0.3492 - val_recall: 0.8800 - val_auc: 0.6954\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8373 - tp: 95.0000 - fp: 136.0000 - tn: 227.0000 - fn: 25.0000 - accuracy: 0.6667 - precision: 0.4113 - recall: 0.7917 - auc: 0.8049 - val_loss: 0.6842 - val_tp: 22.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 3.0000 - val_accuracy: 0.5243 - val_precision: 0.3235 - val_recall: 0.8800 - val_auc: 0.6892\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.8281 - tp: 109.0000 - fp: 169.0000 - tn: 194.0000 - fn: 11.0000 - accuracy: 0.6273 - precision: 0.3921 - recall: 0.9083 - auc: 0.7999 - val_loss: 0.6503 - val_tp: 23.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 2.0000 - val_accuracy: 0.5146 - val_precision: 0.3239 - val_recall: 0.9200 - val_auc: 0.6877\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.7817 - tp: 105.0000 - fp: 132.0000 - tn: 231.0000 - fn: 15.0000 - accuracy: 0.6957 - precision: 0.4430 - recall: 0.8750 - auc: 0.8305 - val_loss: 0.6378 - val_tp: 17.0000 - val_fp: 35.0000 - val_tn: 43.0000 - val_fn: 8.0000 - val_accuracy: 0.5825 - val_precision: 0.3269 - val_recall: 0.6800 - val_auc: 0.6003\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.7447 - tp: 100.0000 - fp: 129.0000 - tn: 234.0000 - fn: 20.0000 - accuracy: 0.6915 - precision: 0.4367 - recall: 0.8333 - auc: 0.8261 - val_loss: 0.6453 - val_tp: 19.0000 - val_fp: 40.0000 - val_tn: 38.0000 - val_fn: 6.0000 - val_accuracy: 0.5534 - val_precision: 0.3220 - val_recall: 0.7600 - val_auc: 0.6908\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.7260 - tp: 97.0000 - fp: 93.0000 - tn: 270.0000 - fn: 23.0000 - accuracy: 0.7598 - precision: 0.5105 - recall: 0.8083 - auc: 0.8434 - val_loss: 0.6857 - val_tp: 22.0000 - val_fp: 35.0000 - val_tn: 43.0000 - val_fn: 3.0000 - val_accuracy: 0.6311 - val_precision: 0.3860 - val_recall: 0.8800 - val_auc: 0.8210\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.7468 - tp: 88.0000 - fp: 81.0000 - tn: 282.0000 - fn: 32.0000 - accuracy: 0.7660 - precision: 0.5207 - recall: 0.7333 - auc: 0.8455 - val_loss: 0.6794 - val_tp: 18.0000 - val_fp: 19.0000 - val_tn: 59.0000 - val_fn: 7.0000 - val_accuracy: 0.7476 - val_precision: 0.4865 - val_recall: 0.7200 - val_auc: 0.7359\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 0.7798 - tp: 87.0000 - fp: 101.0000 - tn: 262.0000 - fn: 33.0000 - accuracy: 0.7226 - precision: 0.4628 - recall: 0.7250 - auc: 0.8176 - val_loss: 0.6043 - val_tp: 16.0000 - val_fp: 30.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.6214 - val_precision: 0.3478 - val_recall: 0.6400 - val_auc: 0.6759\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.7737 - tp: 99.0000 - fp: 128.0000 - tn: 235.0000 - fn: 21.0000 - accuracy: 0.6915 - precision: 0.4361 - recall: 0.8250 - auc: 0.8151 - val_loss: 0.5893 - val_tp: 13.0000 - val_fp: 11.0000 - val_tn: 67.0000 - val_fn: 12.0000 - val_accuracy: 0.7767 - val_precision: 0.5417 - val_recall: 0.5200 - val_auc: 0.7256\n",
      "Calculated mean IoU: 0.1502\n",
      "IoU from saved model: 0.5512\n",
      "No Model update.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 20.7476 - tp: 70.0000 - fp: 162.0000 - tn: 279.0000 - fn: 75.0000 - accuracy: 0.5956 - precision: 0.3017 - recall: 0.4828 - auc: 0.5843 - val_loss: 0.6901 - val_tp: 21.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 4.0000 - val_accuracy: 0.5340 - val_precision: 0.3231 - val_recall: 0.8400 - val_auc: 0.6831\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 1.0214 - tp: 53.0000 - fp: 104.0000 - tn: 259.0000 - fn: 67.0000 - accuracy: 0.6460 - precision: 0.3376 - recall: 0.4417 - auc: 0.6155 - val_loss: 0.7096 - val_tp: 25.0000 - val_fp: 68.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3398 - val_precision: 0.2688 - val_recall: 1.0000 - val_auc: 0.6385\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.9755 - tp: 67.0000 - fp: 113.0000 - tn: 250.0000 - fn: 53.0000 - accuracy: 0.6563 - precision: 0.3722 - recall: 0.5583 - auc: 0.6714 - val_loss: 0.6411 - val_tp: 22.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 3.0000 - val_accuracy: 0.5049 - val_precision: 0.3143 - val_recall: 0.8800 - val_auc: 0.6731\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.9265 - tp: 100.0000 - fp: 160.0000 - tn: 203.0000 - fn: 20.0000 - accuracy: 0.6273 - precision: 0.3846 - recall: 0.8333 - auc: 0.7053 - val_loss: 0.6533 - val_tp: 22.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 3.0000 - val_accuracy: 0.5243 - val_precision: 0.3235 - val_recall: 0.8800 - val_auc: 0.6585\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 1.0158 - tp: 110.0000 - fp: 264.0000 - tn: 99.0000 - fn: 10.0000 - accuracy: 0.4327 - precision: 0.2941 - recall: 0.9167 - auc: 0.6409 - val_loss: 0.6591 - val_tp: 22.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 3.0000 - val_accuracy: 0.5049 - val_precision: 0.3143 - val_recall: 0.8800 - val_auc: 0.7259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40\n",
      "16/16 [==============================] - 4s 228ms/step - loss: 0.8978 - tp: 87.0000 - fp: 141.0000 - tn: 222.0000 - fn: 33.0000 - accuracy: 0.6398 - precision: 0.3816 - recall: 0.7250 - auc: 0.7240 - val_loss: 0.6637 - val_tp: 22.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 3.0000 - val_accuracy: 0.5146 - val_precision: 0.3188 - val_recall: 0.8800 - val_auc: 0.6908\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 208ms/step - loss: 0.8970 - tp: 113.0000 - fp: 203.0000 - tn: 160.0000 - fn: 7.0000 - accuracy: 0.5652 - precision: 0.3576 - recall: 0.9417 - auc: 0.7196 - val_loss: 0.6538 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.7110\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8503 - tp: 94.0000 - fp: 143.0000 - tn: 220.0000 - fn: 26.0000 - accuracy: 0.6501 - precision: 0.3966 - recall: 0.7833 - auc: 0.7580 - val_loss: 0.7060 - val_tp: 23.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.3883 - val_precision: 0.2738 - val_recall: 0.9200 - val_auc: 0.6990\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.9239 - tp: 103.0000 - fp: 177.0000 - tn: 186.0000 - fn: 17.0000 - accuracy: 0.5983 - precision: 0.3679 - recall: 0.8583 - auc: 0.7163 - val_loss: 0.6029 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5990\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.8857 - tp: 86.0000 - fp: 135.0000 - tn: 228.0000 - fn: 34.0000 - accuracy: 0.6501 - precision: 0.3891 - recall: 0.7167 - auc: 0.7389 - val_loss: 0.7055 - val_tp: 22.0000 - val_fp: 57.0000 - val_tn: 21.0000 - val_fn: 3.0000 - val_accuracy: 0.4175 - val_precision: 0.2785 - val_recall: 0.8800 - val_auc: 0.7154\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.8463 - tp: 102.0000 - fp: 154.0000 - tn: 209.0000 - fn: 18.0000 - accuracy: 0.6439 - precision: 0.3984 - recall: 0.8500 - auc: 0.7625 - val_loss: 0.6846 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.7026\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.8781 - tp: 94.0000 - fp: 133.0000 - tn: 230.0000 - fn: 26.0000 - accuracy: 0.6708 - precision: 0.4141 - recall: 0.7833 - auc: 0.7555 - val_loss: 0.7100 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.7141\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.8372 - tp: 103.0000 - fp: 155.0000 - tn: 208.0000 - fn: 17.0000 - accuracy: 0.6439 - precision: 0.3992 - recall: 0.8583 - auc: 0.7699 - val_loss: 0.7409 - val_tp: 22.0000 - val_fp: 57.0000 - val_tn: 21.0000 - val_fn: 3.0000 - val_accuracy: 0.4175 - val_precision: 0.2785 - val_recall: 0.8800 - val_auc: 0.7041\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8977 - tp: 101.0000 - fp: 148.0000 - tn: 215.0000 - fn: 19.0000 - accuracy: 0.6542 - precision: 0.4056 - recall: 0.8417 - auc: 0.7431 - val_loss: 0.7674 - val_tp: 24.0000 - val_fp: 64.0000 - val_tn: 14.0000 - val_fn: 1.0000 - val_accuracy: 0.3689 - val_precision: 0.2727 - val_recall: 0.9600 - val_auc: 0.7100\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.9078 - tp: 109.0000 - fp: 190.0000 - tn: 173.0000 - fn: 11.0000 - accuracy: 0.5839 - precision: 0.3645 - recall: 0.9083 - auc: 0.7192 - val_loss: 0.6287 - val_tp: 22.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 3.0000 - val_accuracy: 0.4951 - val_precision: 0.3099 - val_recall: 0.8800 - val_auc: 0.7095\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8941 - tp: 92.0000 - fp: 132.0000 - tn: 231.0000 - fn: 28.0000 - accuracy: 0.6687 - precision: 0.4107 - recall: 0.7667 - auc: 0.7385 - val_loss: 0.7538 - val_tp: 23.0000 - val_fp: 62.0000 - val_tn: 16.0000 - val_fn: 2.0000 - val_accuracy: 0.3786 - val_precision: 0.2706 - val_recall: 0.9200 - val_auc: 0.7156\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8967 - tp: 107.0000 - fp: 193.0000 - tn: 170.0000 - fn: 13.0000 - accuracy: 0.5735 - precision: 0.3567 - recall: 0.8917 - auc: 0.7113 - val_loss: 0.6373 - val_tp: 22.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 3.0000 - val_accuracy: 0.5049 - val_precision: 0.3143 - val_recall: 0.8800 - val_auc: 0.6977\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 210ms/step - loss: 0.8661 - tp: 97.0000 - fp: 171.0000 - tn: 192.0000 - fn: 23.0000 - accuracy: 0.5983 - precision: 0.3619 - recall: 0.8083 - auc: 0.7264 - val_loss: 0.6977 - val_tp: 23.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.3883 - val_precision: 0.2738 - val_recall: 0.9200 - val_auc: 0.7141\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.8052 - tp: 100.0000 - fp: 154.0000 - tn: 209.0000 - fn: 20.0000 - accuracy: 0.6398 - precision: 0.3937 - recall: 0.8333 - auc: 0.7808 - val_loss: 0.6680 - val_tp: 22.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 3.0000 - val_accuracy: 0.5146 - val_precision: 0.3188 - val_recall: 0.8800 - val_auc: 0.6846\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.9001 - tp: 90.0000 - fp: 143.0000 - tn: 220.0000 - fn: 30.0000 - accuracy: 0.6418 - precision: 0.3863 - recall: 0.7500 - auc: 0.7333 - val_loss: 0.6453 - val_tp: 22.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 3.0000 - val_accuracy: 0.5340 - val_precision: 0.3284 - val_recall: 0.8800 - val_auc: 0.6772\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.9175 - tp: 112.0000 - fp: 205.0000 - tn: 158.0000 - fn: 8.0000 - accuracy: 0.5590 - precision: 0.3533 - recall: 0.9333 - auc: 0.7526 - val_loss: 0.6810 - val_tp: 23.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.4175 - val_precision: 0.2840 - val_recall: 0.9200 - val_auc: 0.7269\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9277 - tp: 103.0000 - fp: 186.0000 - tn: 177.0000 - fn: 17.0000 - accuracy: 0.5797 - precision: 0.3564 - recall: 0.8583 - auc: 0.7338 - val_loss: 0.6373 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.7064\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8392 - tp: 95.0000 - fp: 124.0000 - tn: 239.0000 - fn: 25.0000 - accuracy: 0.6915 - precision: 0.4338 - recall: 0.7917 - auc: 0.7800 - val_loss: 0.6754 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.7049\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8213 - tp: 99.0000 - fp: 137.0000 - tn: 226.0000 - fn: 21.0000 - accuracy: 0.6729 - precision: 0.4195 - recall: 0.8250 - auc: 0.7770 - val_loss: 0.6869 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.6936\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8644 - tp: 110.0000 - fp: 186.0000 - tn: 177.0000 - fn: 10.0000 - accuracy: 0.5942 - precision: 0.3716 - recall: 0.9167 - auc: 0.7540 - val_loss: 0.7482 - val_tp: 24.0000 - val_fp: 67.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.3398 - val_precision: 0.2637 - val_recall: 0.9600 - val_auc: 0.7062\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.9708 - tp: 111.0000 - fp: 230.0000 - tn: 133.0000 - fn: 9.0000 - accuracy: 0.5052 - precision: 0.3255 - recall: 0.9250 - auc: 0.7290 - val_loss: 0.6952 - val_tp: 23.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 2.0000 - val_accuracy: 0.4369 - val_precision: 0.2911 - val_recall: 0.9200 - val_auc: 0.7138\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.9042 - tp: 91.0000 - fp: 129.0000 - tn: 234.0000 - fn: 29.0000 - accuracy: 0.6729 - precision: 0.4136 - recall: 0.7583 - auc: 0.7404 - val_loss: 0.6523 - val_tp: 20.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 5.0000 - val_accuracy: 0.4757 - val_precision: 0.2899 - val_recall: 0.8000 - val_auc: 0.7131\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.9124 - tp: 94.0000 - fp: 158.0000 - tn: 205.0000 - fn: 26.0000 - accuracy: 0.6190 - precision: 0.3730 - recall: 0.7833 - auc: 0.7317 - val_loss: 0.6456 - val_tp: 18.0000 - val_fp: 36.0000 - val_tn: 42.0000 - val_fn: 7.0000 - val_accuracy: 0.5825 - val_precision: 0.3333 - val_recall: 0.7200 - val_auc: 0.6974\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.9587 - tp: 73.0000 - fp: 127.0000 - tn: 236.0000 - fn: 47.0000 - accuracy: 0.6398 - precision: 0.3650 - recall: 0.6083 - auc: 0.6800 - val_loss: 0.7156 - val_tp: 23.0000 - val_fp: 60.0000 - val_tn: 18.0000 - val_fn: 2.0000 - val_accuracy: 0.3981 - val_precision: 0.2771 - val_recall: 0.9200 - val_auc: 0.6956\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9652 - tp: 82.0000 - fp: 140.0000 - tn: 223.0000 - fn: 38.0000 - accuracy: 0.6315 - precision: 0.3694 - recall: 0.6833 - auc: 0.7235 - val_loss: 0.7475 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.7203\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.9157 - tp: 89.0000 - fp: 141.0000 - tn: 222.0000 - fn: 31.0000 - accuracy: 0.6439 - precision: 0.3870 - recall: 0.7417 - auc: 0.7299 - val_loss: 0.6771 - val_tp: 20.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 5.0000 - val_accuracy: 0.4757 - val_precision: 0.2899 - val_recall: 0.8000 - val_auc: 0.7174\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.8679 - tp: 101.0000 - fp: 148.0000 - tn: 215.0000 - fn: 19.0000 - accuracy: 0.6542 - precision: 0.4056 - recall: 0.8417 - auc: 0.7632 - val_loss: 0.7502 - val_tp: 23.0000 - val_fp: 59.0000 - val_tn: 19.0000 - val_fn: 2.0000 - val_accuracy: 0.4078 - val_precision: 0.2805 - val_recall: 0.9200 - val_auc: 0.7138\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8906 - tp: 103.0000 - fp: 170.0000 - tn: 193.0000 - fn: 17.0000 - accuracy: 0.6128 - precision: 0.3773 - recall: 0.8583 - auc: 0.7335 - val_loss: 0.6592 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.7269\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.8414 - tp: 101.0000 - fp: 161.0000 - tn: 202.0000 - fn: 19.0000 - accuracy: 0.6273 - precision: 0.3855 - recall: 0.8417 - auc: 0.7553 - val_loss: 0.7087 - val_tp: 23.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 2.0000 - val_accuracy: 0.4563 - val_precision: 0.2987 - val_recall: 0.9200 - val_auc: 0.7169\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8164 - tp: 99.0000 - fp: 145.0000 - tn: 218.0000 - fn: 21.0000 - accuracy: 0.6563 - precision: 0.4057 - recall: 0.8250 - auc: 0.7868 - val_loss: 0.6113 - val_tp: 16.0000 - val_fp: 25.0000 - val_tn: 53.0000 - val_fn: 9.0000 - val_accuracy: 0.6699 - val_precision: 0.3902 - val_recall: 0.6400 - val_auc: 0.7210\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8141 - tp: 95.0000 - fp: 139.0000 - tn: 224.0000 - fn: 25.0000 - accuracy: 0.6605 - precision: 0.4060 - recall: 0.7917 - auc: 0.7682 - val_loss: 0.6750 - val_tp: 18.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 7.0000 - val_accuracy: 0.5340 - val_precision: 0.3051 - val_recall: 0.7200 - val_auc: 0.6910\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.7817 - tp: 104.0000 - fp: 147.0000 - tn: 216.0000 - fn: 16.0000 - accuracy: 0.6625 - precision: 0.4143 - recall: 0.8667 - auc: 0.8056 - val_loss: 0.5879 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 67.0000 - val_fn: 20.0000 - val_accuracy: 0.6990 - val_precision: 0.3125 - val_recall: 0.2000 - val_auc: 0.6918\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.7521 - tp: 102.0000 - fp: 136.0000 - tn: 227.0000 - fn: 18.0000 - accuracy: 0.6812 - precision: 0.4286 - recall: 0.8500 - auc: 0.8058 - val_loss: 0.7072 - val_tp: 23.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 2.0000 - val_accuracy: 0.4854 - val_precision: 0.3108 - val_recall: 0.9200 - val_auc: 0.6964\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.7792 - tp: 102.0000 - fp: 150.0000 - tn: 213.0000 - fn: 18.0000 - accuracy: 0.6522 - precision: 0.4048 - recall: 0.8500 - auc: 0.8018 - val_loss: 0.7351 - val_tp: 21.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 4.0000 - val_accuracy: 0.5437 - val_precision: 0.3281 - val_recall: 0.8400 - val_auc: 0.7036\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.7541 - tp: 104.0000 - fp: 138.0000 - tn: 225.0000 - fn: 16.0000 - accuracy: 0.6812 - precision: 0.4298 - recall: 0.8667 - auc: 0.8222 - val_loss: 0.7167 - val_tp: 21.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 4.0000 - val_accuracy: 0.5437 - val_precision: 0.3281 - val_recall: 0.8400 - val_auc: 0.6962\n",
      "Calculated mean IoU: 0.5544\n",
      "IoU from saved model: 0.5512\n",
      "Model with updated IoU has been saved.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 5s 281ms/step - loss: 18.1292 - tp: 83.0000 - fp: 266.0000 - tn: 175.0000 - fn: 62.0000 - accuracy: 0.4403 - precision: 0.2378 - recall: 0.5724 - auc: 0.4734 - val_loss: 0.6924 - val_tp: 10.0000 - val_fp: 25.0000 - val_tn: 53.0000 - val_fn: 15.0000 - val_accuracy: 0.6117 - val_precision: 0.2857 - val_recall: 0.4000 - val_auc: 0.5449\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 4s 246ms/step - loss: 1.0509 - tp: 20.0000 - fp: 57.0000 - tn: 306.0000 - fn: 100.0000 - accuracy: 0.6749 - precision: 0.2597 - recall: 0.1667 - auc: 0.4605 - val_loss: 0.6920 - val_tp: 11.0000 - val_fp: 24.0000 - val_tn: 54.0000 - val_fn: 14.0000 - val_accuracy: 0.6311 - val_precision: 0.3143 - val_recall: 0.4400 - val_auc: 0.5249\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 1.0583 - tp: 95.0000 - fp: 290.0000 - tn: 73.0000 - fn: 25.0000 - accuracy: 0.3478 - precision: 0.2468 - recall: 0.7917 - auc: 0.5075 - val_loss: 0.6895 - val_tp: 14.0000 - val_fp: 28.0000 - val_tn: 50.0000 - val_fn: 11.0000 - val_accuracy: 0.6214 - val_precision: 0.3333 - val_recall: 0.5600 - val_auc: 0.6305\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 1.0306 - tp: 62.0000 - fp: 152.0000 - tn: 211.0000 - fn: 58.0000 - accuracy: 0.5652 - precision: 0.2897 - recall: 0.5167 - auc: 0.5874 - val_loss: 0.7389 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.5803p: 62.0000 - fp: 152.0000 - tn: 211.0000 - fn: 58.0000 - accuracy: 0.5652 - precision: 0.2897 - recall: 0.5167 - auc: 0.587\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 1.0295 - tp: 115.0000 - fp: 308.0000 - tn: 55.0000 - fn: 5.0000 - accuracy: 0.3520 - precision: 0.2719 - recall: 0.9583 - auc: 0.6186 - val_loss: 0.7093 - val_tp: 23.0000 - val_fp: 64.0000 - val_tn: 14.0000 - val_fn: 2.0000 - val_accuracy: 0.3592 - val_precision: 0.2644 - val_recall: 0.9200 - val_auc: 0.6864\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.9613 - tp: 105.0000 - fp: 190.0000 - tn: 173.0000 - fn: 15.0000 - accuracy: 0.5756 - precision: 0.3559 - recall: 0.8750 - auc: 0.7142 - val_loss: 0.6910 - val_tp: 21.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 4.0000 - val_accuracy: 0.5049 - val_precision: 0.3088 - val_recall: 0.8400 - val_auc: 0.7128\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 203ms/step - loss: 1.0871 - tp: 43.0000 - fp: 77.0000 - tn: 286.0000 - fn: 77.0000 - accuracy: 0.6812 - precision: 0.3583 - recall: 0.3583 - auc: 0.6275 - val_loss: 0.6434 - val_tp: 15.0000 - val_fp: 33.0000 - val_tn: 45.0000 - val_fn: 10.0000 - val_accuracy: 0.5825 - val_precision: 0.3125 - val_recall: 0.6000 - val_auc: 0.6867\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.9605 - tp: 92.0000 - fp: 174.0000 - tn: 189.0000 - fn: 28.0000 - accuracy: 0.5818 - precision: 0.3459 - recall: 0.7667 - auc: 0.6738 - val_loss: 0.7124 - val_tp: 24.0000 - val_fp: 65.0000 - val_tn: 13.0000 - val_fn: 1.0000 - val_accuracy: 0.3592 - val_precision: 0.2697 - val_recall: 0.9600 - val_auc: 0.6710\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.8973 - tp: 101.0000 - fp: 180.0000 - tn: 183.0000 - fn: 19.0000 - accuracy: 0.5880 - precision: 0.3594 - recall: 0.8417 - auc: 0.7128 - val_loss: 0.6872 - val_tp: 22.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 3.0000 - val_accuracy: 0.4078 - val_precision: 0.2750 - val_recall: 0.8800 - val_auc: 0.6754\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.8970 - tp: 104.0000 - fp: 185.0000 - tn: 178.0000 - fn: 16.0000 - accuracy: 0.5839 - precision: 0.3599 - recall: 0.8667 - auc: 0.7391 - val_loss: 0.6507 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.6731\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.8656 - tp: 103.0000 - fp: 156.0000 - tn: 207.0000 - fn: 17.0000 - accuracy: 0.6418 - precision: 0.3977 - recall: 0.8583 - auc: 0.7563 - val_loss: 0.6942 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.6703\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.8468 - tp: 103.0000 - fp: 153.0000 - tn: 210.0000 - fn: 17.0000 - accuracy: 0.6480 - precision: 0.4023 - recall: 0.8583 - auc: 0.7807 - val_loss: 0.6735 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.6644\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.9202 - tp: 102.0000 - fp: 149.0000 - tn: 214.0000 - fn: 18.0000 - accuracy: 0.6542 - precision: 0.4064 - recall: 0.8500 - auc: 0.7463 - val_loss: 0.6237 - val_tp: 18.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 7.0000 - val_accuracy: 0.5631 - val_precision: 0.3214 - val_recall: 0.7200 - val_auc: 0.6259\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.8983 - tp: 98.0000 - fp: 145.0000 - tn: 218.0000 - fn: 22.0000 - accuracy: 0.6542 - precision: 0.4033 - recall: 0.8167 - auc: 0.7636 - val_loss: 0.6380 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.6423\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.8529 - tp: 92.0000 - fp: 121.0000 - tn: 242.0000 - fn: 28.0000 - accuracy: 0.6915 - precision: 0.4319 - recall: 0.7667 - auc: 0.7697 - val_loss: 0.6797 - val_tp: 21.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 4.0000 - val_accuracy: 0.4951 - val_precision: 0.3043 - val_recall: 0.8400 - val_auc: 0.6467\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.9169 - tp: 109.0000 - fp: 201.0000 - tn: 162.0000 - fn: 11.0000 - accuracy: 0.5611 - precision: 0.3516 - recall: 0.9083 - auc: 0.7259 - val_loss: 0.6529 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.6395\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8732 - tp: 100.0000 - fp: 157.0000 - tn: 206.0000 - fn: 20.0000 - accuracy: 0.6335 - precision: 0.3891 - recall: 0.8333 - auc: 0.7573 - val_loss: 0.7337 - val_tp: 24.0000 - val_fp: 63.0000 - val_tn: 15.0000 - val_fn: 1.0000 - val_accuracy: 0.3786 - val_precision: 0.2759 - val_recall: 0.9600 - val_auc: 0.6797\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.9151 - tp: 104.0000 - fp: 192.0000 - tn: 171.0000 - fn: 16.0000 - accuracy: 0.5694 - precision: 0.3514 - recall: 0.8667 - auc: 0.7128 - val_loss: 0.6513 - val_tp: 22.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 3.0000 - val_accuracy: 0.4466 - val_precision: 0.2895 - val_recall: 0.8800 - val_auc: 0.6523\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8526 - tp: 100.0000 - fp: 167.0000 - tn: 196.0000 - fn: 20.0000 - accuracy: 0.6128 - precision: 0.3745 - recall: 0.8333 - auc: 0.7512 - val_loss: 0.6055 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6574\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.8632 - tp: 100.0000 - fp: 152.0000 - tn: 211.0000 - fn: 20.0000 - accuracy: 0.6439 - precision: 0.3968 - recall: 0.8333 - auc: 0.7685 - val_loss: 0.6535 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.6667\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8041 - tp: 104.0000 - fp: 144.0000 - tn: 219.0000 - fn: 16.0000 - accuracy: 0.6687 - precision: 0.4194 - recall: 0.8667 - auc: 0.7952 - val_loss: 0.6566 - val_tp: 20.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 5.0000 - val_accuracy: 0.5437 - val_precision: 0.3226 - val_recall: 0.8000 - val_auc: 0.6633\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8095 - tp: 102.0000 - fp: 139.0000 - tn: 224.0000 - fn: 18.0000 - accuracy: 0.6749 - precision: 0.4232 - recall: 0.8500 - auc: 0.7857 - val_loss: 0.6621 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.6415\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8027 - tp: 111.0000 - fp: 159.0000 - tn: 204.0000 - fn: 9.0000 - accuracy: 0.6522 - precision: 0.4111 - recall: 0.9250 - auc: 0.8030 - val_loss: 0.6396 - val_tp: 20.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 5.0000 - val_accuracy: 0.5340 - val_precision: 0.3175 - val_recall: 0.8000 - val_auc: 0.6582\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8035 - tp: 103.0000 - fp: 142.0000 - tn: 221.0000 - fn: 17.0000 - accuracy: 0.6708 - precision: 0.4204 - recall: 0.8583 - auc: 0.7941 - val_loss: 0.6642 - val_tp: 23.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 2.0000 - val_accuracy: 0.4563 - val_precision: 0.2987 - val_recall: 0.9200 - val_auc: 0.6549\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 0.7961 - tp: 108.0000 - fp: 152.0000 - tn: 211.0000 - fn: 12.0000 - accuracy: 0.6605 - precision: 0.4154 - recall: 0.9000 - auc: 0.8157 - val_loss: 0.6944 - val_tp: 21.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 4.0000 - val_accuracy: 0.4757 - val_precision: 0.2958 - val_recall: 0.8400 - val_auc: 0.6797\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.8280 - tp: 86.0000 - fp: 141.0000 - tn: 222.0000 - fn: 34.0000 - accuracy: 0.6377 - precision: 0.3789 - recall: 0.7167 - auc: 0.7570 - val_loss: 0.6375 - val_tp: 19.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 6.0000 - val_accuracy: 0.5437 - val_precision: 0.3167 - val_recall: 0.7600 - val_auc: 0.6515\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.7740 - tp: 101.0000 - fp: 139.0000 - tn: 224.0000 - fn: 19.0000 - accuracy: 0.6729 - precision: 0.4208 - recall: 0.8417 - auc: 0.8162 - val_loss: 0.6550 - val_tp: 21.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 4.0000 - val_accuracy: 0.5243 - val_precision: 0.3182 - val_recall: 0.8400 - val_auc: 0.6595\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.7922 - tp: 104.0000 - fp: 146.0000 - tn: 217.0000 - fn: 16.0000 - accuracy: 0.6646 - precision: 0.4160 - recall: 0.8667 - auc: 0.8093 - val_loss: 0.6438 - val_tp: 19.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 6.0000 - val_accuracy: 0.5340 - val_precision: 0.3115 - val_recall: 0.7600 - val_auc: 0.6690\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 207ms/step - loss: 0.8530 - tp: 113.0000 - fp: 195.0000 - tn: 168.0000 - fn: 7.0000 - accuracy: 0.5818 - precision: 0.3669 - recall: 0.9417 - auc: 0.7663 - val_loss: 0.6495 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.6487\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8060 - tp: 103.0000 - fp: 114.0000 - tn: 249.0000 - fn: 17.0000 - accuracy: 0.7288 - precision: 0.4747 - recall: 0.8583 - auc: 0.8117 - val_loss: 0.6741 - val_tp: 12.0000 - val_fp: 20.0000 - val_tn: 58.0000 - val_fn: 13.0000 - val_accuracy: 0.6796 - val_precision: 0.3750 - val_recall: 0.4800 - val_auc: 0.6710\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 208ms/step - loss: 0.8367 - tp: 91.0000 - fp: 125.0000 - tn: 238.0000 - fn: 29.0000 - accuracy: 0.6812 - precision: 0.4213 - recall: 0.7583 - auc: 0.7906 - val_loss: 0.7045 - val_tp: 23.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 2.0000 - val_accuracy: 0.4854 - val_precision: 0.3108 - val_recall: 0.9200 - val_auc: 0.6903\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8480 - tp: 83.0000 - fp: 101.0000 - tn: 262.0000 - fn: 37.0000 - accuracy: 0.7143 - precision: 0.4511 - recall: 0.6917 - auc: 0.7802 - val_loss: 0.6469 - val_tp: 18.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 7.0000 - val_accuracy: 0.5631 - val_precision: 0.3214 - val_recall: 0.7200 - val_auc: 0.7077\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9235 - tp: 86.0000 - fp: 138.0000 - tn: 225.0000 - fn: 34.0000 - accuracy: 0.6439 - precision: 0.3839 - recall: 0.7167 - auc: 0.7367 - val_loss: 0.6971 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.7036\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.7530 - tp: 104.0000 - fp: 129.0000 - tn: 234.0000 - fn: 16.0000 - accuracy: 0.6998 - precision: 0.4464 - recall: 0.8667 - auc: 0.8412 - val_loss: 0.6537 - val_tp: 20.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 5.0000 - val_accuracy: 0.5534 - val_precision: 0.3279 - val_recall: 0.8000 - val_auc: 0.6856\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 4s 270ms/step - loss: 0.7321 - tp: 96.0000 - fp: 101.0000 - tn: 262.0000 - fn: 24.0000 - accuracy: 0.7412 - precision: 0.4873 - recall: 0.8000 - auc: 0.8397 - val_loss: 0.6479 - val_tp: 17.0000 - val_fp: 36.0000 - val_tn: 42.0000 - val_fn: 8.0000 - val_accuracy: 0.5728 - val_precision: 0.3208 - val_recall: 0.6800 - val_auc: 0.6815\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.7150 - tp: 103.0000 - fp: 123.0000 - tn: 240.0000 - fn: 17.0000 - accuracy: 0.7101 - precision: 0.4558 - recall: 0.8583 - auc: 0.8515 - val_loss: 0.6202 - val_tp: 14.0000 - val_fp: 28.0000 - val_tn: 50.0000 - val_fn: 11.0000 - val_accuracy: 0.6214 - val_precision: 0.3333 - val_recall: 0.5600 - val_auc: 0.6608\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.7167 - tp: 100.0000 - fp: 117.0000 - tn: 246.0000 - fn: 20.0000 - accuracy: 0.7164 - precision: 0.4608 - recall: 0.8333 - auc: 0.8492 - val_loss: 0.6648 - val_tp: 17.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 8.0000 - val_accuracy: 0.5243 - val_precision: 0.2931 - val_recall: 0.6800 - val_auc: 0.6323\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.7238 - tp: 92.0000 - fp: 91.0000 - tn: 272.0000 - fn: 28.0000 - accuracy: 0.7536 - precision: 0.5027 - recall: 0.7667 - auc: 0.8470 - val_loss: 0.6509 - val_tp: 16.0000 - val_fp: 32.0000 - val_tn: 46.0000 - val_fn: 9.0000 - val_accuracy: 0.6019 - val_precision: 0.3333 - val_recall: 0.6400 - val_auc: 0.6410\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.6933 - tp: 105.0000 - fp: 112.0000 - tn: 251.0000 - fn: 15.0000 - accuracy: 0.7371 - precision: 0.4839 - recall: 0.8750 - auc: 0.8590 - val_loss: 0.6294 - val_tp: 16.0000 - val_fp: 31.0000 - val_tn: 47.0000 - val_fn: 9.0000 - val_accuracy: 0.6117 - val_precision: 0.3404 - val_recall: 0.6400 - val_auc: 0.6482\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.6761 - tp: 92.0000 - fp: 100.0000 - tn: 263.0000 - fn: 28.0000 - accuracy: 0.7350 - precision: 0.4792 - recall: 0.7667 - auc: 0.8622 - val_loss: 0.7301 - val_tp: 21.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 4.0000 - val_accuracy: 0.5922 - val_precision: 0.3559 - val_recall: 0.8400 - val_auc: 0.6787\n",
      "Calculated mean IoU: 0.5519\n",
      "IoU from saved model: 0.5544\n",
      "No Model update.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 5s 288ms/step - loss: 24.0786 - tp: 96.0000 - fp: 256.0000 - tn: 185.0000 - fn: 49.0000 - accuracy: 0.4795 - precision: 0.2727 - recall: 0.6621 - auc: 0.5430 - val_loss: 0.6956 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.4526\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 1.0419 - tp: 74.0000 - fp: 234.0000 - tn: 129.0000 - fn: 46.0000 - accuracy: 0.4203 - precision: 0.2403 - recall: 0.6167 - auc: 0.5083 - val_loss: 0.6919 - val_tp: 0.0000e+00 - val_fp: 6.0000 - val_tn: 72.0000 - val_fn: 25.0000 - val_accuracy: 0.6990 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5064\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 1.0426 - tp: 40.0000 - fp: 112.0000 - tn: 251.0000 - fn: 80.0000 - accuracy: 0.6025 - precision: 0.2632 - recall: 0.3333 - auc: 0.5145 - val_loss: 0.6854 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5972\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 1.0402 - tp: 100.0000 - fp: 297.0000 - tn: 66.0000 - fn: 20.0000 - accuracy: 0.3437 - precision: 0.2519 - recall: 0.8333 - auc: 0.5521 - val_loss: 0.6936 - val_tp: 20.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 5.0000 - val_accuracy: 0.4272 - val_precision: 0.2703 - val_recall: 0.8000 - val_auc: 0.5844\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0386 - tp: 7.0000 - fp: 25.0000 - tn: 338.0000 - fn: 113.0000 - accuracy: 0.7143 - precision: 0.2188 - recall: 0.0583 - auc: 0.5143 - val_loss: 0.6797 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5662\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0258 - tp: 14.0000 - fp: 31.0000 - tn: 332.0000 - fn: 106.0000 - accuracy: 0.7164 - precision: 0.3111 - recall: 0.1167 - auc: 0.6344 - val_loss: 0.6790 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5833\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.9943 - tp: 60.0000 - fp: 115.0000 - tn: 248.0000 - fn: 60.0000 - accuracy: 0.6377 - precision: 0.3429 - recall: 0.5000 - auc: 0.6768 - val_loss: 0.6226 - val_tp: 22.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 3.0000 - val_accuracy: 0.5146 - val_precision: 0.3188 - val_recall: 0.8800 - val_auc: 0.6390\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 193ms/step - loss: 0.9361 - tp: 105.0000 - fp: 177.0000 - tn: 186.0000 - fn: 15.0000 - accuracy: 0.6025 - precision: 0.3723 - recall: 0.8750 - auc: 0.6969 - val_loss: 0.6451 - val_tp: 23.0000 - val_fp: 59.0000 - val_tn: 19.0000 - val_fn: 2.0000 - val_accuracy: 0.4078 - val_precision: 0.2805 - val_recall: 0.9200 - val_auc: 0.6100\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9545 - tp: 106.0000 - fp: 207.0000 - tn: 156.0000 - fn: 14.0000 - accuracy: 0.5424 - precision: 0.3387 - recall: 0.8833 - auc: 0.6591 - val_loss: 0.7283 - val_tp: 25.0000 - val_fp: 77.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2524 - val_precision: 0.2451 - val_recall: 1.0000 - val_auc: 0.5256\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 1.0459 - tp: 120.0000 - fp: 363.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2484 - precision: 0.2484 - recall: 1.0000 - auc: 0.4773 - val_loss: 0.7298 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.5064\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 1.0456 - tp: 120.0000 - fp: 363.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2484 - precision: 0.2484 - recall: 1.0000 - auc: 0.4632 - val_loss: 0.7165 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 4s 229ms/step - loss: 1.0434 - tp: 64.0000 - fp: 196.0000 - tn: 167.0000 - fn: 56.0000 - accuracy: 0.4783 - precision: 0.2462 - recall: 0.5333 - auc: 0.5158 - val_loss: 0.7037 - val_tp: 24.0000 - val_fp: 68.0000 - val_tn: 10.0000 - val_fn: 1.0000 - val_accuracy: 0.3301 - val_precision: 0.2609 - val_recall: 0.9600 - val_auc: 0.6279\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 1.0171 - tp: 96.0000 - fp: 223.0000 - tn: 140.0000 - fn: 24.0000 - accuracy: 0.4886 - precision: 0.3009 - recall: 0.8000 - auc: 0.6132 - val_loss: 0.6702 - val_tp: 15.0000 - val_fp: 27.0000 - val_tn: 51.0000 - val_fn: 10.0000 - val_accuracy: 0.6408 - val_precision: 0.3571 - val_recall: 0.6000 - val_auc: 0.6597\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.9938 - tp: 79.0000 - fp: 171.0000 - tn: 192.0000 - fn: 41.0000 - accuracy: 0.5611 - precision: 0.3160 - recall: 0.6583 - auc: 0.6611 - val_loss: 0.6940 - val_tp: 22.0000 - val_fp: 62.0000 - val_tn: 16.0000 - val_fn: 3.0000 - val_accuracy: 0.3689 - val_precision: 0.2619 - val_recall: 0.8800 - val_auc: 0.6041\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 1.0386 - tp: 64.0000 - fp: 165.0000 - tn: 198.0000 - fn: 56.0000 - accuracy: 0.5424 - precision: 0.2795 - recall: 0.5333 - auc: 0.5514 - val_loss: 0.6976 - val_tp: 25.0000 - val_fp: 77.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2524 - val_precision: 0.2451 - val_recall: 1.0000 - val_auc: 0.5064\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 1.0329 - tp: 43.0000 - fp: 104.0000 - tn: 259.0000 - fn: 77.0000 - accuracy: 0.6253 - precision: 0.2925 - recall: 0.3583 - auc: 0.5837 - val_loss: 0.6934 - val_tp: 24.0000 - val_fp: 59.0000 - val_tn: 19.0000 - val_fn: 1.0000 - val_accuracy: 0.4175 - val_precision: 0.2892 - val_recall: 0.9600 - val_auc: 0.6338\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 1.0225 - tp: 27.0000 - fp: 40.0000 - tn: 323.0000 - fn: 93.0000 - accuracy: 0.7246 - precision: 0.4030 - recall: 0.2250 - auc: 0.6648 - val_loss: 0.6912 - val_tp: 24.0000 - val_fp: 67.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.3398 - val_precision: 0.2637 - val_recall: 0.9600 - val_auc: 0.5831\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0277 - tp: 100.0000 - fp: 251.0000 - tn: 112.0000 - fn: 20.0000 - accuracy: 0.4389 - precision: 0.2849 - recall: 0.8333 - auc: 0.5908 - val_loss: 0.6773 - val_tp: 23.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 2.0000 - val_accuracy: 0.4369 - val_precision: 0.2911 - val_recall: 0.9200 - val_auc: 0.7082\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 207ms/step - loss: 1.0063 - tp: 86.0000 - fp: 191.0000 - tn: 172.0000 - fn: 34.0000 - accuracy: 0.5342 - precision: 0.3105 - recall: 0.7167 - auc: 0.6046 - val_loss: 0.7080 - val_tp: 25.0000 - val_fp: 69.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3301 - val_precision: 0.2660 - val_recall: 1.0000 - val_auc: 0.5662\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.9903 - tp: 92.0000 - fp: 188.0000 - tn: 175.0000 - fn: 28.0000 - accuracy: 0.5528 - precision: 0.3286 - recall: 0.7667 - auc: 0.6670 - val_loss: 0.6976 - val_tp: 24.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 1.0000 - val_accuracy: 0.3981 - val_precision: 0.2824 - val_recall: 0.9600 - val_auc: 0.6472\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.9373 - tp: 92.0000 - fp: 149.0000 - tn: 214.0000 - fn: 28.0000 - accuracy: 0.6335 - precision: 0.3817 - recall: 0.7667 - auc: 0.7114 - val_loss: 0.7326 - val_tp: 23.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.3883 - val_precision: 0.2738 - val_recall: 0.9200 - val_auc: 0.6764\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.9603 - tp: 99.0000 - fp: 191.0000 - tn: 172.0000 - fn: 21.0000 - accuracy: 0.5611 - precision: 0.3414 - recall: 0.8250 - auc: 0.6833 - val_loss: 0.7033 - val_tp: 22.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.4369 - val_precision: 0.2857 - val_recall: 0.8800 - val_auc: 0.6892\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.9234 - tp: 95.0000 - fp: 159.0000 - tn: 204.0000 - fn: 25.0000 - accuracy: 0.6190 - precision: 0.3740 - recall: 0.7917 - auc: 0.7204 - val_loss: 0.5983 - val_tp: 8.0000 - val_fp: 3.0000 - val_tn: 75.0000 - val_fn: 17.0000 - val_accuracy: 0.8058 - val_precision: 0.7273 - val_recall: 0.3200 - val_auc: 0.6674\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.8825 - tp: 86.0000 - fp: 134.0000 - tn: 229.0000 - fn: 34.0000 - accuracy: 0.6522 - precision: 0.3909 - recall: 0.7167 - auc: 0.7457 - val_loss: 0.6714 - val_tp: 18.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 7.0000 - val_accuracy: 0.5340 - val_precision: 0.3051 - val_recall: 0.7200 - val_auc: 0.6997\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.9041 - tp: 90.0000 - fp: 128.0000 - tn: 235.0000 - fn: 30.0000 - accuracy: 0.6729 - precision: 0.4128 - recall: 0.7500 - auc: 0.7425 - val_loss: 0.6411 - val_tp: 22.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 3.0000 - val_accuracy: 0.5146 - val_precision: 0.3188 - val_recall: 0.8800 - val_auc: 0.6759\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 208ms/step - loss: 0.8825 - tp: 102.0000 - fp: 170.0000 - tn: 193.0000 - fn: 18.0000 - accuracy: 0.6108 - precision: 0.3750 - recall: 0.8500 - auc: 0.7478 - val_loss: 0.7015 - val_tp: 22.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 3.0000 - val_accuracy: 0.4466 - val_precision: 0.2895 - val_recall: 0.8800 - val_auc: 0.6908\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.9334 - tp: 92.0000 - fp: 161.0000 - tn: 202.0000 - fn: 28.0000 - accuracy: 0.6087 - precision: 0.3636 - recall: 0.7667 - auc: 0.7108 - val_loss: 0.6782 - val_tp: 19.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 6.0000 - val_accuracy: 0.4563 - val_precision: 0.2754 - val_recall: 0.7600 - val_auc: 0.6654\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.9092 - tp: 109.0000 - fp: 204.0000 - tn: 159.0000 - fn: 11.0000 - accuracy: 0.5549 - precision: 0.3482 - recall: 0.9083 - auc: 0.7394 - val_loss: 0.6750 - val_tp: 18.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 7.0000 - val_accuracy: 0.4854 - val_precision: 0.2812 - val_recall: 0.7200 - val_auc: 0.6890\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.9153 - tp: 88.0000 - fp: 140.0000 - tn: 223.0000 - fn: 32.0000 - accuracy: 0.6439 - precision: 0.3860 - recall: 0.7333 - auc: 0.7376 - val_loss: 0.6298 - val_tp: 18.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 7.0000 - val_accuracy: 0.5728 - val_precision: 0.3273 - val_recall: 0.7200 - val_auc: 0.7041\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.8242 - tp: 103.0000 - fp: 135.0000 - tn: 228.0000 - fn: 17.0000 - accuracy: 0.6853 - precision: 0.4328 - recall: 0.8583 - auc: 0.7887 - val_loss: 0.6588 - val_tp: 18.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 7.0000 - val_accuracy: 0.5146 - val_precision: 0.2951 - val_recall: 0.7200 - val_auc: 0.6910\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 210ms/step - loss: 0.8610 - tp: 95.0000 - fp: 136.0000 - tn: 227.0000 - fn: 25.0000 - accuracy: 0.6667 - precision: 0.4113 - recall: 0.7917 - auc: 0.7759 - val_loss: 0.6802 - val_tp: 19.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 6.0000 - val_accuracy: 0.4757 - val_precision: 0.2836 - val_recall: 0.7600 - val_auc: 0.6885\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8391 - tp: 102.0000 - fp: 136.0000 - tn: 227.0000 - fn: 18.0000 - accuracy: 0.6812 - precision: 0.4286 - recall: 0.8500 - auc: 0.7792 - val_loss: 0.6253 - val_tp: 18.0000 - val_fp: 35.0000 - val_tn: 43.0000 - val_fn: 7.0000 - val_accuracy: 0.5922 - val_precision: 0.3396 - val_recall: 0.7200 - val_auc: 0.7000\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.9070 - tp: 100.0000 - fp: 163.0000 - tn: 200.0000 - fn: 20.0000 - accuracy: 0.6211 - precision: 0.3802 - recall: 0.8333 - auc: 0.7326 - val_loss: 0.6563 - val_tp: 20.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 5.0000 - val_accuracy: 0.5146 - val_precision: 0.3077 - val_recall: 0.8000 - val_auc: 0.6903\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 211ms/step - loss: 0.8085 - tp: 100.0000 - fp: 128.0000 - tn: 235.0000 - fn: 20.0000 - accuracy: 0.6936 - precision: 0.4386 - recall: 0.8333 - auc: 0.7902 - val_loss: 0.6433 - val_tp: 18.0000 - val_fp: 36.0000 - val_tn: 42.0000 - val_fn: 7.0000 - val_accuracy: 0.5825 - val_precision: 0.3333 - val_recall: 0.7200 - val_auc: 0.7185\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.8772 - tp: 99.0000 - fp: 138.0000 - tn: 225.0000 - fn: 21.0000 - accuracy: 0.6708 - precision: 0.4177 - recall: 0.8250 - auc: 0.7621 - val_loss: 0.6839 - val_tp: 19.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 6.0000 - val_accuracy: 0.4951 - val_precision: 0.2923 - val_recall: 0.7600 - val_auc: 0.7008\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 4s 231ms/step - loss: 0.8335 - tp: 95.0000 - fp: 136.0000 - tn: 227.0000 - fn: 25.0000 - accuracy: 0.6667 - precision: 0.4113 - recall: 0.7917 - auc: 0.7854 - val_loss: 0.6278 - val_tp: 18.0000 - val_fp: 34.0000 - val_tn: 44.0000 - val_fn: 7.0000 - val_accuracy: 0.6019 - val_precision: 0.3462 - val_recall: 0.7200 - val_auc: 0.7095\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.8291 - tp: 96.0000 - fp: 132.0000 - tn: 231.0000 - fn: 24.0000 - accuracy: 0.6770 - precision: 0.4211 - recall: 0.8000 - auc: 0.7774 - val_loss: 0.6452 - val_tp: 18.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 7.0000 - val_accuracy: 0.5146 - val_precision: 0.2951 - val_recall: 0.7200 - val_auc: 0.7190\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.7968 - tp: 97.0000 - fp: 135.0000 - tn: 228.0000 - fn: 23.0000 - accuracy: 0.6729 - precision: 0.4181 - recall: 0.8083 - auc: 0.7967 - val_loss: 0.6127 - val_tp: 17.0000 - val_fp: 30.0000 - val_tn: 48.0000 - val_fn: 8.0000 - val_accuracy: 0.6311 - val_precision: 0.3617 - val_recall: 0.6800 - val_auc: 0.7187\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.7917 - tp: 100.0000 - fp: 130.0000 - tn: 233.0000 - fn: 20.0000 - accuracy: 0.6894 - precision: 0.4348 - recall: 0.8333 - auc: 0.7919 - val_loss: 0.6703 - val_tp: 19.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 6.0000 - val_accuracy: 0.5437 - val_precision: 0.3167 - val_recall: 0.7600 - val_auc: 0.7126\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.8244 - tp: 102.0000 - fp: 145.0000 - tn: 218.0000 - fn: 18.0000 - accuracy: 0.6625 - precision: 0.4130 - recall: 0.8500 - auc: 0.7780 - val_loss: 0.6868 - val_tp: 18.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 7.0000 - val_accuracy: 0.5049 - val_precision: 0.2903 - val_recall: 0.7200 - val_auc: 0.6892\n",
      "Calculated mean IoU: 0.0169\n",
      "IoU from saved model: 0.5544\n",
      "No Model update.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 4s 279ms/step - loss: 16.0523 - tp: 80.0000 - fp: 186.0000 - tn: 255.0000 - fn: 65.0000 - accuracy: 0.5717 - precision: 0.3008 - recall: 0.5517 - auc: 0.5579 - val_loss: 0.7332 - val_tp: 25.0000 - val_fp: 71.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3107 - val_precision: 0.2604 - val_recall: 1.0000 - val_auc: 0.7026\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.9698 - tp: 89.0000 - fp: 162.0000 - tn: 201.0000 - fn: 31.0000 - accuracy: 0.6004 - precision: 0.3546 - recall: 0.7417 - auc: 0.6946 - val_loss: 0.6965 - val_tp: 23.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.3883 - val_precision: 0.2738 - val_recall: 0.9200 - val_auc: 0.6897\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.9055 - tp: 84.0000 - fp: 157.0000 - tn: 206.0000 - fn: 36.0000 - accuracy: 0.6004 - precision: 0.3485 - recall: 0.7000 - auc: 0.7230 - val_loss: 0.6733 - val_tp: 23.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.4175 - val_precision: 0.2840 - val_recall: 0.9200 - val_auc: 0.7308\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.9514 - tp: 105.0000 - fp: 185.0000 - tn: 178.0000 - fn: 15.0000 - accuracy: 0.5859 - precision: 0.3621 - recall: 0.8750 - auc: 0.7220 - val_loss: 0.6621 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.7182\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.8778 - tp: 99.0000 - fp: 153.0000 - tn: 210.0000 - fn: 21.0000 - accuracy: 0.6398 - precision: 0.3929 - recall: 0.8250 - auc: 0.7567 - val_loss: 0.6380 - val_tp: 21.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 4.0000 - val_accuracy: 0.5825 - val_precision: 0.3500 - val_recall: 0.8400 - val_auc: 0.6956\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.9222 - tp: 94.0000 - fp: 158.0000 - tn: 205.0000 - fn: 26.0000 - accuracy: 0.6190 - precision: 0.3730 - recall: 0.7833 - auc: 0.7136 - val_loss: 0.7577 - val_tp: 23.0000 - val_fp: 64.0000 - val_tn: 14.0000 - val_fn: 2.0000 - val_accuracy: 0.3592 - val_precision: 0.2644 - val_recall: 0.9200 - val_auc: 0.6762\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.9546 - tp: 83.0000 - fp: 152.0000 - tn: 211.0000 - fn: 37.0000 - accuracy: 0.6087 - precision: 0.3532 - recall: 0.6917 - auc: 0.6804 - val_loss: 0.6104 - val_tp: 19.0000 - val_fp: 35.0000 - val_tn: 43.0000 - val_fn: 6.0000 - val_accuracy: 0.6019 - val_precision: 0.3519 - val_recall: 0.7600 - val_auc: 0.6651\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.9967 - tp: 108.0000 - fp: 263.0000 - tn: 100.0000 - fn: 12.0000 - accuracy: 0.4306 - precision: 0.2911 - recall: 0.9000 - auc: 0.6314 - val_loss: 0.7124 - val_tp: 25.0000 - val_fp: 74.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2816 - val_precision: 0.2525 - val_recall: 1.0000 - val_auc: 0.6359\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 1.0176 - tp: 89.0000 - fp: 217.0000 - tn: 146.0000 - fn: 31.0000 - accuracy: 0.4865 - precision: 0.2908 - recall: 0.7417 - auc: 0.6365 - val_loss: 0.6887 - val_tp: 18.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 7.0000 - val_accuracy: 0.5534 - val_precision: 0.3158 - val_recall: 0.7200 - val_auc: 0.6182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.9808 - tp: 104.0000 - fp: 212.0000 - tn: 151.0000 - fn: 16.0000 - accuracy: 0.5280 - precision: 0.3291 - recall: 0.8667 - auc: 0.6985 - val_loss: 0.6225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6972\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 1.0115 - tp: 79.0000 - fp: 171.0000 - tn: 192.0000 - fn: 41.0000 - accuracy: 0.5611 - precision: 0.3160 - recall: 0.6583 - auc: 0.6633 - val_loss: 0.6159 - val_tp: 19.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 6.0000 - val_accuracy: 0.5728 - val_precision: 0.3333 - val_recall: 0.7600 - val_auc: 0.7136\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.8982 - tp: 109.0000 - fp: 203.0000 - tn: 160.0000 - fn: 11.0000 - accuracy: 0.5569 - precision: 0.3494 - recall: 0.9083 - auc: 0.7510 - val_loss: 0.6121 - val_tp: 2.0000 - val_fp: 5.0000 - val_tn: 73.0000 - val_fn: 23.0000 - val_accuracy: 0.7282 - val_precision: 0.2857 - val_recall: 0.0800 - val_auc: 0.7095\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8843 - tp: 92.0000 - fp: 146.0000 - tn: 217.0000 - fn: 28.0000 - accuracy: 0.6398 - precision: 0.3866 - recall: 0.7667 - auc: 0.7332 - val_loss: 0.6597 - val_tp: 22.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 3.0000 - val_accuracy: 0.5049 - val_precision: 0.3143 - val_recall: 0.8800 - val_auc: 0.7123\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8708 - tp: 101.0000 - fp: 154.0000 - tn: 209.0000 - fn: 19.0000 - accuracy: 0.6418 - precision: 0.3961 - recall: 0.8417 - auc: 0.7633 - val_loss: 0.6736 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.7018\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 208ms/step - loss: 0.8874 - tp: 110.0000 - fp: 205.0000 - tn: 158.0000 - fn: 10.0000 - accuracy: 0.5549 - precision: 0.3492 - recall: 0.9167 - auc: 0.7622 - val_loss: 0.6526 - val_tp: 21.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 4.0000 - val_accuracy: 0.4951 - val_precision: 0.3043 - val_recall: 0.8400 - val_auc: 0.7113\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.8731 - tp: 94.0000 - fp: 138.0000 - tn: 225.0000 - fn: 26.0000 - accuracy: 0.6605 - precision: 0.4052 - recall: 0.7833 - auc: 0.7514 - val_loss: 0.6077 - val_tp: 14.0000 - val_fp: 21.0000 - val_tn: 57.0000 - val_fn: 11.0000 - val_accuracy: 0.6893 - val_precision: 0.4000 - val_recall: 0.5600 - val_auc: 0.7174\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.8871 - tp: 95.0000 - fp: 157.0000 - tn: 206.0000 - fn: 25.0000 - accuracy: 0.6232 - precision: 0.3770 - recall: 0.7917 - auc: 0.7301 - val_loss: 0.6187 - val_tp: 20.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.5728 - val_precision: 0.3390 - val_recall: 0.8000 - val_auc: 0.7046\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.8816 - tp: 76.0000 - fp: 95.0000 - tn: 268.0000 - fn: 44.0000 - accuracy: 0.7122 - precision: 0.4444 - recall: 0.6333 - auc: 0.7675 - val_loss: 0.6059 - val_tp: 11.0000 - val_fp: 12.0000 - val_tn: 66.0000 - val_fn: 14.0000 - val_accuracy: 0.7476 - val_precision: 0.4783 - val_recall: 0.4400 - val_auc: 0.7033\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.8610 - tp: 102.0000 - fp: 145.0000 - tn: 218.0000 - fn: 18.0000 - accuracy: 0.6625 - precision: 0.4130 - recall: 0.8500 - auc: 0.7684 - val_loss: 0.6453 - val_tp: 22.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 3.0000 - val_accuracy: 0.5049 - val_precision: 0.3143 - val_recall: 0.8800 - val_auc: 0.7174\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8147 - tp: 102.0000 - fp: 148.0000 - tn: 215.0000 - fn: 18.0000 - accuracy: 0.6563 - precision: 0.4080 - recall: 0.8500 - auc: 0.7930 - val_loss: 0.5862 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 68.0000 - val_fn: 17.0000 - val_accuracy: 0.7379 - val_precision: 0.4444 - val_recall: 0.3200 - val_auc: 0.7221\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8725 - tp: 90.0000 - fp: 149.0000 - tn: 214.0000 - fn: 30.0000 - accuracy: 0.6294 - precision: 0.3766 - recall: 0.7500 - auc: 0.7455 - val_loss: 0.6723 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.6954\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8676 - tp: 98.0000 - fp: 137.0000 - tn: 226.0000 - fn: 22.0000 - accuracy: 0.6708 - precision: 0.4170 - recall: 0.8167 - auc: 0.7552 - val_loss: 0.6494 - val_tp: 21.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 4.0000 - val_accuracy: 0.5922 - val_precision: 0.3559 - val_recall: 0.8400 - val_auc: 0.6513\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.8025 - tp: 105.0000 - fp: 152.0000 - tn: 211.0000 - fn: 15.0000 - accuracy: 0.6542 - precision: 0.4086 - recall: 0.8750 - auc: 0.7930 - val_loss: 0.6678 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.6903\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8516 - tp: 101.0000 - fp: 146.0000 - tn: 217.0000 - fn: 19.0000 - accuracy: 0.6584 - precision: 0.4089 - recall: 0.8417 - auc: 0.7803 - val_loss: 0.6803 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.6882\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8557 - tp: 97.0000 - fp: 157.0000 - tn: 206.0000 - fn: 23.0000 - accuracy: 0.6273 - precision: 0.3819 - recall: 0.8083 - auc: 0.7595 - val_loss: 0.6241 - val_tp: 21.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 4.0000 - val_accuracy: 0.6019 - val_precision: 0.3621 - val_recall: 0.8400 - val_auc: 0.6841\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.8196 - tp: 103.0000 - fp: 161.0000 - tn: 202.0000 - fn: 17.0000 - accuracy: 0.6315 - precision: 0.3902 - recall: 0.8583 - auc: 0.7737 - val_loss: 0.6205 - val_tp: 16.0000 - val_fp: 31.0000 - val_tn: 47.0000 - val_fn: 9.0000 - val_accuracy: 0.6117 - val_precision: 0.3404 - val_recall: 0.6400 - val_auc: 0.6669\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8065 - tp: 100.0000 - fp: 141.0000 - tn: 222.0000 - fn: 20.0000 - accuracy: 0.6667 - precision: 0.4149 - recall: 0.8333 - auc: 0.7749 - val_loss: 0.6381 - val_tp: 21.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 4.0000 - val_accuracy: 0.5340 - val_precision: 0.3231 - val_recall: 0.8400 - val_auc: 0.6774\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8229 - tp: 97.0000 - fp: 140.0000 - tn: 223.0000 - fn: 23.0000 - accuracy: 0.6625 - precision: 0.4093 - recall: 0.8083 - auc: 0.7964 - val_loss: 0.6490 - val_tp: 21.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 4.0000 - val_accuracy: 0.5146 - val_precision: 0.3134 - val_recall: 0.8400 - val_auc: 0.6969\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8282 - tp: 110.0000 - fp: 165.0000 - tn: 198.0000 - fn: 10.0000 - accuracy: 0.6377 - precision: 0.4000 - recall: 0.9167 - auc: 0.7964 - val_loss: 0.7050 - val_tp: 24.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 1.0000 - val_accuracy: 0.3981 - val_precision: 0.2824 - val_recall: 0.9600 - val_auc: 0.7018\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8730 - tp: 93.0000 - fp: 140.0000 - tn: 223.0000 - fn: 27.0000 - accuracy: 0.6542 - precision: 0.3991 - recall: 0.7750 - auc: 0.7478 - val_loss: 0.6713 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.7415\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.8008 - tp: 102.0000 - fp: 155.0000 - tn: 208.0000 - fn: 18.0000 - accuracy: 0.6418 - precision: 0.3969 - recall: 0.8500 - auc: 0.7872 - val_loss: 0.6491 - val_tp: 11.0000 - val_fp: 15.0000 - val_tn: 63.0000 - val_fn: 14.0000 - val_accuracy: 0.7184 - val_precision: 0.4231 - val_recall: 0.4400 - val_auc: 0.6946\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.7746 - tp: 107.0000 - fp: 156.0000 - tn: 207.0000 - fn: 13.0000 - accuracy: 0.6501 - precision: 0.4068 - recall: 0.8917 - auc: 0.8128 - val_loss: 0.7211 - val_tp: 14.0000 - val_fp: 11.0000 - val_tn: 67.0000 - val_fn: 11.0000 - val_accuracy: 0.7864 - val_precision: 0.5600 - val_recall: 0.5600 - val_auc: 0.7397\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.9011 - tp: 65.0000 - fp: 90.0000 - tn: 273.0000 - fn: 55.0000 - accuracy: 0.6998 - precision: 0.4194 - recall: 0.5417 - auc: 0.7545 - val_loss: 0.6569 - val_tp: 20.0000 - val_fp: 40.0000 - val_tn: 38.0000 - val_fn: 5.0000 - val_accuracy: 0.5631 - val_precision: 0.3333 - val_recall: 0.8000 - val_auc: 0.7305\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.7830 - tp: 108.0000 - fp: 146.0000 - tn: 217.0000 - fn: 12.0000 - accuracy: 0.6729 - precision: 0.4252 - recall: 0.9000 - auc: 0.8145 - val_loss: 0.6172 - val_tp: 20.0000 - val_fp: 30.0000 - val_tn: 48.0000 - val_fn: 5.0000 - val_accuracy: 0.6602 - val_precision: 0.4000 - val_recall: 0.8000 - val_auc: 0.7595\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.7576 - tp: 97.0000 - fp: 122.0000 - tn: 241.0000 - fn: 23.0000 - accuracy: 0.6998 - precision: 0.4429 - recall: 0.8083 - auc: 0.8144 - val_loss: 0.6051 - val_tp: 18.0000 - val_fp: 28.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.6602 - val_precision: 0.3913 - val_recall: 0.7200 - val_auc: 0.7656\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.7586 - tp: 99.0000 - fp: 115.0000 - tn: 248.0000 - fn: 21.0000 - accuracy: 0.7184 - precision: 0.4626 - recall: 0.8250 - auc: 0.8375 - val_loss: 0.6698 - val_tp: 22.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 3.0000 - val_accuracy: 0.5631 - val_precision: 0.3438 - val_recall: 0.8800 - val_auc: 0.7682\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.6978 - tp: 95.0000 - fp: 99.0000 - tn: 264.0000 - fn: 25.0000 - accuracy: 0.7433 - precision: 0.4897 - recall: 0.7917 - auc: 0.8460 - val_loss: 0.6876 - val_tp: 22.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 3.0000 - val_accuracy: 0.5631 - val_precision: 0.3438 - val_recall: 0.8800 - val_auc: 0.7692\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.7016 - tp: 106.0000 - fp: 114.0000 - tn: 249.0000 - fn: 14.0000 - accuracy: 0.7350 - precision: 0.4818 - recall: 0.8833 - auc: 0.8565 - val_loss: 0.6794 - val_tp: 22.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 3.0000 - val_accuracy: 0.5922 - val_precision: 0.3607 - val_recall: 0.8800 - val_auc: 0.7949\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.6969 - tp: 98.0000 - fp: 100.0000 - tn: 263.0000 - fn: 22.0000 - accuracy: 0.7474 - precision: 0.4949 - recall: 0.8167 - auc: 0.8505 - val_loss: 0.6853 - val_tp: 18.0000 - val_fp: 30.0000 - val_tn: 48.0000 - val_fn: 7.0000 - val_accuracy: 0.6408 - val_precision: 0.3750 - val_recall: 0.7200 - val_auc: 0.7549\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.7058 - tp: 101.0000 - fp: 97.0000 - tn: 266.0000 - fn: 19.0000 - accuracy: 0.7598 - precision: 0.5101 - recall: 0.8417 - auc: 0.8622 - val_loss: 0.7867 - val_tp: 23.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 2.0000 - val_accuracy: 0.5631 - val_precision: 0.3485 - val_recall: 0.9200 - val_auc: 0.7808\n",
      "Calculated mean IoU: 0.5850\n",
      "IoU from saved model: 0.5544\n",
      "Model with updated IoU has been saved.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 4s 274ms/step - loss: 58.1653 - tp: 61.0000 - fp: 148.0000 - tn: 293.0000 - fn: 84.0000 - accuracy: 0.6041 - precision: 0.2919 - recall: 0.4207 - auc: 0.5283 - val_loss: 0.6808 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5508\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 1.0451 - tp: 41.0000 - fp: 121.0000 - tn: 242.0000 - fn: 79.0000 - accuracy: 0.5859 - precision: 0.2531 - recall: 0.3417 - auc: 0.5010 - val_loss: 0.7342 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.6613\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 1.0523 - tp: 64.0000 - fp: 159.0000 - tn: 204.0000 - fn: 56.0000 - accuracy: 0.5549 - precision: 0.2870 - recall: 0.5333 - auc: 0.5515 - val_loss: 0.7033 - val_tp: 25.0000 - val_fp: 77.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2524 - val_precision: 0.2451 - val_recall: 1.0000 - val_auc: 0.5913\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 1.0352 - tp: 74.0000 - fp: 182.0000 - tn: 181.0000 - fn: 46.0000 - accuracy: 0.5280 - precision: 0.2891 - recall: 0.6167 - auc: 0.5662 - val_loss: 0.7101 - val_tp: 24.0000 - val_fp: 65.0000 - val_tn: 13.0000 - val_fn: 1.0000 - val_accuracy: 0.3592 - val_precision: 0.2697 - val_recall: 0.9600 - val_auc: 0.6436\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 1.1026 - tp: 73.0000 - fp: 183.0000 - tn: 180.0000 - fn: 47.0000 - accuracy: 0.5238 - precision: 0.2852 - recall: 0.6083 - auc: 0.5460 - val_loss: 0.6929 - val_tp: 20.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 5.0000 - val_accuracy: 0.4466 - val_precision: 0.2778 - val_recall: 0.8000 - val_auc: 0.6290\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.9521 - tp: 82.0000 - fp: 132.0000 - tn: 231.0000 - fn: 38.0000 - accuracy: 0.6480 - precision: 0.3832 - recall: 0.6833 - auc: 0.6895 - val_loss: 0.7001 - val_tp: 21.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 4.0000 - val_accuracy: 0.3981 - val_precision: 0.2658 - val_recall: 0.8400 - val_auc: 0.6338\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.9212 - tp: 88.0000 - fp: 137.0000 - tn: 226.0000 - fn: 32.0000 - accuracy: 0.6501 - precision: 0.3911 - recall: 0.7333 - auc: 0.7195 - val_loss: 0.7430 - val_tp: 24.0000 - val_fp: 62.0000 - val_tn: 16.0000 - val_fn: 1.0000 - val_accuracy: 0.3883 - val_precision: 0.2791 - val_recall: 0.9600 - val_auc: 0.6495\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.9433 - tp: 82.0000 - fp: 150.0000 - tn: 213.0000 - fn: 38.0000 - accuracy: 0.6108 - precision: 0.3534 - recall: 0.6833 - auc: 0.6961 - val_loss: 0.6223 - val_tp: 11.0000 - val_fp: 9.0000 - val_tn: 69.0000 - val_fn: 14.0000 - val_accuracy: 0.7767 - val_precision: 0.5500 - val_recall: 0.4400 - val_auc: 0.6849\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.9711 - tp: 85.0000 - fp: 171.0000 - tn: 192.0000 - fn: 35.0000 - accuracy: 0.5735 - precision: 0.3320 - recall: 0.7083 - auc: 0.6726 - val_loss: 0.6783 - val_tp: 19.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 6.0000 - val_accuracy: 0.4466 - val_precision: 0.2714 - val_recall: 0.7600 - val_auc: 0.6905\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.9130 - tp: 78.0000 - fp: 120.0000 - tn: 243.0000 - fn: 42.0000 - accuracy: 0.6646 - precision: 0.3939 - recall: 0.6500 - auc: 0.7274 - val_loss: 0.6494 - val_tp: 19.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 6.0000 - val_accuracy: 0.5437 - val_precision: 0.3167 - val_recall: 0.7600 - val_auc: 0.7215\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 210ms/step - loss: 0.8948 - tp: 98.0000 - fp: 144.0000 - tn: 219.0000 - fn: 22.0000 - accuracy: 0.6563 - precision: 0.4050 - recall: 0.8167 - auc: 0.7460 - val_loss: 0.6816 - val_tp: 20.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 5.0000 - val_accuracy: 0.5049 - val_precision: 0.3030 - val_recall: 0.8000 - val_auc: 0.7123\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.8848 - tp: 86.0000 - fp: 121.0000 - tn: 242.0000 - fn: 34.0000 - accuracy: 0.6791 - precision: 0.4155 - recall: 0.7167 - auc: 0.7548 - val_loss: 0.6716 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.7149\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.8898 - tp: 98.0000 - fp: 154.0000 - tn: 209.0000 - fn: 22.0000 - accuracy: 0.6356 - precision: 0.3889 - recall: 0.8167 - auc: 0.7357 - val_loss: 0.6065 - val_tp: 18.0000 - val_fp: 31.0000 - val_tn: 47.0000 - val_fn: 7.0000 - val_accuracy: 0.6311 - val_precision: 0.3673 - val_recall: 0.7200 - val_auc: 0.7138\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.9223 - tp: 90.0000 - fp: 154.0000 - tn: 209.0000 - fn: 30.0000 - accuracy: 0.6190 - precision: 0.3689 - recall: 0.7500 - auc: 0.7080 - val_loss: 0.6871 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.7313\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.8683 - tp: 91.0000 - fp: 128.0000 - tn: 235.0000 - fn: 29.0000 - accuracy: 0.6749 - precision: 0.4155 - recall: 0.7583 - auc: 0.7570 - val_loss: 0.6260 - val_tp: 19.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 6.0000 - val_accuracy: 0.5825 - val_precision: 0.3393 - val_recall: 0.7600 - val_auc: 0.7318\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8713 - tp: 85.0000 - fp: 112.0000 - tn: 251.0000 - fn: 35.0000 - accuracy: 0.6957 - precision: 0.4315 - recall: 0.7083 - auc: 0.7589 - val_loss: 0.6668 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.7313\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8810 - tp: 104.0000 - fp: 173.0000 - tn: 190.0000 - fn: 16.0000 - accuracy: 0.6087 - precision: 0.3755 - recall: 0.8667 - auc: 0.7390 - val_loss: 0.6338 - val_tp: 22.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 3.0000 - val_accuracy: 0.5243 - val_precision: 0.3235 - val_recall: 0.8800 - val_auc: 0.7282\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.8768 - tp: 101.0000 - fp: 149.0000 - tn: 214.0000 - fn: 19.0000 - accuracy: 0.6522 - precision: 0.4040 - recall: 0.8417 - auc: 0.7506 - val_loss: 0.7004 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.7049\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.8756 - tp: 98.0000 - fp: 167.0000 - tn: 196.0000 - fn: 22.0000 - accuracy: 0.6087 - precision: 0.3698 - recall: 0.8167 - auc: 0.7378 - val_loss: 0.6805 - val_tp: 20.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 5.0000 - val_accuracy: 0.4466 - val_precision: 0.2778 - val_recall: 0.8000 - val_auc: 0.6962\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.9138 - tp: 92.0000 - fp: 127.0000 - tn: 236.0000 - fn: 28.0000 - accuracy: 0.6791 - precision: 0.4201 - recall: 0.7667 - auc: 0.7360 - val_loss: 0.6903 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.6764\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.9399 - tp: 107.0000 - fp: 214.0000 - tn: 149.0000 - fn: 13.0000 - accuracy: 0.5300 - precision: 0.3333 - recall: 0.8917 - auc: 0.7142 - val_loss: 0.6930 - val_tp: 21.0000 - val_fp: 57.0000 - val_tn: 21.0000 - val_fn: 4.0000 - val_accuracy: 0.4078 - val_precision: 0.2692 - val_recall: 0.8400 - val_auc: 0.6605\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9088 - tp: 96.0000 - fp: 162.0000 - tn: 201.0000 - fn: 24.0000 - accuracy: 0.6149 - precision: 0.3721 - recall: 0.8000 - auc: 0.7198 - val_loss: 0.6627 - val_tp: 20.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 5.0000 - val_accuracy: 0.4757 - val_precision: 0.2899 - val_recall: 0.8000 - val_auc: 0.7162\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.8613 - tp: 99.0000 - fp: 139.0000 - tn: 224.0000 - fn: 21.0000 - accuracy: 0.6687 - precision: 0.4160 - recall: 0.8250 - auc: 0.7558 - val_loss: 0.6707 - val_tp: 22.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 3.0000 - val_accuracy: 0.5146 - val_precision: 0.3188 - val_recall: 0.8800 - val_auc: 0.7282\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.8583 - tp: 98.0000 - fp: 147.0000 - tn: 216.0000 - fn: 22.0000 - accuracy: 0.6501 - precision: 0.4000 - recall: 0.8167 - auc: 0.7604 - val_loss: 0.6595 - val_tp: 22.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 3.0000 - val_accuracy: 0.5049 - val_precision: 0.3143 - val_recall: 0.8800 - val_auc: 0.7262\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8657 - tp: 103.0000 - fp: 152.0000 - tn: 211.0000 - fn: 17.0000 - accuracy: 0.6501 - precision: 0.4039 - recall: 0.8583 - auc: 0.7590 - val_loss: 0.6398 - val_tp: 20.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 5.0000 - val_accuracy: 0.5340 - val_precision: 0.3175 - val_recall: 0.8000 - val_auc: 0.7197\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.8244 - tp: 90.0000 - fp: 130.0000 - tn: 233.0000 - fn: 30.0000 - accuracy: 0.6687 - precision: 0.4091 - recall: 0.7500 - auc: 0.7755 - val_loss: 0.6647 - val_tp: 22.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 3.0000 - val_accuracy: 0.5243 - val_precision: 0.3235 - val_recall: 0.8800 - val_auc: 0.7277\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8397 - tp: 97.0000 - fp: 138.0000 - tn: 225.0000 - fn: 23.0000 - accuracy: 0.6667 - precision: 0.4128 - recall: 0.8083 - auc: 0.7719 - val_loss: 0.6365 - val_tp: 20.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 5.0000 - val_accuracy: 0.5437 - val_precision: 0.3226 - val_recall: 0.8000 - val_auc: 0.7190\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8039 - tp: 98.0000 - fp: 123.0000 - tn: 240.0000 - fn: 22.0000 - accuracy: 0.6998 - precision: 0.4434 - recall: 0.8167 - auc: 0.7951 - val_loss: 0.6430 - val_tp: 20.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 5.0000 - val_accuracy: 0.5534 - val_precision: 0.3279 - val_recall: 0.8000 - val_auc: 0.7208\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8360 - tp: 95.0000 - fp: 145.0000 - tn: 218.0000 - fn: 25.0000 - accuracy: 0.6480 - precision: 0.3958 - recall: 0.7917 - auc: 0.7690 - val_loss: 0.6153 - val_tp: 20.0000 - val_fp: 33.0000 - val_tn: 45.0000 - val_fn: 5.0000 - val_accuracy: 0.6311 - val_precision: 0.3774 - val_recall: 0.8000 - val_auc: 0.7528\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8614 - tp: 93.0000 - fp: 129.0000 - tn: 234.0000 - fn: 27.0000 - accuracy: 0.6770 - precision: 0.4189 - recall: 0.7750 - auc: 0.7768 - val_loss: 0.6479 - val_tp: 22.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 3.0000 - val_accuracy: 0.5534 - val_precision: 0.3385 - val_recall: 0.8800 - val_auc: 0.7097\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8309 - tp: 103.0000 - fp: 148.0000 - tn: 215.0000 - fn: 17.0000 - accuracy: 0.6584 - precision: 0.4104 - recall: 0.8583 - auc: 0.7730 - val_loss: 0.6249 - val_tp: 20.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 5.0000 - val_accuracy: 0.5437 - val_precision: 0.3226 - val_recall: 0.8000 - val_auc: 0.7133\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.7633 - tp: 104.0000 - fp: 136.0000 - tn: 227.0000 - fn: 16.0000 - accuracy: 0.6853 - precision: 0.4333 - recall: 0.8667 - auc: 0.8127 - val_loss: 0.6505 - val_tp: 22.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 3.0000 - val_accuracy: 0.5340 - val_precision: 0.3284 - val_recall: 0.8800 - val_auc: 0.7118\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8322 - tp: 101.0000 - fp: 143.0000 - tn: 220.0000 - fn: 19.0000 - accuracy: 0.6646 - precision: 0.4139 - recall: 0.8417 - auc: 0.7782 - val_loss: 0.6469 - val_tp: 22.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 3.0000 - val_accuracy: 0.5437 - val_precision: 0.3333 - val_recall: 0.8800 - val_auc: 0.7231\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.7979 - tp: 101.0000 - fp: 129.0000 - tn: 234.0000 - fn: 19.0000 - accuracy: 0.6936 - precision: 0.4391 - recall: 0.8417 - auc: 0.7907 - val_loss: 0.6505 - val_tp: 21.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 4.0000 - val_accuracy: 0.5534 - val_precision: 0.3333 - val_recall: 0.8400 - val_auc: 0.7141\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.7666 - tp: 101.0000 - fp: 121.0000 - tn: 242.0000 - fn: 19.0000 - accuracy: 0.7101 - precision: 0.4550 - recall: 0.8417 - auc: 0.8125 - val_loss: 0.6469 - val_tp: 22.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 3.0000 - val_accuracy: 0.5728 - val_precision: 0.3492 - val_recall: 0.8800 - val_auc: 0.7251\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8227 - tp: 99.0000 - fp: 132.0000 - tn: 231.0000 - fn: 21.0000 - accuracy: 0.6832 - precision: 0.4286 - recall: 0.8250 - auc: 0.7789 - val_loss: 0.5614 - val_tp: 14.0000 - val_fp: 19.0000 - val_tn: 59.0000 - val_fn: 11.0000 - val_accuracy: 0.7087 - val_precision: 0.4242 - val_recall: 0.5600 - val_auc: 0.7387\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.8551 - tp: 97.0000 - fp: 152.0000 - tn: 211.0000 - fn: 23.0000 - accuracy: 0.6377 - precision: 0.3896 - recall: 0.8083 - auc: 0.7360 - val_loss: 0.6360 - val_tp: 20.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 5.0000 - val_accuracy: 0.5825 - val_precision: 0.3448 - val_recall: 0.8000 - val_auc: 0.6997\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8210 - tp: 91.0000 - fp: 134.0000 - tn: 229.0000 - fn: 29.0000 - accuracy: 0.6625 - precision: 0.4044 - recall: 0.7583 - auc: 0.7861 - val_loss: 0.6436 - val_tp: 20.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 5.0000 - val_accuracy: 0.5534 - val_precision: 0.3279 - val_recall: 0.8000 - val_auc: 0.7003\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8229 - tp: 98.0000 - fp: 135.0000 - tn: 228.0000 - fn: 22.0000 - accuracy: 0.6749 - precision: 0.4206 - recall: 0.8167 - auc: 0.7866 - val_loss: 0.6130 - val_tp: 21.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 4.0000 - val_accuracy: 0.5825 - val_precision: 0.3500 - val_recall: 0.8400 - val_auc: 0.7262\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.7980 - tp: 108.0000 - fp: 152.0000 - tn: 211.0000 - fn: 12.0000 - accuracy: 0.6605 - precision: 0.4154 - recall: 0.9000 - auc: 0.7958 - val_loss: 0.6372 - val_tp: 21.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 4.0000 - val_accuracy: 0.5340 - val_precision: 0.3231 - val_recall: 0.8400 - val_auc: 0.7323\n",
      "Calculated mean IoU: 0.0257\n",
      "IoU from saved model: 0.585\n",
      "No Model update.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 4s 259ms/step - loss: 18.4989 - tp: 75.0000 - fp: 216.0000 - tn: 225.0000 - fn: 70.0000 - accuracy: 0.5119 - precision: 0.2577 - recall: 0.5172 - auc: 0.5027 - val_loss: 0.7269 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.6113\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 4s 223ms/step - loss: 1.0499 - tp: 83.0000 - fp: 249.0000 - tn: 114.0000 - fn: 37.0000 - accuracy: 0.4079 - precision: 0.2500 - recall: 0.6917 - auc: 0.5397 - val_loss: 0.6925 - val_tp: 21.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 4.0000 - val_accuracy: 0.4854 - val_precision: 0.3000 - val_recall: 0.8400 - val_auc: 0.6413\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0202 - tp: 32.0000 - fp: 63.0000 - tn: 300.0000 - fn: 88.0000 - accuracy: 0.6874 - precision: 0.3368 - recall: 0.2667 - auc: 0.6274 - val_loss: 0.6918 - val_tp: 23.0000 - val_fp: 60.0000 - val_tn: 18.0000 - val_fn: 2.0000 - val_accuracy: 0.3981 - val_precision: 0.2771 - val_recall: 0.9200 - val_auc: 0.6659\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0026 - tp: 84.0000 - fp: 180.0000 - tn: 183.0000 - fn: 36.0000 - accuracy: 0.5528 - precision: 0.3182 - recall: 0.7000 - auc: 0.6258 - val_loss: 0.6296 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6454\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9219 - tp: 90.0000 - fp: 152.0000 - tn: 211.0000 - fn: 30.0000 - accuracy: 0.6232 - precision: 0.3719 - recall: 0.7500 - auc: 0.7139 - val_loss: 0.6477 - val_tp: 23.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.4175 - val_precision: 0.2840 - val_recall: 0.9200 - val_auc: 0.6515\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.9118 - tp: 108.0000 - fp: 188.0000 - tn: 175.0000 - fn: 12.0000 - accuracy: 0.5859 - precision: 0.3649 - recall: 0.9000 - auc: 0.7463 - val_loss: 0.6633 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.6746\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8899 - tp: 70.0000 - fp: 102.0000 - tn: 261.0000 - fn: 50.0000 - accuracy: 0.6853 - precision: 0.4070 - recall: 0.5833 - auc: 0.7412 - val_loss: 0.6833 - val_tp: 23.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.4175 - val_precision: 0.2840 - val_recall: 0.9200 - val_auc: 0.6972\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8544 - tp: 103.0000 - fp: 167.0000 - tn: 196.0000 - fn: 17.0000 - accuracy: 0.6190 - precision: 0.3815 - recall: 0.8583 - auc: 0.7689 - val_loss: 0.6535 - val_tp: 22.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 3.0000 - val_accuracy: 0.4078 - val_precision: 0.2750 - val_recall: 0.8800 - val_auc: 0.6721\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8488 - tp: 103.0000 - fp: 169.0000 - tn: 194.0000 - fn: 17.0000 - accuracy: 0.6149 - precision: 0.3787 - recall: 0.8583 - auc: 0.7696 - val_loss: 0.6707 - val_tp: 22.0000 - val_fp: 57.0000 - val_tn: 21.0000 - val_fn: 3.0000 - val_accuracy: 0.4175 - val_precision: 0.2785 - val_recall: 0.8800 - val_auc: 0.6651\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8594 - tp: 101.0000 - fp: 170.0000 - tn: 193.0000 - fn: 19.0000 - accuracy: 0.6087 - precision: 0.3727 - recall: 0.8417 - auc: 0.7455 - val_loss: 0.6610 - val_tp: 22.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.4369 - val_precision: 0.2857 - val_recall: 0.8800 - val_auc: 0.6749\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8622 - tp: 102.0000 - fp: 172.0000 - tn: 191.0000 - fn: 18.0000 - accuracy: 0.6066 - precision: 0.3723 - recall: 0.8500 - auc: 0.7655 - val_loss: 0.6563 - val_tp: 22.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 3.0000 - val_accuracy: 0.4466 - val_precision: 0.2895 - val_recall: 0.8800 - val_auc: 0.6613\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 190ms/step - loss: 0.9118 - tp: 82.0000 - fp: 145.0000 - tn: 218.0000 - fn: 38.0000 - accuracy: 0.6211 - precision: 0.3612 - recall: 0.6833 - auc: 0.7096 - val_loss: 0.6773 - val_tp: 23.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.3883 - val_precision: 0.2738 - val_recall: 0.9200 - val_auc: 0.6508\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.9244 - tp: 104.0000 - fp: 193.0000 - tn: 170.0000 - fn: 16.0000 - accuracy: 0.5673 - precision: 0.3502 - recall: 0.8667 - auc: 0.7163 - val_loss: 0.6691 - val_tp: 12.0000 - val_fp: 21.0000 - val_tn: 57.0000 - val_fn: 13.0000 - val_accuracy: 0.6699 - val_precision: 0.3636 - val_recall: 0.4800 - val_auc: 0.6582\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9374 - tp: 92.0000 - fp: 161.0000 - tn: 202.0000 - fn: 28.0000 - accuracy: 0.6087 - precision: 0.3636 - recall: 0.7667 - auc: 0.7035 - val_loss: 0.6584 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.6749\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8195 - tp: 105.0000 - fp: 168.0000 - tn: 195.0000 - fn: 15.0000 - accuracy: 0.6211 - precision: 0.3846 - recall: 0.8750 - auc: 0.7803 - val_loss: 0.6428 - val_tp: 22.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 3.0000 - val_accuracy: 0.4951 - val_precision: 0.3099 - val_recall: 0.8800 - val_auc: 0.6951\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8083 - tp: 99.0000 - fp: 147.0000 - tn: 216.0000 - fn: 21.0000 - accuracy: 0.6522 - precision: 0.4024 - recall: 0.8250 - auc: 0.7798 - val_loss: 0.6404 - val_tp: 22.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 3.0000 - val_accuracy: 0.5437 - val_precision: 0.3333 - val_recall: 0.8800 - val_auc: 0.6931\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8152 - tp: 102.0000 - fp: 142.0000 - tn: 221.0000 - fn: 18.0000 - accuracy: 0.6687 - precision: 0.4180 - recall: 0.8500 - auc: 0.7791 - val_loss: 0.6625 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.6918\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 0.8181 - tp: 107.0000 - fp: 142.0000 - tn: 221.0000 - fn: 13.0000 - accuracy: 0.6791 - precision: 0.4297 - recall: 0.8917 - auc: 0.7826 - val_loss: 0.6679 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.6879\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.7892 - tp: 100.0000 - fp: 134.0000 - tn: 229.0000 - fn: 20.0000 - accuracy: 0.6812 - precision: 0.4274 - recall: 0.8333 - auc: 0.7935 - val_loss: 0.6570 - val_tp: 19.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 6.0000 - val_accuracy: 0.5728 - val_precision: 0.3333 - val_recall: 0.7600 - val_auc: 0.6736\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8334 - tp: 98.0000 - fp: 132.0000 - tn: 231.0000 - fn: 22.0000 - accuracy: 0.6812 - precision: 0.4261 - recall: 0.8167 - auc: 0.7708 - val_loss: 0.6255 - val_tp: 19.0000 - val_fp: 35.0000 - val_tn: 43.0000 - val_fn: 6.0000 - val_accuracy: 0.6019 - val_precision: 0.3519 - val_recall: 0.7600 - val_auc: 0.6733\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8343 - tp: 101.0000 - fp: 159.0000 - tn: 204.0000 - fn: 19.0000 - accuracy: 0.6315 - precision: 0.3885 - recall: 0.8417 - auc: 0.7617 - val_loss: 0.6452 - val_tp: 21.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 4.0000 - val_accuracy: 0.4854 - val_precision: 0.3000 - val_recall: 0.8400 - val_auc: 0.6695\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8755 - tp: 75.0000 - fp: 100.0000 - tn: 263.0000 - fn: 45.0000 - accuracy: 0.6998 - precision: 0.4286 - recall: 0.6250 - auc: 0.7557 - val_loss: 0.6805 - val_tp: 24.0000 - val_fp: 59.0000 - val_tn: 19.0000 - val_fn: 1.0000 - val_accuracy: 0.4175 - val_precision: 0.2892 - val_recall: 0.9600 - val_auc: 0.6521\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8681 - tp: 105.0000 - fp: 176.0000 - tn: 187.0000 - fn: 15.0000 - accuracy: 0.6046 - precision: 0.3737 - recall: 0.8750 - auc: 0.7508 - val_loss: 0.6825 - val_tp: 21.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 4.0000 - val_accuracy: 0.5146 - val_precision: 0.3134 - val_recall: 0.8400 - val_auc: 0.6854\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8384 - tp: 109.0000 - fp: 168.0000 - tn: 195.0000 - fn: 11.0000 - accuracy: 0.6294 - precision: 0.3935 - recall: 0.9083 - auc: 0.7815 - val_loss: 0.6338 - val_tp: 20.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 5.0000 - val_accuracy: 0.5146 - val_precision: 0.3077 - val_recall: 0.8000 - val_auc: 0.6785\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.7994 - tp: 93.0000 - fp: 129.0000 - tn: 234.0000 - fn: 27.0000 - accuracy: 0.6770 - precision: 0.4189 - recall: 0.7750 - auc: 0.7940 - val_loss: 0.6378 - val_tp: 19.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 6.0000 - val_accuracy: 0.5825 - val_precision: 0.3393 - val_recall: 0.7600 - val_auc: 0.6441\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8109 - tp: 97.0000 - fp: 126.0000 - tn: 237.0000 - fn: 23.0000 - accuracy: 0.6915 - precision: 0.4350 - recall: 0.8083 - auc: 0.7818 - val_loss: 0.6271 - val_tp: 18.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 7.0000 - val_accuracy: 0.5728 - val_precision: 0.3273 - val_recall: 0.7200 - val_auc: 0.6477\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.7973 - tp: 84.0000 - fp: 108.0000 - tn: 255.0000 - fn: 36.0000 - accuracy: 0.7019 - precision: 0.4375 - recall: 0.7000 - auc: 0.7932 - val_loss: 0.6886 - val_tp: 24.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 1.0000 - val_accuracy: 0.4563 - val_precision: 0.3038 - val_recall: 0.9600 - val_auc: 0.6518\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.7851 - tp: 112.0000 - fp: 157.0000 - tn: 206.0000 - fn: 8.0000 - accuracy: 0.6584 - precision: 0.4164 - recall: 0.9333 - auc: 0.7972 - val_loss: 0.6418 - val_tp: 18.0000 - val_fp: 40.0000 - val_tn: 38.0000 - val_fn: 7.0000 - val_accuracy: 0.5437 - val_precision: 0.3103 - val_recall: 0.7200 - val_auc: 0.6346\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.7639 - tp: 111.0000 - fp: 145.0000 - tn: 218.0000 - fn: 9.0000 - accuracy: 0.6812 - precision: 0.4336 - recall: 0.9250 - auc: 0.8003 - val_loss: 0.6784 - val_tp: 21.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 4.0000 - val_accuracy: 0.5243 - val_precision: 0.3182 - val_recall: 0.8400 - val_auc: 0.6613\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.7246 - tp: 101.0000 - fp: 114.0000 - tn: 249.0000 - fn: 19.0000 - accuracy: 0.7246 - precision: 0.4698 - recall: 0.8417 - auc: 0.8165 - val_loss: 0.6598 - val_tp: 19.0000 - val_fp: 40.0000 - val_tn: 38.0000 - val_fn: 6.0000 - val_accuracy: 0.5534 - val_precision: 0.3220 - val_recall: 0.7600 - val_auc: 0.6531\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.7346 - tp: 105.0000 - fp: 137.0000 - tn: 226.0000 - fn: 15.0000 - accuracy: 0.6853 - precision: 0.4339 - recall: 0.8750 - auc: 0.8179 - val_loss: 0.6848 - val_tp: 17.0000 - val_fp: 40.0000 - val_tn: 38.0000 - val_fn: 8.0000 - val_accuracy: 0.5340 - val_precision: 0.2982 - val_recall: 0.6800 - val_auc: 0.6436\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.7440 - tp: 108.0000 - fp: 148.0000 - tn: 215.0000 - fn: 12.0000 - accuracy: 0.6687 - precision: 0.4219 - recall: 0.9000 - auc: 0.8139 - val_loss: 0.6981 - val_tp: 20.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 5.0000 - val_accuracy: 0.5534 - val_precision: 0.3279 - val_recall: 0.8000 - val_auc: 0.6533\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.7528 - tp: 107.0000 - fp: 135.0000 - tn: 228.0000 - fn: 13.0000 - accuracy: 0.6936 - precision: 0.4421 - recall: 0.8917 - auc: 0.8326 - val_loss: 0.6494 - val_tp: 20.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 5.0000 - val_accuracy: 0.5437 - val_precision: 0.3226 - val_recall: 0.8000 - val_auc: 0.6723\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.6921 - tp: 104.0000 - fp: 107.0000 - tn: 256.0000 - fn: 16.0000 - accuracy: 0.7453 - precision: 0.4929 - recall: 0.8667 - auc: 0.8397 - val_loss: 0.6890 - val_tp: 20.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 5.0000 - val_accuracy: 0.5437 - val_precision: 0.3226 - val_recall: 0.8000 - val_auc: 0.6738\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.7368 - tp: 103.0000 - fp: 122.0000 - tn: 241.0000 - fn: 17.0000 - accuracy: 0.7122 - precision: 0.4578 - recall: 0.8583 - auc: 0.8127 - val_loss: 0.7223 - val_tp: 21.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 4.0000 - val_accuracy: 0.5534 - val_precision: 0.3333 - val_recall: 0.8400 - val_auc: 0.6785\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.6643 - tp: 110.0000 - fp: 120.0000 - tn: 243.0000 - fn: 10.0000 - accuracy: 0.7308 - precision: 0.4783 - recall: 0.9167 - auc: 0.8572 - val_loss: 0.7144 - val_tp: 20.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 5.0000 - val_accuracy: 0.5534 - val_precision: 0.3279 - val_recall: 0.8000 - val_auc: 0.6756\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.6895 - tp: 101.0000 - fp: 98.0000 - tn: 265.0000 - fn: 19.0000 - accuracy: 0.7578 - precision: 0.5075 - recall: 0.8417 - auc: 0.8506 - val_loss: 0.6519 - val_tp: 21.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 4.0000 - val_accuracy: 0.5631 - val_precision: 0.3387 - val_recall: 0.8400 - val_auc: 0.6772\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.6880 - tp: 104.0000 - fp: 123.0000 - tn: 240.0000 - fn: 16.0000 - accuracy: 0.7122 - precision: 0.4581 - recall: 0.8667 - auc: 0.8500 - val_loss: 0.9305 - val_tp: 18.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 7.0000 - val_accuracy: 0.5631 - val_precision: 0.3214 - val_recall: 0.7200 - val_auc: 0.6410\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.7392 - tp: 98.0000 - fp: 119.0000 - tn: 244.0000 - fn: 22.0000 - accuracy: 0.7081 - precision: 0.4516 - recall: 0.8167 - auc: 0.8268 - val_loss: 0.6951 - val_tp: 22.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 3.0000 - val_accuracy: 0.5243 - val_precision: 0.3235 - val_recall: 0.8800 - val_auc: 0.6895\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.7023 - tp: 112.0000 - fp: 128.0000 - tn: 235.0000 - fn: 8.0000 - accuracy: 0.7184 - precision: 0.4667 - recall: 0.9333 - auc: 0.8372 - val_loss: 0.7270 - val_tp: 20.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 5.0000 - val_accuracy: 0.5534 - val_precision: 0.3279 - val_recall: 0.8000 - val_auc: 0.6849\n",
      "Calculated mean IoU: 0.5378\n",
      "IoU from saved model: 0.585\n",
      "No Model update.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 5s 283ms/step - loss: 28.2442 - tp: 96.0000 - fp: 252.0000 - tn: 189.0000 - fn: 49.0000 - accuracy: 0.4863 - precision: 0.2759 - recall: 0.6621 - auc: 0.5272 - val_loss: 0.6929 - val_tp: 7.0000 - val_fp: 29.0000 - val_tn: 49.0000 - val_fn: 18.0000 - val_accuracy: 0.5437 - val_precision: 0.1944 - val_recall: 0.2800 - val_auc: 0.5128\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 1.0433 - tp: 24.0000 - fp: 69.0000 - tn: 294.0000 - fn: 96.0000 - accuracy: 0.6584 - precision: 0.2581 - recall: 0.2000 - auc: 0.5000 - val_loss: 0.6882 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 77.0000 - val_fn: 24.0000 - val_accuracy: 0.7573 - val_precision: 0.5000 - val_recall: 0.0400 - val_auc: 0.6244\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 1.0188 - tp: 69.0000 - fp: 123.0000 - tn: 240.0000 - fn: 51.0000 - accuracy: 0.6398 - precision: 0.3594 - recall: 0.5750 - auc: 0.6167 - val_loss: 0.7115 - val_tp: 25.0000 - val_fp: 74.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2816 - val_precision: 0.2525 - val_recall: 1.0000 - val_auc: 0.6490\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 1.0591 - tp: 21.0000 - fp: 68.0000 - tn: 295.0000 - fn: 99.0000 - accuracy: 0.6542 - precision: 0.2360 - recall: 0.1750 - auc: 0.5251 - val_loss: 0.6922 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 1.0377 - tp: 80.0000 - fp: 201.0000 - tn: 162.0000 - fn: 40.0000 - accuracy: 0.5010 - precision: 0.2847 - recall: 0.6667 - auc: 0.5822 - val_loss: 0.6888 - val_tp: 21.0000 - val_fp: 57.0000 - val_tn: 21.0000 - val_fn: 4.0000 - val_accuracy: 0.4078 - val_precision: 0.2692 - val_recall: 0.8400 - val_auc: 0.5985\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 1.0301 - tp: 89.0000 - fp: 229.0000 - tn: 134.0000 - fn: 31.0000 - accuracy: 0.4617 - precision: 0.2799 - recall: 0.7417 - auc: 0.5940 - val_loss: 0.6900 - val_tp: 23.0000 - val_fp: 63.0000 - val_tn: 15.0000 - val_fn: 2.0000 - val_accuracy: 0.3689 - val_precision: 0.2674 - val_recall: 0.9200 - val_auc: 0.5833\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 1.0181 - tp: 99.0000 - fp: 246.0000 - tn: 117.0000 - fn: 21.0000 - accuracy: 0.4472 - precision: 0.2870 - recall: 0.8250 - auc: 0.6166 - val_loss: 0.6839 - val_tp: 22.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 3.0000 - val_accuracy: 0.4078 - val_precision: 0.2750 - val_recall: 0.8800 - val_auc: 0.6031\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 1.0380 - tp: 90.0000 - fp: 159.0000 - tn: 204.0000 - fn: 30.0000 - accuracy: 0.6087 - precision: 0.3614 - recall: 0.7500 - auc: 0.6804 - val_loss: 0.6852 - val_tp: 20.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 5.0000 - val_accuracy: 0.4563 - val_precision: 0.2817 - val_recall: 0.8000 - val_auc: 0.6454\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 1.0054 - tp: 69.0000 - fp: 148.0000 - tn: 215.0000 - fn: 51.0000 - accuracy: 0.5880 - precision: 0.3180 - recall: 0.5750 - auc: 0.6408 - val_loss: 0.7121 - val_tp: 23.0000 - val_fp: 60.0000 - val_tn: 18.0000 - val_fn: 2.0000 - val_accuracy: 0.3981 - val_precision: 0.2771 - val_recall: 0.9200 - val_auc: 0.6400\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9198 - tp: 85.0000 - fp: 123.0000 - tn: 240.0000 - fn: 35.0000 - accuracy: 0.6729 - precision: 0.4087 - recall: 0.7083 - auc: 0.7337 - val_loss: 0.6666 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.7069\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.9559 - tp: 91.0000 - fp: 144.0000 - tn: 219.0000 - fn: 29.0000 - accuracy: 0.6418 - precision: 0.3872 - recall: 0.7583 - auc: 0.7237 - val_loss: 0.6582 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 75.0000 - val_fn: 22.0000 - val_accuracy: 0.7573 - val_precision: 0.5000 - val_recall: 0.1200 - val_auc: 0.6672\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 0.9751 - tp: 71.0000 - fp: 140.0000 - tn: 223.0000 - fn: 49.0000 - accuracy: 0.6087 - precision: 0.3365 - recall: 0.5917 - auc: 0.6682 - val_loss: 0.6912 - val_tp: 21.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 4.0000 - val_accuracy: 0.4563 - val_precision: 0.2877 - val_recall: 0.8400 - val_auc: 0.6759\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.9090 - tp: 87.0000 - fp: 121.0000 - tn: 242.0000 - fn: 33.0000 - accuracy: 0.6812 - precision: 0.4183 - recall: 0.7250 - auc: 0.7298 - val_loss: 0.6787 - val_tp: 20.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 5.0000 - val_accuracy: 0.4854 - val_precision: 0.2941 - val_recall: 0.8000 - val_auc: 0.6905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.8986 - tp: 80.0000 - fp: 112.0000 - tn: 251.0000 - fn: 40.0000 - accuracy: 0.6853 - precision: 0.4167 - recall: 0.6667 - auc: 0.7442 - val_loss: 0.6629 - val_tp: 19.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 6.0000 - val_accuracy: 0.5437 - val_precision: 0.3167 - val_recall: 0.7600 - val_auc: 0.6897\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8576 - tp: 94.0000 - fp: 147.0000 - tn: 216.0000 - fn: 26.0000 - accuracy: 0.6418 - precision: 0.3900 - recall: 0.7833 - auc: 0.7688 - val_loss: 0.6255 - val_tp: 20.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 5.0000 - val_accuracy: 0.5340 - val_precision: 0.3175 - val_recall: 0.8000 - val_auc: 0.7051\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.8872 - tp: 101.0000 - fp: 148.0000 - tn: 215.0000 - fn: 19.0000 - accuracy: 0.6542 - precision: 0.4056 - recall: 0.8417 - auc: 0.7621 - val_loss: 0.6088 - val_tp: 17.0000 - val_fp: 27.0000 - val_tn: 51.0000 - val_fn: 8.0000 - val_accuracy: 0.6602 - val_precision: 0.3864 - val_recall: 0.6800 - val_auc: 0.6723\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8623 - tp: 102.0000 - fp: 158.0000 - tn: 205.0000 - fn: 18.0000 - accuracy: 0.6356 - precision: 0.3923 - recall: 0.8500 - auc: 0.7392 - val_loss: 0.6084 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 77.0000 - val_fn: 25.0000 - val_accuracy: 0.7476 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6459\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8954 - tp: 82.0000 - fp: 127.0000 - tn: 236.0000 - fn: 38.0000 - accuracy: 0.6584 - precision: 0.3923 - recall: 0.6833 - auc: 0.7322 - val_loss: 0.6492 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.6451\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.8453 - tp: 99.0000 - fp: 132.0000 - tn: 231.0000 - fn: 21.0000 - accuracy: 0.6832 - precision: 0.4286 - recall: 0.8250 - auc: 0.7699 - val_loss: 0.6517 - val_tp: 21.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 4.0000 - val_accuracy: 0.4951 - val_precision: 0.3043 - val_recall: 0.8400 - val_auc: 0.6882\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.8565 - tp: 102.0000 - fp: 157.0000 - tn: 206.0000 - fn: 18.0000 - accuracy: 0.6377 - precision: 0.3938 - recall: 0.8500 - auc: 0.7644 - val_loss: 0.6224 - val_tp: 15.0000 - val_fp: 31.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.6019 - val_precision: 0.3261 - val_recall: 0.6000 - val_auc: 0.6562\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8745 - tp: 78.0000 - fp: 131.0000 - tn: 232.0000 - fn: 42.0000 - accuracy: 0.6418 - precision: 0.3732 - recall: 0.6500 - auc: 0.7353 - val_loss: 0.6281 - val_tp: 8.0000 - val_fp: 7.0000 - val_tn: 71.0000 - val_fn: 17.0000 - val_accuracy: 0.7670 - val_precision: 0.5333 - val_recall: 0.3200 - val_auc: 0.6533\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8543 - tp: 103.0000 - fp: 166.0000 - tn: 197.0000 - fn: 17.0000 - accuracy: 0.6211 - precision: 0.3829 - recall: 0.8583 - auc: 0.7652 - val_loss: 0.6637 - val_tp: 21.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 4.0000 - val_accuracy: 0.4369 - val_precision: 0.2800 - val_recall: 0.8400 - val_auc: 0.6933\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8560 - tp: 104.0000 - fp: 158.0000 - tn: 205.0000 - fn: 16.0000 - accuracy: 0.6398 - precision: 0.3969 - recall: 0.8667 - auc: 0.7610 - val_loss: 0.6407 - val_tp: 18.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 7.0000 - val_accuracy: 0.5146 - val_precision: 0.2951 - val_recall: 0.7200 - val_auc: 0.6597\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8318 - tp: 101.0000 - fp: 147.0000 - tn: 216.0000 - fn: 19.0000 - accuracy: 0.6563 - precision: 0.4073 - recall: 0.8417 - auc: 0.7673 - val_loss: 0.6800 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.6762\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.8798 - tp: 94.0000 - fp: 146.0000 - tn: 217.0000 - fn: 26.0000 - accuracy: 0.6439 - precision: 0.3917 - recall: 0.7833 - auc: 0.7400 - val_loss: 0.6421 - val_tp: 19.0000 - val_fp: 40.0000 - val_tn: 38.0000 - val_fn: 6.0000 - val_accuracy: 0.5534 - val_precision: 0.3220 - val_recall: 0.7600 - val_auc: 0.6908\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.8302 - tp: 98.0000 - fp: 143.0000 - tn: 220.0000 - fn: 22.0000 - accuracy: 0.6584 - precision: 0.4066 - recall: 0.8167 - auc: 0.7636 - val_loss: 0.7177 - val_tp: 23.0000 - val_fp: 64.0000 - val_tn: 14.0000 - val_fn: 2.0000 - val_accuracy: 0.3592 - val_precision: 0.2644 - val_recall: 0.9200 - val_auc: 0.6397\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9358 - tp: 98.0000 - fp: 200.0000 - tn: 163.0000 - fn: 22.0000 - accuracy: 0.5404 - precision: 0.3289 - recall: 0.8167 - auc: 0.7084 - val_loss: 0.6791 - val_tp: 14.0000 - val_fp: 26.0000 - val_tn: 52.0000 - val_fn: 11.0000 - val_accuracy: 0.6408 - val_precision: 0.3500 - val_recall: 0.5600 - val_auc: 0.5815\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8791 - tp: 88.0000 - fp: 143.0000 - tn: 220.0000 - fn: 32.0000 - accuracy: 0.6377 - precision: 0.3810 - recall: 0.7333 - auc: 0.7470 - val_loss: 0.6458 - val_tp: 19.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 6.0000 - val_accuracy: 0.4854 - val_precision: 0.2879 - val_recall: 0.7600 - val_auc: 0.7079\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8282 - tp: 101.0000 - fp: 152.0000 - tn: 211.0000 - fn: 19.0000 - accuracy: 0.6460 - precision: 0.3992 - recall: 0.8417 - auc: 0.7793 - val_loss: 0.6380 - val_tp: 19.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 6.0000 - val_accuracy: 0.5728 - val_precision: 0.3333 - val_recall: 0.7600 - val_auc: 0.7169\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8182 - tp: 79.0000 - fp: 105.0000 - tn: 258.0000 - fn: 41.0000 - accuracy: 0.6977 - precision: 0.4293 - recall: 0.6583 - auc: 0.7866 - val_loss: 0.6621 - val_tp: 22.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 3.0000 - val_accuracy: 0.4466 - val_precision: 0.2895 - val_recall: 0.8800 - val_auc: 0.6869\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8403 - tp: 101.0000 - fp: 154.0000 - tn: 209.0000 - fn: 19.0000 - accuracy: 0.6418 - precision: 0.3961 - recall: 0.8417 - auc: 0.7587 - val_loss: 0.6641 - val_tp: 19.0000 - val_fp: 36.0000 - val_tn: 42.0000 - val_fn: 6.0000 - val_accuracy: 0.5922 - val_precision: 0.3455 - val_recall: 0.7600 - val_auc: 0.7154\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.7911 - tp: 106.0000 - fp: 140.0000 - tn: 223.0000 - fn: 14.0000 - accuracy: 0.6812 - precision: 0.4309 - recall: 0.8833 - auc: 0.8072 - val_loss: 0.6690 - val_tp: 21.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 4.0000 - val_accuracy: 0.4660 - val_precision: 0.2917 - val_recall: 0.8400 - val_auc: 0.6651\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.7854 - tp: 97.0000 - fp: 121.0000 - tn: 242.0000 - fn: 23.0000 - accuracy: 0.7019 - precision: 0.4450 - recall: 0.8083 - auc: 0.7885 - val_loss: 0.6716 - val_tp: 22.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 3.0000 - val_accuracy: 0.5146 - val_precision: 0.3188 - val_recall: 0.8800 - val_auc: 0.6772\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8161 - tp: 98.0000 - fp: 129.0000 - tn: 234.0000 - fn: 22.0000 - accuracy: 0.6874 - precision: 0.4317 - recall: 0.8167 - auc: 0.7840 - val_loss: 0.6458 - val_tp: 20.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 5.0000 - val_accuracy: 0.5049 - val_precision: 0.3030 - val_recall: 0.8000 - val_auc: 0.6851\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.7657 - tp: 103.0000 - fp: 141.0000 - tn: 222.0000 - fn: 17.0000 - accuracy: 0.6729 - precision: 0.4221 - recall: 0.8583 - auc: 0.8082 - val_loss: 0.6280 - val_tp: 17.0000 - val_fp: 34.0000 - val_tn: 44.0000 - val_fn: 8.0000 - val_accuracy: 0.5922 - val_precision: 0.3333 - val_recall: 0.6800 - val_auc: 0.6303\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8036 - tp: 104.0000 - fp: 129.0000 - tn: 234.0000 - fn: 16.0000 - accuracy: 0.6998 - precision: 0.4464 - recall: 0.8667 - auc: 0.7786 - val_loss: 0.6800 - val_tp: 14.0000 - val_fp: 17.0000 - val_tn: 61.0000 - val_fn: 11.0000 - val_accuracy: 0.7282 - val_precision: 0.4516 - val_recall: 0.5600 - val_auc: 0.7315\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.7733 - tp: 106.0000 - fp: 143.0000 - tn: 220.0000 - fn: 14.0000 - accuracy: 0.6749 - precision: 0.4257 - recall: 0.8833 - auc: 0.7864 - val_loss: 0.6791 - val_tp: 22.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 3.0000 - val_accuracy: 0.4466 - val_precision: 0.2895 - val_recall: 0.8800 - val_auc: 0.6382\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.7508 - tp: 112.0000 - fp: 154.0000 - tn: 209.0000 - fn: 8.0000 - accuracy: 0.6646 - precision: 0.4211 - recall: 0.9333 - auc: 0.8066 - val_loss: 0.6883 - val_tp: 21.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 4.0000 - val_accuracy: 0.5631 - val_precision: 0.3387 - val_recall: 0.8400 - val_auc: 0.6431\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.7568 - tp: 107.0000 - fp: 142.0000 - tn: 221.0000 - fn: 13.0000 - accuracy: 0.6791 - precision: 0.4297 - recall: 0.8917 - auc: 0.8098 - val_loss: 0.7042 - val_tp: 19.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 6.0000 - val_accuracy: 0.5340 - val_precision: 0.3115 - val_recall: 0.7600 - val_auc: 0.6113\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.7655 - tp: 96.0000 - fp: 120.0000 - tn: 243.0000 - fn: 24.0000 - accuracy: 0.7019 - precision: 0.4444 - recall: 0.8000 - auc: 0.8103 - val_loss: 0.6837 - val_tp: 21.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 4.0000 - val_accuracy: 0.5243 - val_precision: 0.3182 - val_recall: 0.8400 - val_auc: 0.7049\n",
      "Calculated mean IoU: 0.5554\n",
      "IoU from saved model: 0.585\n",
      "No Model update.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 4s 265ms/step - loss: 28.6401 - tp: 71.0000 - fp: 214.0000 - tn: 227.0000 - fn: 74.0000 - accuracy: 0.5085 - precision: 0.2491 - recall: 0.4897 - auc: 0.4795 - val_loss: 0.7167 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.5064\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 1.0568 - tp: 69.0000 - fp: 210.0000 - tn: 153.0000 - fn: 51.0000 - accuracy: 0.4596 - precision: 0.2473 - recall: 0.5750 - auc: 0.4826 - val_loss: 0.6943 - val_tp: 25.0000 - val_fp: 76.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2621 - val_precision: 0.2475 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 1.0441 - tp: 65.0000 - fp: 172.0000 - tn: 191.0000 - fn: 55.0000 - accuracy: 0.5300 - precision: 0.2743 - recall: 0.5417 - auc: 0.5296 - val_loss: 0.6825 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6441\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 1.0407 - tp: 9.0000 - fp: 15.0000 - tn: 348.0000 - fn: 111.0000 - accuracy: 0.7391 - precision: 0.3750 - recall: 0.0750 - auc: 0.5979 - val_loss: 0.6982 - val_tp: 25.0000 - val_fp: 75.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2718 - val_precision: 0.2500 - val_recall: 1.0000 - val_auc: 0.5246\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0254 - tp: 92.0000 - fp: 230.0000 - tn: 133.0000 - fn: 28.0000 - accuracy: 0.4658 - precision: 0.2857 - recall: 0.7667 - auc: 0.5863 - val_loss: 0.7190 - val_tp: 25.0000 - val_fp: 72.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3010 - val_precision: 0.2577 - val_recall: 1.0000 - val_auc: 0.5626\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.9337 - tp: 83.0000 - fp: 148.0000 - tn: 215.0000 - fn: 37.0000 - accuracy: 0.6170 - precision: 0.3593 - recall: 0.6917 - auc: 0.6945 - val_loss: 0.6323 - val_tp: 21.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 4.0000 - val_accuracy: 0.5049 - val_precision: 0.3088 - val_recall: 0.8400 - val_auc: 0.6744\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.9197 - tp: 105.0000 - fp: 179.0000 - tn: 184.0000 - fn: 15.0000 - accuracy: 0.5983 - precision: 0.3697 - recall: 0.8750 - auc: 0.7119 - val_loss: 0.6620 - val_tp: 23.0000 - val_fp: 57.0000 - val_tn: 21.0000 - val_fn: 2.0000 - val_accuracy: 0.4272 - val_precision: 0.2875 - val_recall: 0.9200 - val_auc: 0.7336\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9134 - tp: 100.0000 - fp: 171.0000 - tn: 192.0000 - fn: 20.0000 - accuracy: 0.6046 - precision: 0.3690 - recall: 0.8333 - auc: 0.7140 - val_loss: 0.6668 - val_tp: 23.0000 - val_fp: 60.0000 - val_tn: 18.0000 - val_fn: 2.0000 - val_accuracy: 0.3981 - val_precision: 0.2771 - val_recall: 0.9200 - val_auc: 0.6731\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 0.9131 - tp: 82.0000 - fp: 98.0000 - tn: 265.0000 - fn: 38.0000 - accuracy: 0.7184 - precision: 0.4556 - recall: 0.6833 - auc: 0.7559 - val_loss: 0.6787 - val_tp: 23.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.3883 - val_precision: 0.2738 - val_recall: 0.9200 - val_auc: 0.5295\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8888 - tp: 101.0000 - fp: 163.0000 - tn: 200.0000 - fn: 19.0000 - accuracy: 0.6232 - precision: 0.3826 - recall: 0.8417 - auc: 0.7352 - val_loss: 0.6706 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.6328\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.8926 - tp: 102.0000 - fp: 175.0000 - tn: 188.0000 - fn: 18.0000 - accuracy: 0.6004 - precision: 0.3682 - recall: 0.8500 - auc: 0.7411 - val_loss: 0.7126 - val_tp: 23.0000 - val_fp: 63.0000 - val_tn: 15.0000 - val_fn: 2.0000 - val_accuracy: 0.3689 - val_precision: 0.2674 - val_recall: 0.9200 - val_auc: 0.5290\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.9193 - tp: 101.0000 - fp: 186.0000 - tn: 177.0000 - fn: 19.0000 - accuracy: 0.5756 - precision: 0.3519 - recall: 0.8417 - auc: 0.6523 - val_loss: 0.6369 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.6036\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8851 - tp: 102.0000 - fp: 177.0000 - tn: 186.0000 - fn: 18.0000 - accuracy: 0.5963 - precision: 0.3656 - recall: 0.8500 - auc: 0.7215 - val_loss: 0.6454 - val_tp: 22.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 3.0000 - val_accuracy: 0.5534 - val_precision: 0.3385 - val_recall: 0.8800 - val_auc: 0.6203\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8896 - tp: 98.0000 - fp: 147.0000 - tn: 216.0000 - fn: 22.0000 - accuracy: 0.6501 - precision: 0.4000 - recall: 0.8167 - auc: 0.7479 - val_loss: 0.6747 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.6641\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8817 - tp: 103.0000 - fp: 169.0000 - tn: 194.0000 - fn: 17.0000 - accuracy: 0.6149 - precision: 0.3787 - recall: 0.8583 - auc: 0.7274 - val_loss: 0.6683 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.6418\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8538 - tp: 109.0000 - fp: 187.0000 - tn: 176.0000 - fn: 11.0000 - accuracy: 0.5901 - precision: 0.3682 - recall: 0.9083 - auc: 0.7751 - val_loss: 0.6672 - val_tp: 21.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 4.0000 - val_accuracy: 0.5534 - val_precision: 0.3333 - val_recall: 0.8400 - val_auc: 0.6338\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9161 - tp: 94.0000 - fp: 138.0000 - tn: 225.0000 - fn: 26.0000 - accuracy: 0.6605 - precision: 0.4052 - recall: 0.7833 - auc: 0.7317 - val_loss: 0.6914 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.6877\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8411 - tp: 91.0000 - fp: 129.0000 - tn: 234.0000 - fn: 29.0000 - accuracy: 0.6729 - precision: 0.4136 - recall: 0.7583 - auc: 0.7679 - val_loss: 0.6881 - val_tp: 22.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.4369 - val_precision: 0.2857 - val_recall: 0.8800 - val_auc: 0.6428\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8132 - tp: 100.0000 - fp: 154.0000 - tn: 209.0000 - fn: 20.0000 - accuracy: 0.6398 - precision: 0.3937 - recall: 0.8333 - auc: 0.7714 - val_loss: 0.6726 - val_tp: 21.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 4.0000 - val_accuracy: 0.4951 - val_precision: 0.3043 - val_recall: 0.8400 - val_auc: 0.6523\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.8585 - tp: 106.0000 - fp: 174.0000 - tn: 189.0000 - fn: 14.0000 - accuracy: 0.6108 - precision: 0.3786 - recall: 0.8833 - auc: 0.7458 - val_loss: 0.6861 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.6513\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8198 - tp: 108.0000 - fp: 170.0000 - tn: 193.0000 - fn: 12.0000 - accuracy: 0.6232 - precision: 0.3885 - recall: 0.9000 - auc: 0.7820 - val_loss: 0.7131 - val_tp: 22.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.4369 - val_precision: 0.2857 - val_recall: 0.8800 - val_auc: 0.6621\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.7937 - tp: 95.0000 - fp: 120.0000 - tn: 243.0000 - fn: 25.0000 - accuracy: 0.6998 - precision: 0.4419 - recall: 0.7917 - auc: 0.7982 - val_loss: 0.6717 - val_tp: 21.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 4.0000 - val_accuracy: 0.4466 - val_precision: 0.2838 - val_recall: 0.8400 - val_auc: 0.6559\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8003 - tp: 101.0000 - fp: 135.0000 - tn: 228.0000 - fn: 19.0000 - accuracy: 0.6812 - precision: 0.4280 - recall: 0.8417 - auc: 0.7980 - val_loss: 0.6865 - val_tp: 21.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 4.0000 - val_accuracy: 0.4757 - val_precision: 0.2958 - val_recall: 0.8400 - val_auc: 0.6562\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.7863 - tp: 95.0000 - fp: 119.0000 - tn: 244.0000 - fn: 25.0000 - accuracy: 0.7019 - precision: 0.4439 - recall: 0.7917 - auc: 0.8036 - val_loss: 0.6772 - val_tp: 20.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 5.0000 - val_accuracy: 0.4854 - val_precision: 0.2941 - val_recall: 0.8000 - val_auc: 0.6544\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.7710 - tp: 101.0000 - fp: 132.0000 - tn: 231.0000 - fn: 19.0000 - accuracy: 0.6874 - precision: 0.4335 - recall: 0.8417 - auc: 0.7974 - val_loss: 0.6945 - val_tp: 21.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 4.0000 - val_accuracy: 0.4369 - val_precision: 0.2800 - val_recall: 0.8400 - val_auc: 0.6605\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.7677 - tp: 106.0000 - fp: 137.0000 - tn: 226.0000 - fn: 14.0000 - accuracy: 0.6874 - precision: 0.4362 - recall: 0.8833 - auc: 0.8081 - val_loss: 0.7192 - val_tp: 22.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.4369 - val_precision: 0.2857 - val_recall: 0.8800 - val_auc: 0.6762\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.7782 - tp: 108.0000 - fp: 152.0000 - tn: 211.0000 - fn: 12.0000 - accuracy: 0.6605 - precision: 0.4154 - recall: 0.9000 - auc: 0.7952 - val_loss: 0.6934 - val_tp: 21.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 4.0000 - val_accuracy: 0.4660 - val_precision: 0.2917 - val_recall: 0.8400 - val_auc: 0.6418\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.7917 - tp: 101.0000 - fp: 142.0000 - tn: 221.0000 - fn: 19.0000 - accuracy: 0.6667 - precision: 0.4156 - recall: 0.8417 - auc: 0.7996 - val_loss: 0.6932 - val_tp: 20.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 5.0000 - val_accuracy: 0.4660 - val_precision: 0.2857 - val_recall: 0.8000 - val_auc: 0.6592\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 0.7436 - tp: 106.0000 - fp: 136.0000 - tn: 227.0000 - fn: 14.0000 - accuracy: 0.6894 - precision: 0.4380 - recall: 0.8833 - auc: 0.8188 - val_loss: 0.6973 - val_tp: 20.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 5.0000 - val_accuracy: 0.4951 - val_precision: 0.2985 - val_recall: 0.8000 - val_auc: 0.6582\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.7333 - tp: 105.0000 - fp: 130.0000 - tn: 233.0000 - fn: 15.0000 - accuracy: 0.6998 - precision: 0.4468 - recall: 0.8750 - auc: 0.8179 - val_loss: 0.6913 - val_tp: 19.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 6.0000 - val_accuracy: 0.4369 - val_precision: 0.2676 - val_recall: 0.7600 - val_auc: 0.6554\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.7954 - tp: 97.0000 - fp: 120.0000 - tn: 243.0000 - fn: 23.0000 - accuracy: 0.7039 - precision: 0.4470 - recall: 0.8083 - auc: 0.8113 - val_loss: 0.7154 - val_tp: 20.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 5.0000 - val_accuracy: 0.4272 - val_precision: 0.2703 - val_recall: 0.8000 - val_auc: 0.6667\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 0.9064 - tp: 110.0000 - fp: 204.0000 - tn: 159.0000 - fn: 10.0000 - accuracy: 0.5569 - precision: 0.3503 - recall: 0.9167 - auc: 0.7470 - val_loss: 0.6488 - val_tp: 17.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 8.0000 - val_accuracy: 0.5631 - val_precision: 0.3148 - val_recall: 0.6800 - val_auc: 0.6572\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.8814 - tp: 78.0000 - fp: 85.0000 - tn: 278.0000 - fn: 42.0000 - accuracy: 0.7371 - precision: 0.4785 - recall: 0.6500 - auc: 0.7618 - val_loss: 0.6442 - val_tp: 18.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 7.0000 - val_accuracy: 0.5534 - val_precision: 0.3158 - val_recall: 0.7200 - val_auc: 0.6710\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8090 - tp: 97.0000 - fp: 127.0000 - tn: 236.0000 - fn: 23.0000 - accuracy: 0.6894 - precision: 0.4330 - recall: 0.8083 - auc: 0.7884 - val_loss: 0.6538 - val_tp: 20.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 5.0000 - val_accuracy: 0.5146 - val_precision: 0.3077 - val_recall: 0.8000 - val_auc: 0.6826\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.7413 - tp: 100.0000 - fp: 117.0000 - tn: 246.0000 - fn: 20.0000 - accuracy: 0.7164 - precision: 0.4608 - recall: 0.8333 - auc: 0.8366 - val_loss: 0.6983 - val_tp: 19.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 6.0000 - val_accuracy: 0.4757 - val_precision: 0.2836 - val_recall: 0.7600 - val_auc: 0.6490\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.7821 - tp: 97.0000 - fp: 138.0000 - tn: 225.0000 - fn: 23.0000 - accuracy: 0.6667 - precision: 0.4128 - recall: 0.8083 - auc: 0.7972 - val_loss: 0.6661 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.6797\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.7893 - tp: 104.0000 - fp: 143.0000 - tn: 220.0000 - fn: 16.0000 - accuracy: 0.6708 - precision: 0.4211 - recall: 0.8667 - auc: 0.7940 - val_loss: 0.6588 - val_tp: 19.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 6.0000 - val_accuracy: 0.5243 - val_precision: 0.3065 - val_recall: 0.7600 - val_auc: 0.6413\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.7481 - tp: 102.0000 - fp: 130.0000 - tn: 233.0000 - fn: 18.0000 - accuracy: 0.6936 - precision: 0.4397 - recall: 0.8500 - auc: 0.8171 - val_loss: 0.7345 - val_tp: 17.0000 - val_fp: 32.0000 - val_tn: 46.0000 - val_fn: 8.0000 - val_accuracy: 0.6117 - val_precision: 0.3469 - val_recall: 0.6800 - val_auc: 0.6746\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.7832 - tp: 100.0000 - fp: 122.0000 - tn: 241.0000 - fn: 20.0000 - accuracy: 0.7060 - precision: 0.4505 - recall: 0.8333 - auc: 0.8144 - val_loss: 0.5820 - val_tp: 15.0000 - val_fp: 20.0000 - val_tn: 58.0000 - val_fn: 10.0000 - val_accuracy: 0.7087 - val_precision: 0.4286 - val_recall: 0.6000 - val_auc: 0.7174\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.7853 - tp: 99.0000 - fp: 127.0000 - tn: 236.0000 - fn: 21.0000 - accuracy: 0.6936 - precision: 0.4381 - recall: 0.8250 - auc: 0.8201 - val_loss: 0.6679 - val_tp: 18.0000 - val_fp: 34.0000 - val_tn: 44.0000 - val_fn: 7.0000 - val_accuracy: 0.6019 - val_precision: 0.3462 - val_recall: 0.7200 - val_auc: 0.6828\n",
      "Calculated mean IoU: 0.0000\n",
      "IoU from saved model: 0.585\n",
      "No Model update.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 4s 265ms/step - loss: 20.4787 - tp: 92.0000 - fp: 244.0000 - tn: 197.0000 - fn: 53.0000 - accuracy: 0.4932 - precision: 0.2738 - recall: 0.6345 - auc: 0.5161 - val_loss: 0.7269 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.4918\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0579 - tp: 49.0000 - fp: 136.0000 - tn: 227.0000 - fn: 71.0000 - accuracy: 0.5714 - precision: 0.2649 - recall: 0.4083 - auc: 0.4883 - val_loss: 0.7022 - val_tp: 25.0000 - val_fp: 76.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2621 - val_precision: 0.2475 - val_recall: 1.0000 - val_auc: 0.5090\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 1.0237 - tp: 97.0000 - fp: 242.0000 - tn: 121.0000 - fn: 23.0000 - accuracy: 0.4513 - precision: 0.2861 - recall: 0.8083 - auc: 0.6009 - val_loss: 0.6983 - val_tp: 24.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 1.0000 - val_accuracy: 0.3981 - val_precision: 0.2824 - val_recall: 0.9600 - val_auc: 0.5821\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9981 - tp: 82.0000 - fp: 169.0000 - tn: 194.0000 - fn: 38.0000 - accuracy: 0.5714 - precision: 0.3267 - recall: 0.6833 - auc: 0.6471 - val_loss: 0.7358 - val_tp: 25.0000 - val_fp: 76.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2621 - val_precision: 0.2475 - val_recall: 1.0000 - val_auc: 0.6085\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 1.0412 - tp: 66.0000 - fp: 190.0000 - tn: 173.0000 - fn: 54.0000 - accuracy: 0.4948 - precision: 0.2578 - recall: 0.5500 - auc: 0.5245 - val_loss: 0.7022 - val_tp: 25.0000 - val_fp: 76.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2621 - val_precision: 0.2475 - val_recall: 1.0000 - val_auc: 0.6062\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 1.0316 - tp: 97.0000 - fp: 267.0000 - tn: 96.0000 - fn: 23.0000 - accuracy: 0.3996 - precision: 0.2665 - recall: 0.8083 - auc: 0.5914 - val_loss: 0.6947 - val_tp: 20.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 5.0000 - val_accuracy: 0.4369 - val_precision: 0.2740 - val_recall: 0.8000 - val_auc: 0.6631\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 1.0076 - tp: 87.0000 - fp: 198.0000 - tn: 165.0000 - fn: 33.0000 - accuracy: 0.5217 - precision: 0.3053 - recall: 0.7250 - auc: 0.6332 - val_loss: 0.7106 - val_tp: 25.0000 - val_fp: 62.0000 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3981 - val_precision: 0.2874 - val_recall: 1.0000 - val_auc: 0.7090\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9432 - tp: 98.0000 - fp: 149.0000 - tn: 214.0000 - fn: 22.0000 - accuracy: 0.6460 - precision: 0.3968 - recall: 0.8167 - auc: 0.7380 - val_loss: 0.6387 - val_tp: 19.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 6.0000 - val_accuracy: 0.5728 - val_precision: 0.3333 - val_recall: 0.7600 - val_auc: 0.7085\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0230 - tp: 55.0000 - fp: 112.0000 - tn: 251.0000 - fn: 65.0000 - accuracy: 0.6335 - precision: 0.3293 - recall: 0.4583 - auc: 0.6325 - val_loss: 0.6415 - val_tp: 19.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 6.0000 - val_accuracy: 0.5631 - val_precision: 0.3276 - val_recall: 0.7600 - val_auc: 0.7126\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.9776 - tp: 103.0000 - fp: 176.0000 - tn: 187.0000 - fn: 17.0000 - accuracy: 0.6004 - precision: 0.3692 - recall: 0.8583 - auc: 0.6822 - val_loss: 0.6686 - val_tp: 23.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 2.0000 - val_accuracy: 0.4466 - val_precision: 0.2949 - val_recall: 0.9200 - val_auc: 0.6682\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.9071 - tp: 104.0000 - fp: 179.0000 - tn: 184.0000 - fn: 16.0000 - accuracy: 0.5963 - precision: 0.3675 - recall: 0.8667 - auc: 0.7161 - val_loss: 0.6710 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.6836\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9187 - tp: 103.0000 - fp: 183.0000 - tn: 180.0000 - fn: 17.0000 - accuracy: 0.5859 - precision: 0.3601 - recall: 0.8583 - auc: 0.7197 - val_loss: 0.6190 - val_tp: 20.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 5.0000 - val_accuracy: 0.5340 - val_precision: 0.3175 - val_recall: 0.8000 - val_auc: 0.6726\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8985 - tp: 103.0000 - fp: 177.0000 - tn: 186.0000 - fn: 17.0000 - accuracy: 0.5983 - precision: 0.3679 - recall: 0.8583 - auc: 0.7248 - val_loss: 0.6541 - val_tp: 22.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 3.0000 - val_accuracy: 0.4951 - val_precision: 0.3099 - val_recall: 0.8800 - val_auc: 0.6679\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8824 - tp: 103.0000 - fp: 167.0000 - tn: 196.0000 - fn: 17.0000 - accuracy: 0.6190 - precision: 0.3815 - recall: 0.8583 - auc: 0.7335 - val_loss: 0.7185 - val_tp: 23.0000 - val_fp: 62.0000 - val_tn: 16.0000 - val_fn: 2.0000 - val_accuracy: 0.3786 - val_precision: 0.2706 - val_recall: 0.9200 - val_auc: 0.6664\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8999 - tp: 111.0000 - fp: 219.0000 - tn: 144.0000 - fn: 9.0000 - accuracy: 0.5280 - precision: 0.3364 - recall: 0.9250 - auc: 0.7371 - val_loss: 0.6114 - val_tp: 19.0000 - val_fp: 34.0000 - val_tn: 44.0000 - val_fn: 6.0000 - val_accuracy: 0.6117 - val_precision: 0.3585 - val_recall: 0.7600 - val_auc: 0.6779\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 200ms/step - loss: 1.0138 - tp: 114.0000 - fp: 286.0000 - tn: 77.0000 - fn: 6.0000 - accuracy: 0.3954 - precision: 0.2850 - recall: 0.9500 - auc: 0.6809 - val_loss: 0.7137 - val_tp: 25.0000 - val_fp: 72.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3010 - val_precision: 0.2577 - val_recall: 1.0000 - val_auc: 0.6300\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.9628 - tp: 110.0000 - fp: 213.0000 - tn: 150.0000 - fn: 10.0000 - accuracy: 0.5383 - precision: 0.3406 - recall: 0.9167 - auc: 0.7160 - val_loss: 0.6867 - val_tp: 20.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 5.0000 - val_accuracy: 0.4563 - val_precision: 0.2817 - val_recall: 0.8000 - val_auc: 0.6528\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9514 - tp: 76.0000 - fp: 142.0000 - tn: 221.0000 - fn: 44.0000 - accuracy: 0.6149 - precision: 0.3486 - recall: 0.6333 - auc: 0.6917 - val_loss: 0.7217 - val_tp: 23.0000 - val_fp: 62.0000 - val_tn: 16.0000 - val_fn: 2.0000 - val_accuracy: 0.3786 - val_precision: 0.2706 - val_recall: 0.9200 - val_auc: 0.6872\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.9127 - tp: 85.0000 - fp: 133.0000 - tn: 230.0000 - fn: 35.0000 - accuracy: 0.6522 - precision: 0.3899 - recall: 0.7083 - auc: 0.7243 - val_loss: 0.7260 - val_tp: 23.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.4175 - val_precision: 0.2840 - val_recall: 0.9200 - val_auc: 0.7136\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.9148 - tp: 93.0000 - fp: 133.0000 - tn: 230.0000 - fn: 27.0000 - accuracy: 0.6687 - precision: 0.4115 - recall: 0.7750 - auc: 0.7360 - val_loss: 0.6997 - val_tp: 23.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 2.0000 - val_accuracy: 0.4466 - val_precision: 0.2949 - val_recall: 0.9200 - val_auc: 0.7049\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8880 - tp: 96.0000 - fp: 157.0000 - tn: 206.0000 - fn: 24.0000 - accuracy: 0.6253 - precision: 0.3794 - recall: 0.8000 - auc: 0.7528 - val_loss: 0.7082 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.7621\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.9023 - tp: 83.0000 - fp: 118.0000 - tn: 245.0000 - fn: 37.0000 - accuracy: 0.6791 - precision: 0.4129 - recall: 0.6917 - auc: 0.7550 - val_loss: 0.6784 - val_tp: 22.0000 - val_fp: 35.0000 - val_tn: 43.0000 - val_fn: 3.0000 - val_accuracy: 0.6311 - val_precision: 0.3860 - val_recall: 0.8800 - val_auc: 0.7844\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8344 - tp: 100.0000 - fp: 144.0000 - tn: 219.0000 - fn: 20.0000 - accuracy: 0.6605 - precision: 0.4098 - recall: 0.8333 - auc: 0.7853 - val_loss: 0.6702 - val_tp: 23.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 2.0000 - val_accuracy: 0.5049 - val_precision: 0.3194 - val_recall: 0.9200 - val_auc: 0.7926\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.9053 - tp: 109.0000 - fp: 192.0000 - tn: 171.0000 - fn: 11.0000 - accuracy: 0.5797 - precision: 0.3621 - recall: 0.9083 - auc: 0.7686 - val_loss: 0.6755 - val_tp: 22.0000 - val_fp: 34.0000 - val_tn: 44.0000 - val_fn: 3.0000 - val_accuracy: 0.6408 - val_precision: 0.3929 - val_recall: 0.8800 - val_auc: 0.7859\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8314 - tp: 104.0000 - fp: 140.0000 - tn: 223.0000 - fn: 16.0000 - accuracy: 0.6770 - precision: 0.4262 - recall: 0.8667 - auc: 0.8095 - val_loss: 0.4511 - val_tp: 5.0000 - val_fp: 2.0000 - val_tn: 76.0000 - val_fn: 20.0000 - val_accuracy: 0.7864 - val_precision: 0.7143 - val_recall: 0.2000 - val_auc: 0.8246\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8355 - tp: 98.0000 - fp: 138.0000 - tn: 225.0000 - fn: 22.0000 - accuracy: 0.6687 - precision: 0.4153 - recall: 0.8167 - auc: 0.7931 - val_loss: 0.6620 - val_tp: 23.0000 - val_fp: 34.0000 - val_tn: 44.0000 - val_fn: 2.0000 - val_accuracy: 0.6505 - val_precision: 0.4035 - val_recall: 0.9200 - val_auc: 0.8285\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8201 - tp: 100.0000 - fp: 114.0000 - tn: 249.0000 - fn: 20.0000 - accuracy: 0.7226 - precision: 0.4673 - recall: 0.8333 - auc: 0.8030 - val_loss: 0.6843 - val_tp: 23.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 2.0000 - val_accuracy: 0.4854 - val_precision: 0.3108 - val_recall: 0.9200 - val_auc: 0.8477\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8032 - tp: 102.0000 - fp: 131.0000 - tn: 232.0000 - fn: 18.0000 - accuracy: 0.6915 - precision: 0.4378 - recall: 0.8500 - auc: 0.8107 - val_loss: 0.6859 - val_tp: 23.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 2.0000 - val_accuracy: 0.5437 - val_precision: 0.3382 - val_recall: 0.9200 - val_auc: 0.8446\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.7730 - tp: 100.0000 - fp: 109.0000 - tn: 254.0000 - fn: 20.0000 - accuracy: 0.7329 - precision: 0.4785 - recall: 0.8333 - auc: 0.8300 - val_loss: 0.6703 - val_tp: 21.0000 - val_fp: 21.0000 - val_tn: 57.0000 - val_fn: 4.0000 - val_accuracy: 0.7573 - val_precision: 0.5000 - val_recall: 0.8400 - val_auc: 0.8310\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.6974 - tp: 99.0000 - fp: 91.0000 - tn: 272.0000 - fn: 21.0000 - accuracy: 0.7681 - precision: 0.5211 - recall: 0.8250 - auc: 0.8612 - val_loss: 0.5786 - val_tp: 19.0000 - val_fp: 15.0000 - val_tn: 63.0000 - val_fn: 6.0000 - val_accuracy: 0.7961 - val_precision: 0.5588 - val_recall: 0.7600 - val_auc: 0.8326\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.6792 - tp: 102.0000 - fp: 81.0000 - tn: 282.0000 - fn: 18.0000 - accuracy: 0.7950 - precision: 0.5574 - recall: 0.8500 - auc: 0.8672 - val_loss: 0.5317 - val_tp: 17.0000 - val_fp: 12.0000 - val_tn: 66.0000 - val_fn: 8.0000 - val_accuracy: 0.8058 - val_precision: 0.5862 - val_recall: 0.6800 - val_auc: 0.8236\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8148 - tp: 95.0000 - fp: 96.0000 - tn: 267.0000 - fn: 25.0000 - accuracy: 0.7495 - precision: 0.4974 - recall: 0.7917 - auc: 0.8308 - val_loss: 0.6645 - val_tp: 20.0000 - val_fp: 29.0000 - val_tn: 49.0000 - val_fn: 5.0000 - val_accuracy: 0.6699 - val_precision: 0.4082 - val_recall: 0.8000 - val_auc: 0.7836\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.7303 - tp: 96.0000 - fp: 92.0000 - tn: 271.0000 - fn: 24.0000 - accuracy: 0.7598 - precision: 0.5106 - recall: 0.8000 - auc: 0.8514 - val_loss: 0.6932 - val_tp: 23.0000 - val_fp: 36.0000 - val_tn: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.6311 - val_precision: 0.3898 - val_recall: 0.9200 - val_auc: 0.8387\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.6821 - tp: 99.0000 - fp: 76.0000 - tn: 287.0000 - fn: 21.0000 - accuracy: 0.7992 - precision: 0.5657 - recall: 0.8250 - auc: 0.8707 - val_loss: 0.5469 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 62.0000 - val_fn: 9.0000 - val_accuracy: 0.7573 - val_precision: 0.5000 - val_recall: 0.6400 - val_auc: 0.8433\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.6542 - tp: 97.0000 - fp: 73.0000 - tn: 290.0000 - fn: 23.0000 - accuracy: 0.8012 - precision: 0.5706 - recall: 0.8083 - auc: 0.8794 - val_loss: 0.5770 - val_tp: 20.0000 - val_fp: 18.0000 - val_tn: 60.0000 - val_fn: 5.0000 - val_accuracy: 0.7767 - val_precision: 0.5263 - val_recall: 0.8000 - val_auc: 0.8523\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 7s 439ms/step - loss: 0.6467 - tp: 94.0000 - fp: 57.0000 - tn: 306.0000 - fn: 26.0000 - accuracy: 0.8282 - precision: 0.6225 - recall: 0.7833 - auc: 0.8876 - val_loss: 0.5210 - val_tp: 17.0000 - val_fp: 16.0000 - val_tn: 62.0000 - val_fn: 8.0000 - val_accuracy: 0.7670 - val_precision: 0.5152 - val_recall: 0.6800 - val_auc: 0.8149\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 7s 429ms/step - loss: 0.6396 - tp: 106.0000 - fp: 93.0000 - tn: 270.0000 - fn: 14.0000 - accuracy: 0.7785 - precision: 0.5327 - recall: 0.8833 - auc: 0.8900 - val_loss: 0.5170 - val_tp: 14.0000 - val_fp: 10.0000 - val_tn: 68.0000 - val_fn: 11.0000 - val_accuracy: 0.7961 - val_precision: 0.5833 - val_recall: 0.5600 - val_auc: 0.8031\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 5s 331ms/step - loss: 0.6238 - tp: 96.0000 - fp: 66.0000 - tn: 297.0000 - fn: 24.0000 - accuracy: 0.8137 - precision: 0.5926 - recall: 0.8000 - auc: 0.8920 - val_loss: 0.5637 - val_tp: 17.0000 - val_fp: 17.0000 - val_tn: 61.0000 - val_fn: 8.0000 - val_accuracy: 0.7573 - val_precision: 0.5000 - val_recall: 0.6800 - val_auc: 0.7803\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.5935 - tp: 104.0000 - fp: 77.0000 - tn: 286.0000 - fn: 16.0000 - accuracy: 0.8075 - precision: 0.5746 - recall: 0.8667 - auc: 0.9039 - val_loss: 0.6233 - val_tp: 18.0000 - val_fp: 18.0000 - val_tn: 60.0000 - val_fn: 7.0000 - val_accuracy: 0.7573 - val_precision: 0.5000 - val_recall: 0.7200 - val_auc: 0.7505\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.6116 - tp: 92.0000 - fp: 44.0000 - tn: 319.0000 - fn: 28.0000 - accuracy: 0.8509 - precision: 0.6765 - recall: 0.7667 - auc: 0.9045 - val_loss: 0.5899 - val_tp: 18.0000 - val_fp: 15.0000 - val_tn: 63.0000 - val_fn: 7.0000 - val_accuracy: 0.7864 - val_precision: 0.5455 - val_recall: 0.7200 - val_auc: 0.7810\n",
      "Calculated mean IoU: 0.4465\n",
      "IoU from saved model: 0.585\n",
      "No Model update.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 5s 282ms/step - loss: 24.2462 - tp: 72.0000 - fp: 237.0000 - tn: 204.0000 - fn: 73.0000 - accuracy: 0.4710 - precision: 0.2330 - recall: 0.4966 - auc: 0.4582 - val_loss: 0.7044 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.4744\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 1.0419 - tp: 60.0000 - fp: 173.0000 - tn: 190.0000 - fn: 60.0000 - accuracy: 0.5176 - precision: 0.2575 - recall: 0.5000 - auc: 0.5146 - val_loss: 0.6967 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.5128\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0407 - tp: 108.0000 - fp: 319.0000 - tn: 44.0000 - fn: 12.0000 - accuracy: 0.3147 - precision: 0.2529 - recall: 0.9000 - auc: 0.5764 - val_loss: 0.6948 - val_tp: 25.0000 - val_fp: 77.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2524 - val_precision: 0.2451 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0357 - tp: 74.0000 - fp: 193.0000 - tn: 170.0000 - fn: 46.0000 - accuracy: 0.5052 - precision: 0.2772 - recall: 0.6167 - auc: 0.5681 - val_loss: 0.7036 - val_tp: 25.0000 - val_fp: 74.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2816 - val_precision: 0.2525 - val_recall: 1.0000 - val_auc: 0.5797\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 1.0435 - tp: 50.0000 - fp: 129.0000 - tn: 234.0000 - fn: 70.0000 - accuracy: 0.5880 - precision: 0.2793 - recall: 0.4167 - auc: 0.5390 - val_loss: 0.6967 - val_tp: 25.0000 - val_fp: 74.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2816 - val_precision: 0.2525 - val_recall: 1.0000 - val_auc: 0.5751\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 205ms/step - loss: 1.0362 - tp: 94.0000 - fp: 249.0000 - tn: 114.0000 - fn: 26.0000 - accuracy: 0.4306 - precision: 0.2741 - recall: 0.7833 - auc: 0.5581 - val_loss: 0.6974 - val_tp: 21.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 4.0000 - val_accuracy: 0.3981 - val_precision: 0.2658 - val_recall: 0.8400 - val_auc: 0.5979\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 1.0119 - tp: 78.0000 - fp: 160.0000 - tn: 203.0000 - fn: 42.0000 - accuracy: 0.5818 - precision: 0.3277 - recall: 0.6500 - auc: 0.6195 - val_loss: 0.6998 - val_tp: 20.0000 - val_fp: 59.0000 - val_tn: 19.0000 - val_fn: 5.0000 - val_accuracy: 0.3786 - val_precision: 0.2532 - val_recall: 0.8000 - val_auc: 0.6246\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9877 - tp: 61.0000 - fp: 113.0000 - tn: 250.0000 - fn: 59.0000 - accuracy: 0.6439 - precision: 0.3506 - recall: 0.5083 - auc: 0.6368 - val_loss: 0.8816 - val_tp: 25.0000 - val_fp: 68.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3398 - val_precision: 0.2688 - val_recall: 1.0000 - val_auc: 0.6585\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9735 - tp: 84.0000 - fp: 154.0000 - tn: 209.0000 - fn: 36.0000 - accuracy: 0.6066 - precision: 0.3529 - recall: 0.7000 - auc: 0.6769 - val_loss: 0.6974 - val_tp: 22.0000 - val_fp: 60.0000 - val_tn: 18.0000 - val_fn: 3.0000 - val_accuracy: 0.3883 - val_precision: 0.2683 - val_recall: 0.8800 - val_auc: 0.6497\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9559 - tp: 84.0000 - fp: 148.0000 - tn: 215.0000 - fn: 36.0000 - accuracy: 0.6190 - precision: 0.3621 - recall: 0.7000 - auc: 0.6915 - val_loss: 0.6643 - val_tp: 19.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 6.0000 - val_accuracy: 0.4466 - val_precision: 0.2714 - val_recall: 0.7600 - val_auc: 0.6713\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.9221 - tp: 94.0000 - fp: 164.0000 - tn: 199.0000 - fn: 26.0000 - accuracy: 0.6066 - precision: 0.3643 - recall: 0.7833 - auc: 0.7151 - val_loss: 0.6615 - val_tp: 22.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 3.0000 - val_accuracy: 0.5049 - val_precision: 0.3143 - val_recall: 0.8800 - val_auc: 0.6582\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.9772 - tp: 108.0000 - fp: 205.0000 - tn: 158.0000 - fn: 12.0000 - accuracy: 0.5507 - precision: 0.3450 - recall: 0.9000 - auc: 0.6600 - val_loss: 0.6302 - val_tp: 21.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 4.0000 - val_accuracy: 0.5049 - val_precision: 0.3088 - val_recall: 0.8400 - val_auc: 0.6482\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9114 - tp: 107.0000 - fp: 190.0000 - tn: 173.0000 - fn: 13.0000 - accuracy: 0.5797 - precision: 0.3603 - recall: 0.8917 - auc: 0.7210 - val_loss: 0.6363 - val_tp: 22.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 3.0000 - val_accuracy: 0.4951 - val_precision: 0.3099 - val_recall: 0.8800 - val_auc: 0.6285\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.9074 - tp: 110.0000 - fp: 202.0000 - tn: 161.0000 - fn: 10.0000 - accuracy: 0.5611 - precision: 0.3526 - recall: 0.9167 - auc: 0.7000 - val_loss: 0.6487 - val_tp: 22.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 3.0000 - val_accuracy: 0.5146 - val_precision: 0.3188 - val_recall: 0.8800 - val_auc: 0.7082\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9538 - tp: 99.0000 - fp: 198.0000 - tn: 165.0000 - fn: 21.0000 - accuracy: 0.5466 - precision: 0.3333 - recall: 0.8250 - auc: 0.6814 - val_loss: 0.5897 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6056\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9302 - tp: 93.0000 - fp: 159.0000 - tn: 204.0000 - fn: 27.0000 - accuracy: 0.6149 - precision: 0.3690 - recall: 0.7750 - auc: 0.7154 - val_loss: 0.7169 - val_tp: 23.0000 - val_fp: 60.0000 - val_tn: 18.0000 - val_fn: 2.0000 - val_accuracy: 0.3981 - val_precision: 0.2771 - val_recall: 0.9200 - val_auc: 0.6515\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8770 - tp: 96.0000 - fp: 166.0000 - tn: 197.0000 - fn: 24.0000 - accuracy: 0.6066 - precision: 0.3664 - recall: 0.8000 - auc: 0.7398 - val_loss: 0.6719 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.6744\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.8704 - tp: 107.0000 - fp: 186.0000 - tn: 177.0000 - fn: 13.0000 - accuracy: 0.5880 - precision: 0.3652 - recall: 0.8917 - auc: 0.7325 - val_loss: 0.6673 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.6664\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8337 - tp: 95.0000 - fp: 152.0000 - tn: 211.0000 - fn: 25.0000 - accuracy: 0.6335 - precision: 0.3846 - recall: 0.7917 - auc: 0.7672 - val_loss: 0.7051 - val_tp: 21.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 4.0000 - val_accuracy: 0.4951 - val_precision: 0.3043 - val_recall: 0.8400 - val_auc: 0.6503\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8389 - tp: 105.0000 - fp: 158.0000 - tn: 205.0000 - fn: 15.0000 - accuracy: 0.6418 - precision: 0.3992 - recall: 0.8750 - auc: 0.7501 - val_loss: 0.6342 - val_tp: 20.0000 - val_fp: 40.0000 - val_tn: 38.0000 - val_fn: 5.0000 - val_accuracy: 0.5631 - val_precision: 0.3333 - val_recall: 0.8000 - val_auc: 0.6536\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.8440 - tp: 105.0000 - fp: 154.0000 - tn: 209.0000 - fn: 15.0000 - accuracy: 0.6501 - precision: 0.4054 - recall: 0.8750 - auc: 0.7643 - val_loss: 0.7195 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.6421\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.8460 - tp: 102.0000 - fp: 161.0000 - tn: 202.0000 - fn: 18.0000 - accuracy: 0.6294 - precision: 0.3878 - recall: 0.8500 - auc: 0.7670 - val_loss: 0.6897 - val_tp: 19.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 6.0000 - val_accuracy: 0.4854 - val_precision: 0.2879 - val_recall: 0.7600 - val_auc: 0.6318\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8205 - tp: 93.0000 - fp: 131.0000 - tn: 232.0000 - fn: 27.0000 - accuracy: 0.6729 - precision: 0.4152 - recall: 0.7750 - auc: 0.7804 - val_loss: 0.6704 - val_tp: 19.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 6.0000 - val_accuracy: 0.4951 - val_precision: 0.2923 - val_recall: 0.7600 - val_auc: 0.6551\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8004 - tp: 103.0000 - fp: 168.0000 - tn: 195.0000 - fn: 17.0000 - accuracy: 0.6170 - precision: 0.3801 - recall: 0.8583 - auc: 0.7959 - val_loss: 0.7188 - val_tp: 19.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 6.0000 - val_accuracy: 0.5049 - val_precision: 0.2969 - val_recall: 0.7600 - val_auc: 0.6469\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8222 - tp: 97.0000 - fp: 148.0000 - tn: 215.0000 - fn: 23.0000 - accuracy: 0.6460 - precision: 0.3959 - recall: 0.8083 - auc: 0.7688 - val_loss: 0.6686 - val_tp: 19.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 6.0000 - val_accuracy: 0.5146 - val_precision: 0.3016 - val_recall: 0.7600 - val_auc: 0.6462\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8021 - tp: 101.0000 - fp: 132.0000 - tn: 231.0000 - fn: 19.0000 - accuracy: 0.6874 - precision: 0.4335 - recall: 0.8417 - auc: 0.7825 - val_loss: 0.6716 - val_tp: 19.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 6.0000 - val_accuracy: 0.5340 - val_precision: 0.3115 - val_recall: 0.7600 - val_auc: 0.6505\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.7636 - tp: 101.0000 - fp: 134.0000 - tn: 229.0000 - fn: 19.0000 - accuracy: 0.6832 - precision: 0.4298 - recall: 0.8417 - auc: 0.8144 - val_loss: 0.7284 - val_tp: 19.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 6.0000 - val_accuracy: 0.5340 - val_precision: 0.3115 - val_recall: 0.7600 - val_auc: 0.6826\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.7480 - tp: 100.0000 - fp: 114.0000 - tn: 249.0000 - fn: 20.0000 - accuracy: 0.7226 - precision: 0.4673 - recall: 0.8333 - auc: 0.8254 - val_loss: 0.6517 - val_tp: 16.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 9.0000 - val_accuracy: 0.5534 - val_precision: 0.3019 - val_recall: 0.6400 - val_auc: 0.6536\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.7594 - tp: 89.0000 - fp: 88.0000 - tn: 275.0000 - fn: 31.0000 - accuracy: 0.7536 - precision: 0.5028 - recall: 0.7417 - auc: 0.8305 - val_loss: 0.7792 - val_tp: 20.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 5.0000 - val_accuracy: 0.4854 - val_precision: 0.2941 - val_recall: 0.8000 - val_auc: 0.6246\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8438 - tp: 105.0000 - fp: 160.0000 - tn: 203.0000 - fn: 15.0000 - accuracy: 0.6377 - precision: 0.3962 - recall: 0.8750 - auc: 0.8076 - val_loss: 0.7112 - val_tp: 23.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 2.0000 - val_accuracy: 0.4563 - val_precision: 0.2987 - val_recall: 0.9200 - val_auc: 0.7290\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.7942 - tp: 101.0000 - fp: 136.0000 - tn: 227.0000 - fn: 19.0000 - accuracy: 0.6791 - precision: 0.4262 - recall: 0.8417 - auc: 0.8179 - val_loss: 0.7045 - val_tp: 20.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 5.0000 - val_accuracy: 0.5146 - val_precision: 0.3077 - val_recall: 0.8000 - val_auc: 0.7256\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.7146 - tp: 100.0000 - fp: 114.0000 - tn: 249.0000 - fn: 20.0000 - accuracy: 0.7226 - precision: 0.4673 - recall: 0.8333 - auc: 0.8468 - val_loss: 0.6403 - val_tp: 20.0000 - val_fp: 24.0000 - val_tn: 54.0000 - val_fn: 5.0000 - val_accuracy: 0.7184 - val_precision: 0.4545 - val_recall: 0.8000 - val_auc: 0.7805\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.7145 - tp: 107.0000 - fp: 124.0000 - tn: 239.0000 - fn: 13.0000 - accuracy: 0.7164 - precision: 0.4632 - recall: 0.8917 - auc: 0.8522 - val_loss: 0.6168 - val_tp: 13.0000 - val_fp: 10.0000 - val_tn: 68.0000 - val_fn: 12.0000 - val_accuracy: 0.7864 - val_precision: 0.5652 - val_recall: 0.5200 - val_auc: 0.7592\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8676 - tp: 80.0000 - fp: 112.0000 - tn: 251.0000 - fn: 40.0000 - accuracy: 0.6853 - precision: 0.4167 - recall: 0.6667 - auc: 0.7652 - val_loss: 0.7186 - val_tp: 21.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 4.0000 - val_accuracy: 0.3689 - val_precision: 0.2561 - val_recall: 0.8400 - val_auc: 0.5531\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.8293 - tp: 79.0000 - fp: 110.0000 - tn: 253.0000 - fn: 41.0000 - accuracy: 0.6874 - precision: 0.4180 - recall: 0.6583 - auc: 0.7672 - val_loss: 0.7075 - val_tp: 20.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 5.0000 - val_accuracy: 0.5340 - val_precision: 0.3175 - val_recall: 0.8000 - val_auc: 0.6867\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.7824 - tp: 113.0000 - fp: 183.0000 - tn: 180.0000 - fn: 7.0000 - accuracy: 0.6066 - precision: 0.3818 - recall: 0.9417 - auc: 0.8044 - val_loss: 0.7526 - val_tp: 21.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 4.0000 - val_accuracy: 0.5825 - val_precision: 0.3500 - val_recall: 0.8400 - val_auc: 0.7595\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.7357 - tp: 103.0000 - fp: 129.0000 - tn: 234.0000 - fn: 17.0000 - accuracy: 0.6977 - precision: 0.4440 - recall: 0.8583 - auc: 0.8248 - val_loss: 0.7191 - val_tp: 21.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 4.0000 - val_accuracy: 0.5825 - val_precision: 0.3500 - val_recall: 0.8400 - val_auc: 0.7413\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.6695 - tp: 105.0000 - fp: 115.0000 - tn: 248.0000 - fn: 15.0000 - accuracy: 0.7308 - precision: 0.4773 - recall: 0.8750 - auc: 0.8702 - val_loss: 0.8331 - val_tp: 21.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 4.0000 - val_accuracy: 0.6019 - val_precision: 0.3621 - val_recall: 0.8400 - val_auc: 0.7790\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.6583 - tp: 97.0000 - fp: 105.0000 - tn: 258.0000 - fn: 23.0000 - accuracy: 0.7350 - precision: 0.4802 - recall: 0.8083 - auc: 0.8740 - val_loss: 0.7054 - val_tp: 19.0000 - val_fp: 24.0000 - val_tn: 54.0000 - val_fn: 6.0000 - val_accuracy: 0.7087 - val_precision: 0.4419 - val_recall: 0.7600 - val_auc: 0.7564\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.6163 - tp: 97.0000 - fp: 84.0000 - tn: 279.0000 - fn: 23.0000 - accuracy: 0.7785 - precision: 0.5359 - recall: 0.8083 - auc: 0.8912 - val_loss: 0.7396 - val_tp: 21.0000 - val_fp: 31.0000 - val_tn: 47.0000 - val_fn: 4.0000 - val_accuracy: 0.6602 - val_precision: 0.4038 - val_recall: 0.8400 - val_auc: 0.7515\n",
      "Calculated mean IoU: 0.5448\n",
      "IoU from saved model: 0.585\n",
      "No Model update.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 5s 291ms/step - loss: 41.5166 - tp: 79.0000 - fp: 196.0000 - tn: 245.0000 - fn: 66.0000 - accuracy: 0.5529 - precision: 0.2873 - recall: 0.5448 - auc: 0.5693 - val_loss: 0.6995 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.5015\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 1.0454 - tp: 34.0000 - fp: 107.0000 - tn: 256.0000 - fn: 86.0000 - accuracy: 0.6004 - precision: 0.2411 - recall: 0.2833 - auc: 0.4814 - val_loss: 0.6939 - val_tp: 24.0000 - val_fp: 73.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.2816 - val_precision: 0.2474 - val_recall: 0.9600 - val_auc: 0.5128\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 1.0331 - tp: 59.0000 - fp: 127.0000 - tn: 236.0000 - fn: 61.0000 - accuracy: 0.6108 - precision: 0.3172 - recall: 0.4917 - auc: 0.5897 - val_loss: 0.6179 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7090\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0656 - tp: 75.0000 - fp: 224.0000 - tn: 139.0000 - fn: 45.0000 - accuracy: 0.4431 - precision: 0.2508 - recall: 0.6250 - auc: 0.5286 - val_loss: 0.7016 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.5256\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 1.0404 - tp: 119.0000 - fp: 347.0000 - tn: 16.0000 - fn: 1.0000 - accuracy: 0.2795 - precision: 0.2554 - recall: 0.9917 - auc: 0.5319 - val_loss: 0.6990 - val_tp: 25.0000 - val_fp: 75.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2718 - val_precision: 0.2500 - val_recall: 1.0000 - val_auc: 0.5256\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 1.0308 - tp: 109.0000 - fp: 291.0000 - tn: 72.0000 - fn: 11.0000 - accuracy: 0.3747 - precision: 0.2725 - recall: 0.9083 - auc: 0.6100 - val_loss: 0.7220 - val_tp: 25.0000 - val_fp: 76.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2621 - val_precision: 0.2475 - val_recall: 1.0000 - val_auc: 0.6746\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 1.0548 - tp: 76.0000 - fp: 153.0000 - tn: 210.0000 - fn: 44.0000 - accuracy: 0.5921 - precision: 0.3319 - recall: 0.6333 - auc: 0.6127 - val_loss: 0.7264 - val_tp: 25.0000 - val_fp: 74.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2816 - val_precision: 0.2525 - val_recall: 1.0000 - val_auc: 0.6397\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.0277 - tp: 88.0000 - fp: 244.0000 - tn: 119.0000 - fn: 32.0000 - accuracy: 0.4286 - precision: 0.2651 - recall: 0.7333 - auc: 0.5897 - val_loss: 0.7001 - val_tp: 25.0000 - val_fp: 67.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3495 - val_precision: 0.2717 - val_recall: 1.0000 - val_auc: 0.6097\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 207ms/step - loss: 1.0039 - tp: 72.0000 - fp: 154.0000 - tn: 209.0000 - fn: 48.0000 - accuracy: 0.5818 - precision: 0.3186 - recall: 0.6000 - auc: 0.6355 - val_loss: 0.7347 - val_tp: 25.0000 - val_fp: 67.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3495 - val_precision: 0.2717 - val_recall: 1.0000 - val_auc: 0.6585\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 1.0102 - tp: 98.0000 - fp: 205.0000 - tn: 158.0000 - fn: 22.0000 - accuracy: 0.5300 - precision: 0.3234 - recall: 0.8167 - auc: 0.6781 - val_loss: 0.6863 - val_tp: 24.0000 - val_fp: 63.0000 - val_tn: 15.0000 - val_fn: 1.0000 - val_accuracy: 0.3786 - val_precision: 0.2759 - val_recall: 0.9600 - val_auc: 0.6590\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.9712 - tp: 79.0000 - fp: 114.0000 - tn: 249.0000 - fn: 41.0000 - accuracy: 0.6791 - precision: 0.4093 - recall: 0.6583 - auc: 0.7321 - val_loss: 0.6094 - val_tp: 19.0000 - val_fp: 35.0000 - val_tn: 43.0000 - val_fn: 6.0000 - val_accuracy: 0.6019 - val_precision: 0.3519 - val_recall: 0.7600 - val_auc: 0.6605\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.9054 - tp: 97.0000 - fp: 158.0000 - tn: 205.0000 - fn: 23.0000 - accuracy: 0.6253 - precision: 0.3804 - recall: 0.8083 - auc: 0.7354 - val_loss: 0.6510 - val_tp: 22.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 3.0000 - val_accuracy: 0.4466 - val_precision: 0.2895 - val_recall: 0.8800 - val_auc: 0.6551\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 0.8798 - tp: 102.0000 - fp: 158.0000 - tn: 205.0000 - fn: 18.0000 - accuracy: 0.6356 - precision: 0.3923 - recall: 0.8500 - auc: 0.7739 - val_loss: 0.6704 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.6641\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.8449 - tp: 95.0000 - fp: 124.0000 - tn: 239.0000 - fn: 25.0000 - accuracy: 0.6915 - precision: 0.4338 - recall: 0.7917 - auc: 0.7780 - val_loss: 0.7017 - val_tp: 22.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 3.0000 - val_accuracy: 0.4466 - val_precision: 0.2895 - val_recall: 0.8800 - val_auc: 0.6754\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8792 - tp: 91.0000 - fp: 129.0000 - tn: 234.0000 - fn: 29.0000 - accuracy: 0.6729 - precision: 0.4136 - recall: 0.7583 - auc: 0.7536 - val_loss: 0.7226 - val_tp: 23.0000 - val_fp: 59.0000 - val_tn: 19.0000 - val_fn: 2.0000 - val_accuracy: 0.4078 - val_precision: 0.2805 - val_recall: 0.9200 - val_auc: 0.6623\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 209ms/step - loss: 0.9959 - tp: 88.0000 - fp: 200.0000 - tn: 163.0000 - fn: 32.0000 - accuracy: 0.5197 - precision: 0.3056 - recall: 0.7333 - auc: 0.6460 - val_loss: 0.6746 - val_tp: 23.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.4175 - val_precision: 0.2840 - val_recall: 0.9200 - val_auc: 0.6944\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 0.9206 - tp: 100.0000 - fp: 162.0000 - tn: 201.0000 - fn: 20.0000 - accuracy: 0.6232 - precision: 0.3817 - recall: 0.8333 - auc: 0.7397 - val_loss: 0.7264 - val_tp: 23.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.3883 - val_precision: 0.2738 - val_recall: 0.9200 - val_auc: 0.6969\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 198ms/step - loss: 0.9351 - tp: 86.0000 - fp: 136.0000 - tn: 227.0000 - fn: 34.0000 - accuracy: 0.6480 - precision: 0.3874 - recall: 0.7167 - auc: 0.7252 - val_loss: 0.7320 - val_tp: 23.0000 - val_fp: 62.0000 - val_tn: 16.0000 - val_fn: 2.0000 - val_accuracy: 0.3786 - val_precision: 0.2706 - val_recall: 0.9200 - val_auc: 0.6964\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.9241 - tp: 89.0000 - fp: 132.0000 - tn: 231.0000 - fn: 31.0000 - accuracy: 0.6625 - precision: 0.4027 - recall: 0.7417 - auc: 0.7278 - val_loss: 0.6224 - val_tp: 22.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 3.0000 - val_accuracy: 0.5437 - val_precision: 0.3333 - val_recall: 0.8800 - val_auc: 0.7121\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 4s 223ms/step - loss: 0.8693 - tp: 92.0000 - fp: 118.0000 - tn: 245.0000 - fn: 28.0000 - accuracy: 0.6977 - precision: 0.4381 - recall: 0.7667 - auc: 0.7675 - val_loss: 0.7285 - val_tp: 22.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 3.0000 - val_accuracy: 0.4078 - val_precision: 0.2750 - val_recall: 0.8800 - val_auc: 0.6969\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8583 - tp: 97.0000 - fp: 148.0000 - tn: 215.0000 - fn: 23.0000 - accuracy: 0.6460 - precision: 0.3959 - recall: 0.8083 - auc: 0.7445 - val_loss: 0.6744 - val_tp: 22.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 3.0000 - val_accuracy: 0.4466 - val_precision: 0.2895 - val_recall: 0.8800 - val_auc: 0.7074\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.8388 - tp: 97.0000 - fp: 138.0000 - tn: 225.0000 - fn: 23.0000 - accuracy: 0.6667 - precision: 0.4128 - recall: 0.8083 - auc: 0.7563 - val_loss: 0.6763 - val_tp: 22.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 3.0000 - val_accuracy: 0.4466 - val_precision: 0.2895 - val_recall: 0.8800 - val_auc: 0.7062\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8629 - tp: 95.0000 - fp: 143.0000 - tn: 220.0000 - fn: 25.0000 - accuracy: 0.6522 - precision: 0.3992 - recall: 0.7917 - auc: 0.7579 - val_loss: 0.7017 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.7023\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.8475 - tp: 102.0000 - fp: 156.0000 - tn: 207.0000 - fn: 18.0000 - accuracy: 0.6398 - precision: 0.3953 - recall: 0.8500 - auc: 0.7574 - val_loss: 0.6787 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.7069\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8472 - tp: 95.0000 - fp: 141.0000 - tn: 222.0000 - fn: 25.0000 - accuracy: 0.6563 - precision: 0.4025 - recall: 0.7917 - auc: 0.7805 - val_loss: 0.6544 - val_tp: 21.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 4.0000 - val_accuracy: 0.5243 - val_precision: 0.3182 - val_recall: 0.8400 - val_auc: 0.7056\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.8382 - tp: 105.0000 - fp: 148.0000 - tn: 215.0000 - fn: 15.0000 - accuracy: 0.6625 - precision: 0.4150 - recall: 0.8750 - auc: 0.7762 - val_loss: 0.6350 - val_tp: 21.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 4.0000 - val_accuracy: 0.5825 - val_precision: 0.3500 - val_recall: 0.8400 - val_auc: 0.6836\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8257 - tp: 95.0000 - fp: 137.0000 - tn: 226.0000 - fn: 25.0000 - accuracy: 0.6646 - precision: 0.4095 - recall: 0.7917 - auc: 0.7793 - val_loss: 0.6491 - val_tp: 21.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 4.0000 - val_accuracy: 0.5340 - val_precision: 0.3231 - val_recall: 0.8400 - val_auc: 0.6918\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8160 - tp: 103.0000 - fp: 152.0000 - tn: 211.0000 - fn: 17.0000 - accuracy: 0.6501 - precision: 0.4039 - recall: 0.8583 - auc: 0.7822 - val_loss: 0.6451 - val_tp: 21.0000 - val_fp: 36.0000 - val_tn: 42.0000 - val_fn: 4.0000 - val_accuracy: 0.6117 - val_precision: 0.3684 - val_recall: 0.8400 - val_auc: 0.6882\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8784 - tp: 100.0000 - fp: 178.0000 - tn: 185.0000 - fn: 20.0000 - accuracy: 0.5901 - precision: 0.3597 - recall: 0.8333 - auc: 0.7299 - val_loss: 0.6512 - val_tp: 22.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 3.0000 - val_accuracy: 0.4466 - val_precision: 0.2895 - val_recall: 0.8800 - val_auc: 0.6987\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.8301 - tp: 90.0000 - fp: 99.0000 - tn: 264.0000 - fn: 30.0000 - accuracy: 0.7329 - precision: 0.4762 - recall: 0.7500 - auc: 0.8067 - val_loss: 0.6540 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.7079\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 219ms/step - loss: 0.7948 - tp: 104.0000 - fp: 146.0000 - tn: 217.0000 - fn: 16.0000 - accuracy: 0.6646 - precision: 0.4160 - recall: 0.8667 - auc: 0.7985 - val_loss: 0.6590 - val_tp: 21.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 4.0000 - val_accuracy: 0.5825 - val_precision: 0.3500 - val_recall: 0.8400 - val_auc: 0.6823\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 4s 229ms/step - loss: 0.8036 - tp: 99.0000 - fp: 119.0000 - tn: 244.0000 - fn: 21.0000 - accuracy: 0.7101 - precision: 0.4541 - recall: 0.8250 - auc: 0.8006 - val_loss: 0.6349 - val_tp: 18.0000 - val_fp: 31.0000 - val_tn: 47.0000 - val_fn: 7.0000 - val_accuracy: 0.6311 - val_precision: 0.3673 - val_recall: 0.7200 - val_auc: 0.6836\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.8308 - tp: 91.0000 - fp: 144.0000 - tn: 219.0000 - fn: 29.0000 - accuracy: 0.6418 - precision: 0.3872 - recall: 0.7583 - auc: 0.7715 - val_loss: 0.6547 - val_tp: 22.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 3.0000 - val_accuracy: 0.5437 - val_precision: 0.3333 - val_recall: 0.8800 - val_auc: 0.7049\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.7883 - tp: 91.0000 - fp: 107.0000 - tn: 256.0000 - fn: 29.0000 - accuracy: 0.7184 - precision: 0.4596 - recall: 0.7583 - auc: 0.8065 - val_loss: 0.6991 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.6992\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.7655 - tp: 107.0000 - fp: 149.0000 - tn: 214.0000 - fn: 13.0000 - accuracy: 0.6646 - precision: 0.4180 - recall: 0.8917 - auc: 0.8268 - val_loss: 0.6865 - val_tp: 24.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.4951 - val_precision: 0.3200 - val_recall: 0.9600 - val_auc: 0.7051\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 0.7578 - tp: 102.0000 - fp: 125.0000 - tn: 238.0000 - fn: 18.0000 - accuracy: 0.7039 - precision: 0.4493 - recall: 0.8500 - auc: 0.8216 - val_loss: 0.6954 - val_tp: 19.0000 - val_fp: 35.0000 - val_tn: 43.0000 - val_fn: 6.0000 - val_accuracy: 0.6019 - val_precision: 0.3519 - val_recall: 0.7600 - val_auc: 0.6833\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.8508 - tp: 95.0000 - fp: 144.0000 - tn: 219.0000 - fn: 25.0000 - accuracy: 0.6501 - precision: 0.3975 - recall: 0.7917 - auc: 0.7710 - val_loss: 0.7417 - val_tp: 24.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 1.0000 - val_accuracy: 0.3981 - val_precision: 0.2824 - val_recall: 0.9600 - val_auc: 0.6903\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.8766 - tp: 102.0000 - fp: 176.0000 - tn: 187.0000 - fn: 18.0000 - accuracy: 0.5983 - precision: 0.3669 - recall: 0.8500 - auc: 0.7596 - val_loss: 0.6505 - val_tp: 22.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 3.0000 - val_accuracy: 0.5243 - val_precision: 0.3235 - val_recall: 0.8800 - val_auc: 0.7100\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8231 - tp: 95.0000 - fp: 120.0000 - tn: 243.0000 - fn: 25.0000 - accuracy: 0.6998 - precision: 0.4419 - recall: 0.7917 - auc: 0.8015 - val_loss: 0.6823 - val_tp: 22.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 3.0000 - val_accuracy: 0.5340 - val_precision: 0.3284 - val_recall: 0.8800 - val_auc: 0.7033\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.7776 - tp: 98.0000 - fp: 126.0000 - tn: 237.0000 - fn: 22.0000 - accuracy: 0.6936 - precision: 0.4375 - recall: 0.8167 - auc: 0.8107 - val_loss: 0.6286 - val_tp: 18.0000 - val_fp: 35.0000 - val_tn: 43.0000 - val_fn: 7.0000 - val_accuracy: 0.5922 - val_precision: 0.3396 - val_recall: 0.7200 - val_auc: 0.7210\n",
      "Calculated mean IoU: 0.4752\n",
      "IoU from saved model: 0.585\n",
      "No Model update.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 4s 272ms/step - loss: 10.1423 - tp: 76.0000 - fp: 193.0000 - tn: 248.0000 - fn: 69.0000 - accuracy: 0.5529 - precision: 0.2825 - recall: 0.5241 - auc: 0.5347 - val_loss: 0.7102 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.5800\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 1.0454 - tp: 87.0000 - fp: 254.0000 - tn: 109.0000 - fn: 33.0000 - accuracy: 0.4058 - precision: 0.2551 - recall: 0.7250 - auc: 0.5498 - val_loss: 0.6435 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7010\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 210ms/step - loss: 1.0670 - tp: 75.0000 - fp: 167.0000 - tn: 196.0000 - fn: 45.0000 - accuracy: 0.5611 - precision: 0.3099 - recall: 0.6250 - auc: 0.5854 - val_loss: 0.7008 - val_tp: 25.0000 - val_fp: 68.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3398 - val_precision: 0.2688 - val_recall: 1.0000 - val_auc: 0.6462\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 1.0060 - tp: 71.0000 - fp: 135.0000 - tn: 228.0000 - fn: 49.0000 - accuracy: 0.6190 - precision: 0.3447 - recall: 0.5917 - auc: 0.6238 - val_loss: 0.7220 - val_tp: 23.0000 - val_fp: 63.0000 - val_tn: 15.0000 - val_fn: 2.0000 - val_accuracy: 0.3689 - val_precision: 0.2674 - val_recall: 0.9200 - val_auc: 0.6908\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.9465 - tp: 96.0000 - fp: 168.0000 - tn: 195.0000 - fn: 24.0000 - accuracy: 0.6025 - precision: 0.3636 - recall: 0.8000 - auc: 0.7198 - val_loss: 0.6784 - val_tp: 22.0000 - val_fp: 59.0000 - val_tn: 19.0000 - val_fn: 3.0000 - val_accuracy: 0.3981 - val_precision: 0.2716 - val_recall: 0.8800 - val_auc: 0.6985\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.9376 - tp: 98.0000 - fp: 171.0000 - tn: 192.0000 - fn: 22.0000 - accuracy: 0.6004 - precision: 0.3643 - recall: 0.8167 - auc: 0.7190 - val_loss: 0.6774 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.6769\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 4s 259ms/step - loss: 0.9399 - tp: 97.0000 - fp: 166.0000 - tn: 197.0000 - fn: 23.0000 - accuracy: 0.6087 - precision: 0.3688 - recall: 0.8083 - auc: 0.7073 - val_loss: 0.7208 - val_tp: 24.0000 - val_fp: 66.0000 - val_tn: 12.0000 - val_fn: 1.0000 - val_accuracy: 0.3495 - val_precision: 0.2667 - val_recall: 0.9600 - val_auc: 0.6454\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.9683 - tp: 82.0000 - fp: 124.0000 - tn: 239.0000 - fn: 38.0000 - accuracy: 0.6646 - precision: 0.3981 - recall: 0.6833 - auc: 0.7162 - val_loss: 0.6662 - val_tp: 22.0000 - val_fp: 57.0000 - val_tn: 21.0000 - val_fn: 3.0000 - val_accuracy: 0.4175 - val_precision: 0.2785 - val_recall: 0.8800 - val_auc: 0.6813\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.9136 - tp: 95.0000 - fp: 175.0000 - tn: 188.0000 - fn: 25.0000 - accuracy: 0.5859 - precision: 0.3519 - recall: 0.7917 - auc: 0.7101 - val_loss: 0.6558 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.6851\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.8691 - tp: 87.0000 - fp: 122.0000 - tn: 241.0000 - fn: 33.0000 - accuracy: 0.6791 - precision: 0.4163 - recall: 0.7250 - auc: 0.7464 - val_loss: 0.6949 - val_tp: 22.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 3.0000 - val_accuracy: 0.4078 - val_precision: 0.2750 - val_recall: 0.8800 - val_auc: 0.6808\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8674 - tp: 107.0000 - fp: 169.0000 - tn: 194.0000 - fn: 13.0000 - accuracy: 0.6232 - precision: 0.3877 - recall: 0.8917 - auc: 0.7448 - val_loss: 0.6224 - val_tp: 21.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 4.0000 - val_accuracy: 0.5340 - val_precision: 0.3231 - val_recall: 0.8400 - val_auc: 0.6674\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8993 - tp: 101.0000 - fp: 171.0000 - tn: 192.0000 - fn: 19.0000 - accuracy: 0.6066 - precision: 0.3713 - recall: 0.8417 - auc: 0.7243 - val_loss: 0.6571 - val_tp: 22.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.4369 - val_precision: 0.2857 - val_recall: 0.8800 - val_auc: 0.6746\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8719 - tp: 99.0000 - fp: 149.0000 - tn: 214.0000 - fn: 21.0000 - accuracy: 0.6480 - precision: 0.3992 - recall: 0.8250 - auc: 0.7516 - val_loss: 0.6448 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.6797\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.8520 - tp: 98.0000 - fp: 154.0000 - tn: 209.0000 - fn: 22.0000 - accuracy: 0.6356 - precision: 0.3889 - recall: 0.8167 - auc: 0.7641 - val_loss: 0.6654 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.6777\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.8534 - tp: 98.0000 - fp: 139.0000 - tn: 224.0000 - fn: 22.0000 - accuracy: 0.6667 - precision: 0.4135 - recall: 0.8167 - auc: 0.7647 - val_loss: 0.6706 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.6792\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8594 - tp: 103.0000 - fp: 161.0000 - tn: 202.0000 - fn: 17.0000 - accuracy: 0.6315 - precision: 0.3902 - recall: 0.8583 - auc: 0.7637 - val_loss: 0.6852 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.6710\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8986 - tp: 103.0000 - fp: 165.0000 - tn: 198.0000 - fn: 17.0000 - accuracy: 0.6232 - precision: 0.3843 - recall: 0.8583 - auc: 0.7523 - val_loss: 0.6794 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.6654\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8685 - tp: 84.0000 - fp: 118.0000 - tn: 245.0000 - fn: 36.0000 - accuracy: 0.6812 - precision: 0.4158 - recall: 0.7000 - auc: 0.7537 - val_loss: 0.6815 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.6746\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 193ms/step - loss: 0.8324 - tp: 98.0000 - fp: 144.0000 - tn: 219.0000 - fn: 22.0000 - accuracy: 0.6563 - precision: 0.4050 - recall: 0.8167 - auc: 0.7738 - val_loss: 0.6434 - val_tp: 22.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 3.0000 - val_accuracy: 0.5049 - val_precision: 0.3143 - val_recall: 0.8800 - val_auc: 0.6738\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8542 - tp: 104.0000 - fp: 158.0000 - tn: 205.0000 - fn: 16.0000 - accuracy: 0.6398 - precision: 0.3969 - recall: 0.8667 - auc: 0.7726 - val_loss: 0.6544 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.6890\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.8197 - tp: 98.0000 - fp: 132.0000 - tn: 231.0000 - fn: 22.0000 - accuracy: 0.6812 - precision: 0.4261 - recall: 0.8167 - auc: 0.7804 - val_loss: 0.6529 - val_tp: 22.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 3.0000 - val_accuracy: 0.5049 - val_precision: 0.3143 - val_recall: 0.8800 - val_auc: 0.7041\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.8231 - tp: 101.0000 - fp: 138.0000 - tn: 225.0000 - fn: 19.0000 - accuracy: 0.6749 - precision: 0.4226 - recall: 0.8417 - auc: 0.7947 - val_loss: 0.6270 - val_tp: 21.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 4.0000 - val_accuracy: 0.5631 - val_precision: 0.3387 - val_recall: 0.8400 - val_auc: 0.6874\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.8181 - tp: 93.0000 - fp: 129.0000 - tn: 234.0000 - fn: 27.0000 - accuracy: 0.6770 - precision: 0.4189 - recall: 0.7750 - auc: 0.7776 - val_loss: 0.6384 - val_tp: 21.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 4.0000 - val_accuracy: 0.5146 - val_precision: 0.3134 - val_recall: 0.8400 - val_auc: 0.6987\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8045 - tp: 106.0000 - fp: 129.0000 - tn: 234.0000 - fn: 14.0000 - accuracy: 0.7039 - precision: 0.4511 - recall: 0.8833 - auc: 0.7954 - val_loss: 0.6319 - val_tp: 21.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 4.0000 - val_accuracy: 0.5340 - val_precision: 0.3231 - val_recall: 0.8400 - val_auc: 0.7021\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8208 - tp: 94.0000 - fp: 112.0000 - tn: 251.0000 - fn: 26.0000 - accuracy: 0.7143 - precision: 0.4563 - recall: 0.7833 - auc: 0.7917 - val_loss: 0.6645 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.7108\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.8237 - tp: 104.0000 - fp: 154.0000 - tn: 209.0000 - fn: 16.0000 - accuracy: 0.6480 - precision: 0.4031 - recall: 0.8667 - auc: 0.7878 - val_loss: 0.6700 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.7059\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.8489 - tp: 96.0000 - fp: 124.0000 - tn: 239.0000 - fn: 24.0000 - accuracy: 0.6936 - precision: 0.4364 - recall: 0.8000 - auc: 0.7838 - val_loss: 0.7216 - val_tp: 23.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.3883 - val_precision: 0.2738 - val_recall: 0.9200 - val_auc: 0.6877\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 4s 219ms/step - loss: 0.8812 - tp: 83.0000 - fp: 102.0000 - tn: 261.0000 - fn: 37.0000 - accuracy: 0.7122 - precision: 0.4486 - recall: 0.6917 - auc: 0.7616 - val_loss: 0.6550 - val_tp: 22.0000 - val_fp: 54.0000 - val_tn: 24.0000 - val_fn: 3.0000 - val_accuracy: 0.4466 - val_precision: 0.2895 - val_recall: 0.8800 - val_auc: 0.6708\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.8229 - tp: 100.0000 - fp: 128.0000 - tn: 235.0000 - fn: 20.0000 - accuracy: 0.6936 - precision: 0.4386 - recall: 0.8333 - auc: 0.7780 - val_loss: 0.6789 - val_tp: 22.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 3.0000 - val_accuracy: 0.4078 - val_precision: 0.2750 - val_recall: 0.8800 - val_auc: 0.6838\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 4s 261ms/step - loss: 0.8078 - tp: 107.0000 - fp: 154.0000 - tn: 209.0000 - fn: 13.0000 - accuracy: 0.6542 - precision: 0.4100 - recall: 0.8917 - auc: 0.7980 - val_loss: 0.6676 - val_tp: 22.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 3.0000 - val_accuracy: 0.4951 - val_precision: 0.3099 - val_recall: 0.8800 - val_auc: 0.7156\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8087 - tp: 101.0000 - fp: 144.0000 - tn: 219.0000 - fn: 19.0000 - accuracy: 0.6625 - precision: 0.4122 - recall: 0.8417 - auc: 0.7777 - val_loss: 0.6080 - val_tp: 17.0000 - val_fp: 29.0000 - val_tn: 49.0000 - val_fn: 8.0000 - val_accuracy: 0.6408 - val_precision: 0.3696 - val_recall: 0.6800 - val_auc: 0.7205\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.7852 - tp: 107.0000 - fp: 143.0000 - tn: 220.0000 - fn: 13.0000 - accuracy: 0.6770 - precision: 0.4280 - recall: 0.8917 - auc: 0.7918 - val_loss: 0.6322 - val_tp: 22.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 3.0000 - val_accuracy: 0.5728 - val_precision: 0.3492 - val_recall: 0.8800 - val_auc: 0.7469\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.8697 - tp: 91.0000 - fp: 124.0000 - tn: 239.0000 - fn: 29.0000 - accuracy: 0.6832 - precision: 0.4233 - recall: 0.7583 - auc: 0.7619 - val_loss: 0.6566 - val_tp: 16.0000 - val_fp: 25.0000 - val_tn: 53.0000 - val_fn: 9.0000 - val_accuracy: 0.6699 - val_precision: 0.3902 - val_recall: 0.6400 - val_auc: 0.6892\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 4s 228ms/step - loss: 0.8951 - tp: 82.0000 - fp: 123.0000 - tn: 240.0000 - fn: 38.0000 - accuracy: 0.6667 - precision: 0.4000 - recall: 0.6833 - auc: 0.7363 - val_loss: 0.7118 - val_tp: 22.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 3.0000 - val_accuracy: 0.4272 - val_precision: 0.2821 - val_recall: 0.8800 - val_auc: 0.7169\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.9059 - tp: 89.0000 - fp: 149.0000 - tn: 214.0000 - fn: 31.0000 - accuracy: 0.6273 - precision: 0.3739 - recall: 0.7417 - auc: 0.7285 - val_loss: 0.7212 - val_tp: 23.0000 - val_fp: 57.0000 - val_tn: 21.0000 - val_fn: 2.0000 - val_accuracy: 0.4272 - val_precision: 0.2875 - val_recall: 0.9200 - val_auc: 0.7310\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.8809 - tp: 92.0000 - fp: 145.0000 - tn: 218.0000 - fn: 28.0000 - accuracy: 0.6418 - precision: 0.3882 - recall: 0.7667 - auc: 0.7490 - val_loss: 0.7013 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.7482\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.8329 - tp: 95.0000 - fp: 132.0000 - tn: 231.0000 - fn: 25.0000 - accuracy: 0.6749 - precision: 0.4185 - recall: 0.7917 - auc: 0.7936 - val_loss: 0.6246 - val_tp: 21.0000 - val_fp: 34.0000 - val_tn: 44.0000 - val_fn: 4.0000 - val_accuracy: 0.6311 - val_precision: 0.3818 - val_recall: 0.8400 - val_auc: 0.7841\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.8428 - tp: 95.0000 - fp: 121.0000 - tn: 242.0000 - fn: 25.0000 - accuracy: 0.6977 - precision: 0.4398 - recall: 0.7917 - auc: 0.7910 - val_loss: 0.6161 - val_tp: 21.0000 - val_fp: 36.0000 - val_tn: 42.0000 - val_fn: 4.0000 - val_accuracy: 0.6117 - val_precision: 0.3684 - val_recall: 0.8400 - val_auc: 0.7579\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.7968 - tp: 94.0000 - fp: 110.0000 - tn: 253.0000 - fn: 26.0000 - accuracy: 0.7184 - precision: 0.4608 - recall: 0.7833 - auc: 0.8047 - val_loss: 0.6707 - val_tp: 22.0000 - val_fp: 53.0000 - val_tn: 25.0000 - val_fn: 3.0000 - val_accuracy: 0.4563 - val_precision: 0.2933 - val_recall: 0.8800 - val_auc: 0.7813\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 211ms/step - loss: 0.8321 - tp: 84.0000 - fp: 105.0000 - tn: 258.0000 - fn: 36.0000 - accuracy: 0.7081 - precision: 0.4444 - recall: 0.7000 - auc: 0.7820 - val_loss: 0.6400 - val_tp: 22.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 3.0000 - val_accuracy: 0.5922 - val_precision: 0.3607 - val_recall: 0.8800 - val_auc: 0.7103\n",
      "Calculated mean IoU: 0.5461\n",
      "IoU from saved model: 0.585\n",
      "No Model update.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 5s 285ms/step - loss: 19.3467 - tp: 87.0000 - fp: 246.0000 - tn: 195.0000 - fn: 58.0000 - accuracy: 0.4812 - precision: 0.2613 - recall: 0.6000 - auc: 0.4920 - val_loss: 0.6924 - val_tp: 19.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 6.0000 - val_accuracy: 0.4563 - val_precision: 0.2754 - val_recall: 0.7600 - val_auc: 0.6467\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 1.0268 - tp: 49.0000 - fp: 113.0000 - tn: 250.0000 - fn: 71.0000 - accuracy: 0.6190 - precision: 0.3025 - recall: 0.4083 - auc: 0.5826 - val_loss: 0.7638 - val_tp: 25.0000 - val_fp: 77.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2524 - val_precision: 0.2451 - val_recall: 1.0000 - val_auc: 0.5300\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 1.0520 - tp: 77.0000 - fp: 196.0000 - tn: 167.0000 - fn: 43.0000 - accuracy: 0.5052 - precision: 0.2821 - recall: 0.6417 - auc: 0.5317 - val_loss: 0.7143 - val_tp: 25.0000 - val_fp: 72.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3010 - val_precision: 0.2577 - val_recall: 1.0000 - val_auc: 0.5405\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 0.9653 - tp: 94.0000 - fp: 192.0000 - tn: 171.0000 - fn: 26.0000 - accuracy: 0.5487 - precision: 0.3287 - recall: 0.7833 - auc: 0.6696 - val_loss: 0.7467 - val_tp: 25.0000 - val_fp: 71.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3107 - val_precision: 0.2604 - val_recall: 1.0000 - val_auc: 0.6133\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 205ms/step - loss: 0.9578 - tp: 99.0000 - fp: 198.0000 - tn: 165.0000 - fn: 21.0000 - accuracy: 0.5466 - precision: 0.3333 - recall: 0.8250 - auc: 0.6760 - val_loss: 0.6541 - val_tp: 22.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 3.0000 - val_accuracy: 0.4369 - val_precision: 0.2857 - val_recall: 0.8800 - val_auc: 0.6787\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 210ms/step - loss: 0.9205 - tp: 92.0000 - fp: 149.0000 - tn: 214.0000 - fn: 28.0000 - accuracy: 0.6335 - precision: 0.3817 - recall: 0.7667 - auc: 0.7290 - val_loss: 0.6518 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.6841\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.8787 - tp: 104.0000 - fp: 183.0000 - tn: 180.0000 - fn: 16.0000 - accuracy: 0.5880 - precision: 0.3624 - recall: 0.8667 - auc: 0.7504 - val_loss: 0.6520 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.6659\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 4s 231ms/step - loss: 0.9261 - tp: 96.0000 - fp: 172.0000 - tn: 191.0000 - fn: 24.0000 - accuracy: 0.5942 - precision: 0.3582 - recall: 0.8000 - auc: 0.6922 - val_loss: 0.6164 - val_tp: 20.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 5.0000 - val_accuracy: 0.5437 - val_precision: 0.3226 - val_recall: 0.8000 - val_auc: 0.6782\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 4s 222ms/step - loss: 0.8643 - tp: 103.0000 - fp: 171.0000 - tn: 192.0000 - fn: 17.0000 - accuracy: 0.6108 - precision: 0.3759 - recall: 0.8583 - auc: 0.7525 - val_loss: 0.6354 - val_tp: 20.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 5.0000 - val_accuracy: 0.5243 - val_precision: 0.3125 - val_recall: 0.8000 - val_auc: 0.6803\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 4s 226ms/step - loss: 0.8599 - tp: 105.0000 - fp: 154.0000 - tn: 209.0000 - fn: 15.0000 - accuracy: 0.6501 - precision: 0.4054 - recall: 0.8750 - auc: 0.7679 - val_loss: 0.6076 - val_tp: 15.0000 - val_fp: 29.0000 - val_tn: 49.0000 - val_fn: 10.0000 - val_accuracy: 0.6214 - val_precision: 0.3409 - val_recall: 0.6000 - val_auc: 0.6677\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.9097 - tp: 56.0000 - fp: 65.0000 - tn: 298.0000 - fn: 64.0000 - accuracy: 0.7329 - precision: 0.4628 - recall: 0.4667 - auc: 0.7658 - val_loss: 0.6338 - val_tp: 19.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 6.0000 - val_accuracy: 0.5146 - val_precision: 0.3016 - val_recall: 0.7600 - val_auc: 0.6503\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 4s 225ms/step - loss: 0.8754 - tp: 101.0000 - fp: 140.0000 - tn: 223.0000 - fn: 19.0000 - accuracy: 0.6708 - precision: 0.4191 - recall: 0.8417 - auc: 0.7591 - val_loss: 0.6522 - val_tp: 21.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 4.0000 - val_accuracy: 0.4757 - val_precision: 0.2958 - val_recall: 0.8400 - val_auc: 0.6621\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 216ms/step - loss: 0.8367 - tp: 108.0000 - fp: 158.0000 - tn: 205.0000 - fn: 12.0000 - accuracy: 0.6480 - precision: 0.4060 - recall: 0.9000 - auc: 0.7825 - val_loss: 0.6413 - val_tp: 21.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 4.0000 - val_accuracy: 0.5146 - val_precision: 0.3134 - val_recall: 0.8400 - val_auc: 0.6528\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 4s 229ms/step - loss: 0.8378 - tp: 97.0000 - fp: 143.0000 - tn: 220.0000 - fn: 23.0000 - accuracy: 0.6563 - precision: 0.4042 - recall: 0.8083 - auc: 0.7732 - val_loss: 0.6561 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.6351\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 4s 219ms/step - loss: 0.8468 - tp: 95.0000 - fp: 135.0000 - tn: 228.0000 - fn: 25.0000 - accuracy: 0.6687 - precision: 0.4130 - recall: 0.7917 - auc: 0.7715 - val_loss: 0.6806 - val_tp: 21.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 4.0000 - val_accuracy: 0.4563 - val_precision: 0.2877 - val_recall: 0.8400 - val_auc: 0.6633\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 4s 224ms/step - loss: 0.9037 - tp: 96.0000 - fp: 172.0000 - tn: 191.0000 - fn: 24.0000 - accuracy: 0.5942 - precision: 0.3582 - recall: 0.8000 - auc: 0.7142 - val_loss: 0.6563 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.6797p: 66.0000 - tn: 49.0000 - fn: 5.0000 - accuracy: 0.5562 - precision: 0.3774 - recall: 0.8889\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 4s 224ms/step - loss: 0.8302 - tp: 104.0000 - fp: 158.0000 - tn: 205.0000 - fn: 16.0000 - accuracy: 0.6398 - precision: 0.3969 - recall: 0.8667 - auc: 0.7690 - val_loss: 0.6877 - val_tp: 21.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 4.0000 - val_accuracy: 0.4563 - val_precision: 0.2877 - val_recall: 0.8400 - val_auc: 0.6882\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 4s 224ms/step - loss: 0.8072 - tp: 98.0000 - fp: 132.0000 - tn: 231.0000 - fn: 22.0000 - accuracy: 0.6812 - precision: 0.4261 - recall: 0.8167 - auc: 0.7851 - val_loss: 0.6548 - val_tp: 21.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 4.0000 - val_accuracy: 0.5049 - val_precision: 0.3088 - val_recall: 0.8400 - val_auc: 0.6697\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 4s 224ms/step - loss: 0.8222 - tp: 103.0000 - fp: 150.0000 - tn: 213.0000 - fn: 17.0000 - accuracy: 0.6542 - precision: 0.4071 - recall: 0.8583 - auc: 0.7767 - val_loss: 0.6523 - val_tp: 21.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 4.0000 - val_accuracy: 0.5243 - val_precision: 0.3182 - val_recall: 0.8400 - val_auc: 0.6641\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 4s 222ms/step - loss: 0.8680 - tp: 95.0000 - fp: 129.0000 - tn: 234.0000 - fn: 25.0000 - accuracy: 0.6812 - precision: 0.4241 - recall: 0.7917 - auc: 0.7533 - val_loss: 0.7065 - val_tp: 22.0000 - val_fp: 59.0000 - val_tn: 19.0000 - val_fn: 3.0000 - val_accuracy: 0.3981 - val_precision: 0.2716 - val_recall: 0.8800 - val_auc: 0.6605\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 4s 222ms/step - loss: 0.8457 - tp: 102.0000 - fp: 152.0000 - tn: 211.0000 - fn: 18.0000 - accuracy: 0.6480 - precision: 0.4016 - recall: 0.8500 - auc: 0.7711 - val_loss: 0.6531 - val_tp: 20.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 5.0000 - val_accuracy: 0.5340 - val_precision: 0.3175 - val_recall: 0.8000 - val_auc: 0.6515\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.8040 - tp: 96.0000 - fp: 124.0000 - tn: 239.0000 - fn: 24.0000 - accuracy: 0.6936 - precision: 0.4364 - recall: 0.8000 - auc: 0.7923 - val_loss: 0.6915 - val_tp: 21.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 4.0000 - val_accuracy: 0.4563 - val_precision: 0.2877 - val_recall: 0.8400 - val_auc: 0.6644\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 4s 227ms/step - loss: 0.8014 - tp: 103.0000 - fp: 129.0000 - tn: 234.0000 - fn: 17.0000 - accuracy: 0.6977 - precision: 0.4440 - recall: 0.8583 - auc: 0.7874 - val_loss: 0.6436 - val_tp: 19.0000 - val_fp: 40.0000 - val_tn: 38.0000 - val_fn: 6.0000 - val_accuracy: 0.5534 - val_precision: 0.3220 - val_recall: 0.7600 - val_auc: 0.6605\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.7845 - tp: 99.0000 - fp: 119.0000 - tn: 244.0000 - fn: 21.0000 - accuracy: 0.7101 - precision: 0.4541 - recall: 0.8250 - auc: 0.8012 - val_loss: 0.6523 - val_tp: 20.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 5.0000 - val_accuracy: 0.5534 - val_precision: 0.3279 - val_recall: 0.8000 - val_auc: 0.6431\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 4s 225ms/step - loss: 0.8344 - tp: 88.0000 - fp: 119.0000 - tn: 244.0000 - fn: 32.0000 - accuracy: 0.6874 - precision: 0.4251 - recall: 0.7333 - auc: 0.7694 - val_loss: 0.6777 - val_tp: 20.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 5.0000 - val_accuracy: 0.4854 - val_precision: 0.2941 - val_recall: 0.8000 - val_auc: 0.6392\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 4s 246ms/step - loss: 0.8272 - tp: 107.0000 - fp: 163.0000 - tn: 200.0000 - fn: 13.0000 - accuracy: 0.6356 - precision: 0.3963 - recall: 0.8917 - auc: 0.7746 - val_loss: 0.6438 - val_tp: 20.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 5.0000 - val_accuracy: 0.5437 - val_precision: 0.3226 - val_recall: 0.8000 - val_auc: 0.6454\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.7956 - tp: 99.0000 - fp: 134.0000 - tn: 229.0000 - fn: 21.0000 - accuracy: 0.6791 - precision: 0.4249 - recall: 0.8250 - auc: 0.7967 - val_loss: 0.6465 - val_tp: 20.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 5.0000 - val_accuracy: 0.5340 - val_precision: 0.3175 - val_recall: 0.8000 - val_auc: 0.6582\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 4s 220ms/step - loss: 0.8253 - tp: 102.0000 - fp: 141.0000 - tn: 222.0000 - fn: 18.0000 - accuracy: 0.6708 - precision: 0.4198 - recall: 0.8500 - auc: 0.7946 - val_loss: 0.6796 - val_tp: 20.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 5.0000 - val_accuracy: 0.4951 - val_precision: 0.2985 - val_recall: 0.8000 - val_auc: 0.6436\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 4s 221ms/step - loss: 0.7906 - tp: 101.0000 - fp: 125.0000 - tn: 238.0000 - fn: 19.0000 - accuracy: 0.7019 - precision: 0.4469 - recall: 0.8417 - auc: 0.7925 - val_loss: 0.6410 - val_tp: 17.0000 - val_fp: 36.0000 - val_tn: 42.0000 - val_fn: 8.0000 - val_accuracy: 0.5728 - val_precision: 0.3208 - val_recall: 0.6800 - val_auc: 0.6290\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 4s 219ms/step - loss: 0.7740 - tp: 104.0000 - fp: 148.0000 - tn: 215.0000 - fn: 16.0000 - accuracy: 0.6605 - precision: 0.4127 - recall: 0.8667 - auc: 0.8058 - val_loss: 0.6733 - val_tp: 20.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 5.0000 - val_accuracy: 0.5146 - val_precision: 0.3077 - val_recall: 0.8000 - val_auc: 0.6497\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 4s 221ms/step - loss: 0.8219 - tp: 94.0000 - fp: 123.0000 - tn: 240.0000 - fn: 26.0000 - accuracy: 0.6915 - precision: 0.4332 - recall: 0.7833 - auc: 0.7876 - val_loss: 0.6902 - val_tp: 21.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 4.0000 - val_accuracy: 0.4660 - val_precision: 0.2917 - val_recall: 0.8400 - val_auc: 0.6467\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.8051 - tp: 105.0000 - fp: 147.0000 - tn: 216.0000 - fn: 15.0000 - accuracy: 0.6646 - precision: 0.4167 - recall: 0.8750 - auc: 0.7852 - val_loss: 0.6542 - val_tp: 19.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 6.0000 - val_accuracy: 0.5340 - val_precision: 0.3115 - val_recall: 0.7600 - val_auc: 0.6377\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 4s 219ms/step - loss: 0.7571 - tp: 100.0000 - fp: 126.0000 - tn: 237.0000 - fn: 20.0000 - accuracy: 0.6977 - precision: 0.4425 - recall: 0.8333 - auc: 0.8059 - val_loss: 0.6531 - val_tp: 19.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 6.0000 - val_accuracy: 0.5437 - val_precision: 0.3167 - val_recall: 0.7600 - val_auc: 0.6421\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 4s 222ms/step - loss: 0.8018 - tp: 95.0000 - fp: 134.0000 - tn: 229.0000 - fn: 25.0000 - accuracy: 0.6708 - precision: 0.4148 - recall: 0.7917 - auc: 0.7854 - val_loss: 0.7177 - val_tp: 22.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 3.0000 - val_accuracy: 0.4078 - val_precision: 0.2750 - val_recall: 0.8800 - val_auc: 0.6641\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 4s 221ms/step - loss: 0.7830 - tp: 105.0000 - fp: 147.0000 - tn: 216.0000 - fn: 15.0000 - accuracy: 0.6646 - precision: 0.4167 - recall: 0.8750 - auc: 0.7931 - val_loss: 0.6487 - val_tp: 17.0000 - val_fp: 35.0000 - val_tn: 43.0000 - val_fn: 8.0000 - val_accuracy: 0.5825 - val_precision: 0.3269 - val_recall: 0.6800 - val_auc: 0.6431\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.7856 - tp: 102.0000 - fp: 125.0000 - tn: 238.0000 - fn: 18.0000 - accuracy: 0.7039 - precision: 0.4493 - recall: 0.8500 - auc: 0.7916 - val_loss: 0.6417 - val_tp: 18.0000 - val_fp: 36.0000 - val_tn: 42.0000 - val_fn: 7.0000 - val_accuracy: 0.5825 - val_precision: 0.3333 - val_recall: 0.7200 - val_auc: 0.6574\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 4s 220ms/step - loss: 0.7914 - tp: 86.0000 - fp: 101.0000 - tn: 262.0000 - fn: 34.0000 - accuracy: 0.7205 - precision: 0.4599 - recall: 0.7167 - auc: 0.7988 - val_loss: 0.6600 - val_tp: 20.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 5.0000 - val_accuracy: 0.5049 - val_precision: 0.3030 - val_recall: 0.8000 - val_auc: 0.6636\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 216ms/step - loss: 0.7820 - tp: 97.0000 - fp: 123.0000 - tn: 240.0000 - fn: 23.0000 - accuracy: 0.6977 - precision: 0.4409 - recall: 0.8083 - auc: 0.8109 - val_loss: 0.6441 - val_tp: 19.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 6.0000 - val_accuracy: 0.5728 - val_precision: 0.3333 - val_recall: 0.7600 - val_auc: 0.6518\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 4s 221ms/step - loss: 0.7359 - tp: 100.0000 - fp: 118.0000 - tn: 245.0000 - fn: 20.0000 - accuracy: 0.7143 - precision: 0.4587 - recall: 0.8333 - auc: 0.8162 - val_loss: 0.6630 - val_tp: 16.0000 - val_fp: 30.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.6214 - val_precision: 0.3478 - val_recall: 0.6400 - val_auc: 0.6585\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 4s 219ms/step - loss: 0.7139 - tp: 110.0000 - fp: 130.0000 - tn: 233.0000 - fn: 10.0000 - accuracy: 0.7101 - precision: 0.4583 - recall: 0.9167 - auc: 0.8315 - val_loss: 0.6686 - val_tp: 20.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.5728 - val_precision: 0.3390 - val_recall: 0.8000 - val_auc: 0.6336\n",
      "Calculated mean IoU: 0.5044\n",
      "IoU from saved model: 0.585\n",
      "No Model update.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "16/16 [==============================] - 5s 339ms/step - loss: 45.7916 - tp: 60.0000 - fp: 183.0000 - tn: 258.0000 - fn: 85.0000 - accuracy: 0.5427 - precision: 0.2469 - recall: 0.4138 - auc: 0.4729 - val_loss: 0.6866 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5187\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 4s 227ms/step - loss: 1.0477 - tp: 26.0000 - fp: 87.0000 - tn: 276.0000 - fn: 94.0000 - accuracy: 0.6253 - precision: 0.2301 - recall: 0.2167 - auc: 0.4751 - val_loss: 0.6933 - val_tp: 22.0000 - val_fp: 69.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.3010 - val_precision: 0.2418 - val_recall: 0.8800 - val_auc: 0.5000\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 4s 223ms/step - loss: 1.0465 - tp: 92.0000 - fp: 277.0000 - tn: 86.0000 - fn: 28.0000 - accuracy: 0.3685 - precision: 0.2493 - recall: 0.7667 - auc: 0.5244 - val_loss: 0.7247 - val_tp: 25.0000 - val_fp: 78.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.2427 - val_precision: 0.2427 - val_recall: 1.0000 - val_auc: 0.4392\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 208ms/step - loss: 1.0425 - tp: 76.0000 - fp: 230.0000 - tn: 133.0000 - fn: 44.0000 - accuracy: 0.4327 - precision: 0.2484 - recall: 0.6333 - auc: 0.5199 - val_loss: 0.6981 - val_tp: 25.0000 - val_fp: 71.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3107 - val_precision: 0.2604 - val_recall: 1.0000 - val_auc: 0.6723\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 1.0306 - tp: 69.0000 - fp: 147.0000 - tn: 216.0000 - fn: 51.0000 - accuracy: 0.5901 - precision: 0.3194 - recall: 0.5750 - auc: 0.5844 - val_loss: 0.7228 - val_tp: 25.0000 - val_fp: 75.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2718 - val_precision: 0.2500 - val_recall: 1.0000 - val_auc: 0.6187\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 210ms/step - loss: 1.0126 - tp: 66.0000 - fp: 112.0000 - tn: 251.0000 - fn: 54.0000 - accuracy: 0.6563 - precision: 0.3708 - recall: 0.5500 - auc: 0.6463 - val_loss: 0.7038 - val_tp: 19.0000 - val_fp: 60.0000 - val_tn: 18.0000 - val_fn: 6.0000 - val_accuracy: 0.3592 - val_precision: 0.2405 - val_recall: 0.7600 - val_auc: 0.6192\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.9552 - tp: 93.0000 - fp: 166.0000 - tn: 197.0000 - fn: 27.0000 - accuracy: 0.6004 - precision: 0.3591 - recall: 0.7750 - auc: 0.7035 - val_loss: 0.6994 - val_tp: 18.0000 - val_fp: 55.0000 - val_tn: 23.0000 - val_fn: 7.0000 - val_accuracy: 0.3981 - val_precision: 0.2466 - val_recall: 0.7200 - val_auc: 0.6418\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.9111 - tp: 77.0000 - fp: 116.0000 - tn: 247.0000 - fn: 43.0000 - accuracy: 0.6708 - precision: 0.3990 - recall: 0.6417 - auc: 0.7317 - val_loss: 0.7104 - val_tp: 23.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.4175 - val_precision: 0.2840 - val_recall: 0.9200 - val_auc: 0.6495\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.8986 - tp: 94.0000 - fp: 162.0000 - tn: 201.0000 - fn: 26.0000 - accuracy: 0.6108 - precision: 0.3672 - recall: 0.7833 - auc: 0.7268 - val_loss: 0.6518 - val_tp: 18.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 7.0000 - val_accuracy: 0.5146 - val_precision: 0.2951 - val_recall: 0.7200 - val_auc: 0.6728\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.9444 - tp: 74.0000 - fp: 121.0000 - tn: 242.0000 - fn: 46.0000 - accuracy: 0.6542 - precision: 0.3795 - recall: 0.6167 - auc: 0.6962 - val_loss: 0.6250 - val_tp: 18.0000 - val_fp: 40.0000 - val_tn: 38.0000 - val_fn: 7.0000 - val_accuracy: 0.5437 - val_precision: 0.3103 - val_recall: 0.7200 - val_auc: 0.6795\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.8944 - tp: 96.0000 - fp: 150.0000 - tn: 213.0000 - fn: 24.0000 - accuracy: 0.6398 - precision: 0.3902 - recall: 0.8000 - auc: 0.7431 - val_loss: 0.6311 - val_tp: 19.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 6.0000 - val_accuracy: 0.4951 - val_precision: 0.2923 - val_recall: 0.7600 - val_auc: 0.7013\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.8872 - tp: 91.0000 - fp: 126.0000 - tn: 237.0000 - fn: 29.0000 - accuracy: 0.6791 - precision: 0.4194 - recall: 0.7583 - auc: 0.7447 - val_loss: 0.6668 - val_tp: 20.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 5.0000 - val_accuracy: 0.4563 - val_precision: 0.2817 - val_recall: 0.8000 - val_auc: 0.7003\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 4s 268ms/step - loss: 0.8981 - tp: 101.0000 - fp: 163.0000 - tn: 200.0000 - fn: 19.0000 - accuracy: 0.6232 - precision: 0.3826 - recall: 0.8417 - auc: 0.7413 - val_loss: 0.6439 - val_tp: 20.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 5.0000 - val_accuracy: 0.4757 - val_precision: 0.2899 - val_recall: 0.8000 - val_auc: 0.6990\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 4s 258ms/step - loss: 0.8471 - tp: 96.0000 - fp: 142.0000 - tn: 221.0000 - fn: 24.0000 - accuracy: 0.6563 - precision: 0.4034 - recall: 0.8000 - auc: 0.7651 - val_loss: 0.6125 - val_tp: 18.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 7.0000 - val_accuracy: 0.5728 - val_precision: 0.3273 - val_recall: 0.7200 - val_auc: 0.7159\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 4s 220ms/step - loss: 0.8424 - tp: 94.0000 - fp: 132.0000 - tn: 231.0000 - fn: 26.0000 - accuracy: 0.6729 - precision: 0.4159 - recall: 0.7833 - auc: 0.7758 - val_loss: 0.6436 - val_tp: 19.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 6.0000 - val_accuracy: 0.4660 - val_precision: 0.2794 - val_recall: 0.7600 - val_auc: 0.6828\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.8468 - tp: 99.0000 - fp: 122.0000 - tn: 241.0000 - fn: 21.0000 - accuracy: 0.7039 - precision: 0.4480 - recall: 0.8250 - auc: 0.7751 - val_loss: 0.6641 - val_tp: 20.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 5.0000 - val_accuracy: 0.4660 - val_precision: 0.2857 - val_recall: 0.8000 - val_auc: 0.6882\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 4s 224ms/step - loss: 0.8488 - tp: 88.0000 - fp: 109.0000 - tn: 254.0000 - fn: 32.0000 - accuracy: 0.7081 - precision: 0.4467 - recall: 0.7333 - auc: 0.7693 - val_loss: 0.6520 - val_tp: 21.0000 - val_fp: 49.0000 - val_tn: 29.0000 - val_fn: 4.0000 - val_accuracy: 0.4854 - val_precision: 0.3000 - val_recall: 0.8400 - val_auc: 0.6867\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.8620 - tp: 105.0000 - fp: 173.0000 - tn: 190.0000 - fn: 15.0000 - accuracy: 0.6108 - precision: 0.3777 - recall: 0.8750 - auc: 0.7475 - val_loss: 0.6360 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.6779\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.8443 - tp: 109.0000 - fp: 185.0000 - tn: 178.0000 - fn: 11.0000 - accuracy: 0.5942 - precision: 0.3707 - recall: 0.9083 - auc: 0.7755 - val_loss: 0.6217 - val_tp: 20.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 5.0000 - val_accuracy: 0.5825 - val_precision: 0.3448 - val_recall: 0.8000 - val_auc: 0.6941\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 219ms/step - loss: 0.8093 - tp: 104.0000 - fp: 142.0000 - tn: 221.0000 - fn: 16.0000 - accuracy: 0.6729 - precision: 0.4228 - recall: 0.8667 - auc: 0.7924 - val_loss: 0.6292 - val_tp: 19.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 6.0000 - val_accuracy: 0.5340 - val_precision: 0.3115 - val_recall: 0.7600 - val_auc: 0.6479\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.8290 - tp: 100.0000 - fp: 145.0000 - tn: 218.0000 - fn: 20.0000 - accuracy: 0.6584 - precision: 0.4082 - recall: 0.8333 - auc: 0.7706 - val_loss: 0.6970 - val_tp: 20.0000 - val_fp: 41.0000 - val_tn: 37.0000 - val_fn: 5.0000 - val_accuracy: 0.5534 - val_precision: 0.3279 - val_recall: 0.8000 - val_auc: 0.6718\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 210ms/step - loss: 0.8004 - tp: 93.0000 - fp: 125.0000 - tn: 238.0000 - fn: 27.0000 - accuracy: 0.6853 - precision: 0.4266 - recall: 0.7750 - auc: 0.7937 - val_loss: 0.6420 - val_tp: 21.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 4.0000 - val_accuracy: 0.5922 - val_precision: 0.3559 - val_recall: 0.8400 - val_auc: 0.6767\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.7531 - tp: 97.0000 - fp: 119.0000 - tn: 244.0000 - fn: 23.0000 - accuracy: 0.7060 - precision: 0.4491 - recall: 0.8083 - auc: 0.8130 - val_loss: 0.6285 - val_tp: 21.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 4.0000 - val_accuracy: 0.6019 - val_precision: 0.3621 - val_recall: 0.8400 - val_auc: 0.6979\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 216ms/step - loss: 0.7547 - tp: 104.0000 - fp: 125.0000 - tn: 238.0000 - fn: 16.0000 - accuracy: 0.7081 - precision: 0.4541 - recall: 0.8667 - auc: 0.8331 - val_loss: 0.6491 - val_tp: 23.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 2.0000 - val_accuracy: 0.5728 - val_precision: 0.3538 - val_recall: 0.9200 - val_auc: 0.7974\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.7938 - tp: 95.0000 - fp: 124.0000 - tn: 239.0000 - fn: 25.0000 - accuracy: 0.6915 - precision: 0.4338 - recall: 0.7917 - auc: 0.7979 - val_loss: 0.6533 - val_tp: 21.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 4.0000 - val_accuracy: 0.5437 - val_precision: 0.3281 - val_recall: 0.8400 - val_auc: 0.7623\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 4s 229ms/step - loss: 0.7481 - tp: 89.0000 - fp: 99.0000 - tn: 264.0000 - fn: 31.0000 - accuracy: 0.7308 - precision: 0.4734 - recall: 0.7417 - auc: 0.8360 - val_loss: 0.6499 - val_tp: 21.0000 - val_fp: 44.0000 - val_tn: 34.0000 - val_fn: 4.0000 - val_accuracy: 0.5340 - val_precision: 0.3231 - val_recall: 0.8400 - val_auc: 0.7679\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.6704 - tp: 105.0000 - fp: 108.0000 - tn: 255.0000 - fn: 15.0000 - accuracy: 0.7453 - precision: 0.4930 - recall: 0.8750 - auc: 0.8740 - val_loss: 0.6249 - val_tp: 22.0000 - val_fp: 22.0000 - val_tn: 56.0000 - val_fn: 3.0000 - val_accuracy: 0.7573 - val_precision: 0.5000 - val_recall: 0.8800 - val_auc: 0.8028\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.7149 - tp: 98.0000 - fp: 82.0000 - tn: 281.0000 - fn: 22.0000 - accuracy: 0.7847 - precision: 0.5444 - recall: 0.8167 - auc: 0.8572 - val_loss: 0.6910 - val_tp: 21.0000 - val_fp: 40.0000 - val_tn: 38.0000 - val_fn: 4.0000 - val_accuracy: 0.5728 - val_precision: 0.3443 - val_recall: 0.8400 - val_auc: 0.7356\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.6753 - tp: 102.0000 - fp: 96.0000 - tn: 267.0000 - fn: 18.0000 - accuracy: 0.7640 - precision: 0.5152 - recall: 0.8500 - auc: 0.8720 - val_loss: 0.6172 - val_tp: 19.0000 - val_fp: 17.0000 - val_tn: 61.0000 - val_fn: 6.0000 - val_accuracy: 0.7767 - val_precision: 0.5278 - val_recall: 0.7600 - val_auc: 0.7562\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 4s 230ms/step - loss: 0.7096 - tp: 95.0000 - fp: 112.0000 - tn: 251.0000 - fn: 25.0000 - accuracy: 0.7164 - precision: 0.4589 - recall: 0.7917 - auc: 0.8449 - val_loss: 0.6568 - val_tp: 21.0000 - val_fp: 28.0000 - val_tn: 50.0000 - val_fn: 4.0000 - val_accuracy: 0.6893 - val_precision: 0.4286 - val_recall: 0.8400 - val_auc: 0.7749\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 4s 255ms/step - loss: 0.5939 - tp: 105.0000 - fp: 79.0000 - tn: 284.0000 - fn: 15.0000 - accuracy: 0.8054 - precision: 0.5707 - recall: 0.8750 - auc: 0.9019 - val_loss: 0.7219 - val_tp: 21.0000 - val_fp: 20.0000 - val_tn: 58.0000 - val_fn: 4.0000 - val_accuracy: 0.7670 - val_precision: 0.5122 - val_recall: 0.8400 - val_auc: 0.7828\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 4s 229ms/step - loss: 0.6633 - tp: 99.0000 - fp: 74.0000 - tn: 289.0000 - fn: 21.0000 - accuracy: 0.8033 - precision: 0.5723 - recall: 0.8250 - auc: 0.8773 - val_loss: 0.6272 - val_tp: 23.0000 - val_fp: 26.0000 - val_tn: 52.0000 - val_fn: 2.0000 - val_accuracy: 0.7282 - val_precision: 0.4694 - val_recall: 0.9200 - val_auc: 0.8236\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 4s 224ms/step - loss: 0.6439 - tp: 104.0000 - fp: 98.0000 - tn: 265.0000 - fn: 16.0000 - accuracy: 0.7640 - precision: 0.5149 - recall: 0.8667 - auc: 0.8903 - val_loss: 0.6526 - val_tp: 23.0000 - val_fp: 26.0000 - val_tn: 52.0000 - val_fn: 2.0000 - val_accuracy: 0.7282 - val_precision: 0.4694 - val_recall: 0.9200 - val_auc: 0.8144\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 4s 219ms/step - loss: 0.6282 - tp: 105.0000 - fp: 100.0000 - tn: 263.0000 - fn: 15.0000 - accuracy: 0.7619 - precision: 0.5122 - recall: 0.8750 - auc: 0.8931 - val_loss: 0.6188 - val_tp: 22.0000 - val_fp: 22.0000 - val_tn: 56.0000 - val_fn: 3.0000 - val_accuracy: 0.7573 - val_precision: 0.5000 - val_recall: 0.8800 - val_auc: 0.7964\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.5935 - tp: 102.0000 - fp: 83.0000 - tn: 280.0000 - fn: 18.0000 - accuracy: 0.7909 - precision: 0.5514 - recall: 0.8500 - auc: 0.8994 - val_loss: 0.6033 - val_tp: 18.0000 - val_fp: 21.0000 - val_tn: 57.0000 - val_fn: 7.0000 - val_accuracy: 0.7282 - val_precision: 0.4615 - val_recall: 0.7200 - val_auc: 0.7431\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 216ms/step - loss: 0.6146 - tp: 103.0000 - fp: 70.0000 - tn: 293.0000 - fn: 17.0000 - accuracy: 0.8199 - precision: 0.5954 - recall: 0.8583 - auc: 0.9041 - val_loss: 0.5965 - val_tp: 15.0000 - val_fp: 15.0000 - val_tn: 63.0000 - val_fn: 10.0000 - val_accuracy: 0.7573 - val_precision: 0.5000 - val_recall: 0.6000 - val_auc: 0.7490\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.6242 - tp: 104.0000 - fp: 82.0000 - tn: 281.0000 - fn: 16.0000 - accuracy: 0.7971 - precision: 0.5591 - recall: 0.8667 - auc: 0.8920 - val_loss: 0.7081 - val_tp: 22.0000 - val_fp: 35.0000 - val_tn: 43.0000 - val_fn: 3.0000 - val_accuracy: 0.6311 - val_precision: 0.3860 - val_recall: 0.8800 - val_auc: 0.7649\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.6276 - tp: 98.0000 - fp: 86.0000 - tn: 277.0000 - fn: 22.0000 - accuracy: 0.7764 - precision: 0.5326 - recall: 0.8167 - auc: 0.8855 - val_loss: 0.7017 - val_tp: 22.0000 - val_fp: 23.0000 - val_tn: 55.0000 - val_fn: 3.0000 - val_accuracy: 0.7476 - val_precision: 0.4889 - val_recall: 0.8800 - val_auc: 0.7608\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 205ms/step - loss: 0.6413 - tp: 101.0000 - fp: 75.0000 - tn: 288.0000 - fn: 19.0000 - accuracy: 0.8054 - precision: 0.5739 - recall: 0.8417 - auc: 0.8929 - val_loss: 0.6877 - val_tp: 18.0000 - val_fp: 22.0000 - val_tn: 56.0000 - val_fn: 7.0000 - val_accuracy: 0.7184 - val_precision: 0.4500 - val_recall: 0.7200 - val_auc: 0.7395\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 209ms/step - loss: 0.6828 - tp: 98.0000 - fp: 62.0000 - tn: 301.0000 - fn: 22.0000 - accuracy: 0.8261 - precision: 0.6125 - recall: 0.8167 - auc: 0.8808 - val_loss: 0.6475 - val_tp: 20.0000 - val_fp: 18.0000 - val_tn: 60.0000 - val_fn: 5.0000 - val_accuracy: 0.7767 - val_precision: 0.5263 - val_recall: 0.8000 - val_auc: 0.7767\n",
      "Calculated mean IoU: 0.3772\n",
      "IoU from saved model: 0.585\n",
      "No Model update.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 5s 303ms/step - loss: 40.5640 - tp: 58.0000 - fp: 152.0000 - tn: 289.0000 - fn: 87.0000 - accuracy: 0.5922 - precision: 0.2762 - recall: 0.4000 - auc: 0.5001 - val_loss: 0.6914 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5249\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 217ms/step - loss: 1.0381 - tp: 54.0000 - fp: 131.0000 - tn: 232.0000 - fn: 66.0000 - accuracy: 0.5921 - precision: 0.2919 - recall: 0.4500 - auc: 0.5589 - val_loss: 0.7067 - val_tp: 25.0000 - val_fp: 77.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2524 - val_precision: 0.2451 - val_recall: 1.0000 - val_auc: 0.5349\n",
      "Epoch 3/40\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 1.0152 - tp: 80.0000 - fp: 179.0000 - tn: 184.0000 - fn: 40.0000 - accuracy: 0.5466 - precision: 0.3089 - recall: 0.6667 - auc: 0.6042 - val_loss: 0.7138 - val_tp: 25.0000 - val_fp: 64.0000 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3786 - val_precision: 0.2809 - val_recall: 1.0000 - val_auc: 0.6764\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.9606 - tp: 76.0000 - fp: 133.0000 - tn: 230.0000 - fn: 44.0000 - accuracy: 0.6335 - precision: 0.3636 - recall: 0.6333 - auc: 0.6885 - val_loss: 0.7033 - val_tp: 23.0000 - val_fp: 61.0000 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.3883 - val_precision: 0.2738 - val_recall: 0.9200 - val_auc: 0.6754\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 1.0669 - tp: 59.0000 - fp: 160.0000 - tn: 203.0000 - fn: 61.0000 - accuracy: 0.5424 - precision: 0.2694 - recall: 0.4917 - auc: 0.5852 - val_loss: 0.6834 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6269\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 1.0461 - tp: 9.0000 - fp: 13.0000 - tn: 350.0000 - fn: 111.0000 - accuracy: 0.7433 - precision: 0.4091 - recall: 0.0750 - auc: 0.5811 - val_loss: 0.6935 - val_tp: 24.0000 - val_fp: 62.0000 - val_tn: 16.0000 - val_fn: 1.0000 - val_accuracy: 0.3883 - val_precision: 0.2791 - val_recall: 0.9600 - val_auc: 0.5631\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 4s 223ms/step - loss: 1.0198 - tp: 76.0000 - fp: 132.0000 - tn: 231.0000 - fn: 44.0000 - accuracy: 0.6356 - precision: 0.3654 - recall: 0.6333 - auc: 0.6760 - val_loss: 0.7135 - val_tp: 25.0000 - val_fp: 69.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3301 - val_precision: 0.2660 - val_recall: 1.0000 - val_auc: 0.6718\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 219ms/step - loss: 1.0192 - tp: 88.0000 - fp: 181.0000 - tn: 182.0000 - fn: 32.0000 - accuracy: 0.5590 - precision: 0.3271 - recall: 0.7333 - auc: 0.6300 - val_loss: 0.7069 - val_tp: 23.0000 - val_fp: 59.0000 - val_tn: 19.0000 - val_fn: 2.0000 - val_accuracy: 0.4078 - val_precision: 0.2805 - val_recall: 0.9200 - val_auc: 0.6667\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 4s 220ms/step - loss: 0.9528 - tp: 88.0000 - fp: 147.0000 - tn: 216.0000 - fn: 32.0000 - accuracy: 0.6294 - precision: 0.3745 - recall: 0.7333 - auc: 0.7108 - val_loss: 0.6780 - val_tp: 22.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 3.0000 - val_accuracy: 0.5146 - val_precision: 0.3188 - val_recall: 0.8800 - val_auc: 0.7069\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 4s 225ms/step - loss: 0.9174 - tp: 93.0000 - fp: 144.0000 - tn: 219.0000 - fn: 27.0000 - accuracy: 0.6460 - precision: 0.3924 - recall: 0.7750 - auc: 0.7355 - val_loss: 0.6995 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.7031\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.9079 - tp: 96.0000 - fp: 152.0000 - tn: 211.0000 - fn: 24.0000 - accuracy: 0.6356 - precision: 0.3871 - recall: 0.8000 - auc: 0.7401 - val_loss: 0.6659 - val_tp: 22.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 3.0000 - val_accuracy: 0.5049 - val_precision: 0.3143 - val_recall: 0.8800 - val_auc: 0.6887\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 0.8903 - tp: 93.0000 - fp: 139.0000 - tn: 224.0000 - fn: 27.0000 - accuracy: 0.6563 - precision: 0.4009 - recall: 0.7750 - auc: 0.7438 - val_loss: 0.6193 - val_tp: 21.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 4.0000 - val_accuracy: 0.6019 - val_precision: 0.3621 - val_recall: 0.8400 - val_auc: 0.6931\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 4s 221ms/step - loss: 0.8982 - tp: 93.0000 - fp: 132.0000 - tn: 231.0000 - fn: 27.0000 - accuracy: 0.6708 - precision: 0.4133 - recall: 0.7750 - auc: 0.7619 - val_loss: 0.7500 - val_tp: 23.0000 - val_fp: 65.0000 - val_tn: 13.0000 - val_fn: 2.0000 - val_accuracy: 0.3495 - val_precision: 0.2614 - val_recall: 0.9200 - val_auc: 0.6964\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.9424 - tp: 100.0000 - fp: 182.0000 - tn: 181.0000 - fn: 20.0000 - accuracy: 0.5818 - precision: 0.3546 - recall: 0.8333 - auc: 0.7064 - val_loss: 0.6450 - val_tp: 18.0000 - val_fp: 36.0000 - val_tn: 42.0000 - val_fn: 7.0000 - val_accuracy: 0.5825 - val_precision: 0.3333 - val_recall: 0.7200 - val_auc: 0.6985\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.9022 - tp: 64.0000 - fp: 79.0000 - tn: 284.0000 - fn: 56.0000 - accuracy: 0.7205 - precision: 0.4476 - recall: 0.5333 - auc: 0.7587 - val_loss: 0.6375 - val_tp: 21.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 4.0000 - val_accuracy: 0.5049 - val_precision: 0.3088 - val_recall: 0.8400 - val_auc: 0.6964\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.8675 - tp: 103.0000 - fp: 163.0000 - tn: 200.0000 - fn: 17.0000 - accuracy: 0.6273 - precision: 0.3872 - recall: 0.8583 - auc: 0.7566 - val_loss: 0.6930 - val_tp: 23.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 2.0000 - val_accuracy: 0.4369 - val_precision: 0.2911 - val_recall: 0.9200 - val_auc: 0.6931\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.8896 - tp: 107.0000 - fp: 172.0000 - tn: 191.0000 - fn: 13.0000 - accuracy: 0.6170 - precision: 0.3835 - recall: 0.8917 - auc: 0.7484 - val_loss: 0.6428 - val_tp: 21.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 4.0000 - val_accuracy: 0.4757 - val_precision: 0.2958 - val_recall: 0.8400 - val_auc: 0.6910\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.8635 - tp: 98.0000 - fp: 137.0000 - tn: 226.0000 - fn: 22.0000 - accuracy: 0.6708 - precision: 0.4170 - recall: 0.8167 - auc: 0.7587 - val_loss: 0.6299 - val_tp: 21.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 4.0000 - val_accuracy: 0.5922 - val_precision: 0.3559 - val_recall: 0.8400 - val_auc: 0.6695\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 4s 261ms/step - loss: 0.9565 - tp: 105.0000 - fp: 202.0000 - tn: 161.0000 - fn: 15.0000 - accuracy: 0.5507 - precision: 0.3420 - recall: 0.8750 - auc: 0.7139 - val_loss: 0.7378 - val_tp: 25.0000 - val_fp: 69.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3301 - val_precision: 0.2660 - val_recall: 1.0000 - val_auc: 0.6505\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 4s 267ms/step - loss: 0.9445 - tp: 95.0000 - fp: 182.0000 - tn: 181.0000 - fn: 25.0000 - accuracy: 0.5714 - precision: 0.3430 - recall: 0.7917 - auc: 0.7069 - val_loss: 0.6498 - val_tp: 19.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 6.0000 - val_accuracy: 0.5631 - val_precision: 0.3276 - val_recall: 0.7600 - val_auc: 0.6828\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 4s 256ms/step - loss: 0.8956 - tp: 90.0000 - fp: 144.0000 - tn: 219.0000 - fn: 30.0000 - accuracy: 0.6398 - precision: 0.3846 - recall: 0.7500 - auc: 0.7410 - val_loss: 0.6551 - val_tp: 19.0000 - val_fp: 42.0000 - val_tn: 36.0000 - val_fn: 6.0000 - val_accuracy: 0.5340 - val_precision: 0.3115 - val_recall: 0.7600 - val_auc: 0.7003\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 4s 231ms/step - loss: 0.9458 - tp: 71.0000 - fp: 103.0000 - tn: 260.0000 - fn: 49.0000 - accuracy: 0.6853 - precision: 0.4080 - recall: 0.5917 - auc: 0.7239 - val_loss: 0.6336 - val_tp: 17.0000 - val_fp: 25.0000 - val_tn: 53.0000 - val_fn: 8.0000 - val_accuracy: 0.6796 - val_precision: 0.4048 - val_recall: 0.6800 - val_auc: 0.7082\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.9310 - tp: 98.0000 - fp: 136.0000 - tn: 227.0000 - fn: 22.0000 - accuracy: 0.6729 - precision: 0.4188 - recall: 0.8167 - auc: 0.7598 - val_loss: 0.6543 - val_tp: 22.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 3.0000 - val_accuracy: 0.4757 - val_precision: 0.3014 - val_recall: 0.8800 - val_auc: 0.6913\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.9439 - tp: 109.0000 - fp: 222.0000 - tn: 141.0000 - fn: 11.0000 - accuracy: 0.5176 - precision: 0.3293 - recall: 0.9083 - auc: 0.7070 - val_loss: 0.6815 - val_tp: 23.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.4175 - val_precision: 0.2840 - val_recall: 0.9200 - val_auc: 0.7003\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 0.8916 - tp: 96.0000 - fp: 154.0000 - tn: 209.0000 - fn: 24.0000 - accuracy: 0.6315 - precision: 0.3840 - recall: 0.8000 - auc: 0.7513 - val_loss: 0.6399 - val_tp: 19.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 6.0000 - val_accuracy: 0.5243 - val_precision: 0.3065 - val_recall: 0.7600 - val_auc: 0.7095\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.8510 - tp: 91.0000 - fp: 138.0000 - tn: 225.0000 - fn: 29.0000 - accuracy: 0.6542 - precision: 0.3974 - recall: 0.7583 - auc: 0.7556 - val_loss: 0.6526 - val_tp: 21.0000 - val_fp: 51.0000 - val_tn: 27.0000 - val_fn: 4.0000 - val_accuracy: 0.4660 - val_precision: 0.2917 - val_recall: 0.8400 - val_auc: 0.7118\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.8302 - tp: 92.0000 - fp: 133.0000 - tn: 230.0000 - fn: 28.0000 - accuracy: 0.6667 - precision: 0.4089 - recall: 0.7667 - auc: 0.7788 - val_loss: 0.6432 - val_tp: 21.0000 - val_fp: 45.0000 - val_tn: 33.0000 - val_fn: 4.0000 - val_accuracy: 0.5243 - val_precision: 0.3182 - val_recall: 0.8400 - val_auc: 0.7156\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.8517 - tp: 93.0000 - fp: 136.0000 - tn: 227.0000 - fn: 27.0000 - accuracy: 0.6625 - precision: 0.4061 - recall: 0.7750 - auc: 0.7639 - val_loss: 0.6316 - val_tp: 19.0000 - val_fp: 34.0000 - val_tn: 44.0000 - val_fn: 6.0000 - val_accuracy: 0.6117 - val_precision: 0.3585 - val_recall: 0.7600 - val_auc: 0.7118\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 4s 223ms/step - loss: 0.8100 - tp: 97.0000 - fp: 133.0000 - tn: 230.0000 - fn: 23.0000 - accuracy: 0.6770 - precision: 0.4217 - recall: 0.8083 - auc: 0.7937 - val_loss: 0.6587 - val_tp: 21.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 4.0000 - val_accuracy: 0.5146 - val_precision: 0.3134 - val_recall: 0.8400 - val_auc: 0.7149\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 0.8224 - tp: 94.0000 - fp: 115.0000 - tn: 248.0000 - fn: 26.0000 - accuracy: 0.7081 - precision: 0.4498 - recall: 0.7833 - auc: 0.7787 - val_loss: 0.6616 - val_tp: 21.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 4.0000 - val_accuracy: 0.5437 - val_precision: 0.3281 - val_recall: 0.8400 - val_auc: 0.7067\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.8151 - tp: 96.0000 - fp: 137.0000 - tn: 226.0000 - fn: 24.0000 - accuracy: 0.6667 - precision: 0.4120 - recall: 0.8000 - auc: 0.7973 - val_loss: 0.6869 - val_tp: 21.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 4.0000 - val_accuracy: 0.4563 - val_precision: 0.2877 - val_recall: 0.8400 - val_auc: 0.7069\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.7847 - tp: 104.0000 - fp: 149.0000 - tn: 214.0000 - fn: 16.0000 - accuracy: 0.6584 - precision: 0.4111 - recall: 0.8667 - auc: 0.8047 - val_loss: 0.6733 - val_tp: 21.0000 - val_fp: 40.0000 - val_tn: 38.0000 - val_fn: 4.0000 - val_accuracy: 0.5728 - val_precision: 0.3443 - val_recall: 0.8400 - val_auc: 0.6838\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.7727 - tp: 96.0000 - fp: 122.0000 - tn: 241.0000 - fn: 24.0000 - accuracy: 0.6977 - precision: 0.4404 - recall: 0.8000 - auc: 0.7991 - val_loss: 0.6558 - val_tp: 20.0000 - val_fp: 34.0000 - val_tn: 44.0000 - val_fn: 5.0000 - val_accuracy: 0.6214 - val_precision: 0.3704 - val_recall: 0.8000 - val_auc: 0.6928\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.7755 - tp: 92.0000 - fp: 109.0000 - tn: 254.0000 - fn: 28.0000 - accuracy: 0.7164 - precision: 0.4577 - recall: 0.7667 - auc: 0.8159 - val_loss: 0.6872 - val_tp: 21.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 4.0000 - val_accuracy: 0.5146 - val_precision: 0.3134 - val_recall: 0.8400 - val_auc: 0.6933\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 211ms/step - loss: 0.7798 - tp: 108.0000 - fp: 158.0000 - tn: 205.0000 - fn: 12.0000 - accuracy: 0.6480 - precision: 0.4060 - recall: 0.9000 - auc: 0.7998 - val_loss: 0.7564 - val_tp: 22.0000 - val_fp: 52.0000 - val_tn: 26.0000 - val_fn: 3.0000 - val_accuracy: 0.4660 - val_precision: 0.2973 - val_recall: 0.8800 - val_auc: 0.6887\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.8205 - tp: 99.0000 - fp: 133.0000 - tn: 230.0000 - fn: 21.0000 - accuracy: 0.6812 - precision: 0.4267 - recall: 0.8250 - auc: 0.7878 - val_loss: 0.6713 - val_tp: 21.0000 - val_fp: 37.0000 - val_tn: 41.0000 - val_fn: 4.0000 - val_accuracy: 0.6019 - val_precision: 0.3621 - val_recall: 0.8400 - val_auc: 0.6679\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.7737 - tp: 97.0000 - fp: 128.0000 - tn: 235.0000 - fn: 23.0000 - accuracy: 0.6874 - precision: 0.4311 - recall: 0.8083 - auc: 0.8054 - val_loss: 0.6847 - val_tp: 21.0000 - val_fp: 47.0000 - val_tn: 31.0000 - val_fn: 4.0000 - val_accuracy: 0.5049 - val_precision: 0.3088 - val_recall: 0.8400 - val_auc: 0.6846\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.7755 - tp: 103.0000 - fp: 129.0000 - tn: 234.0000 - fn: 17.0000 - accuracy: 0.6977 - precision: 0.4440 - recall: 0.8583 - auc: 0.8007 - val_loss: 0.6876 - val_tp: 21.0000 - val_fp: 43.0000 - val_tn: 35.0000 - val_fn: 4.0000 - val_accuracy: 0.5437 - val_precision: 0.3281 - val_recall: 0.8400 - val_auc: 0.6895\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.7470 - tp: 105.0000 - fp: 129.0000 - tn: 234.0000 - fn: 15.0000 - accuracy: 0.7019 - precision: 0.4487 - recall: 0.8750 - auc: 0.8143 - val_loss: 0.6735 - val_tp: 19.0000 - val_fp: 36.0000 - val_tn: 42.0000 - val_fn: 6.0000 - val_accuracy: 0.5922 - val_precision: 0.3455 - val_recall: 0.7600 - val_auc: 0.6956\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.7674 - tp: 99.0000 - fp: 126.0000 - tn: 237.0000 - fn: 21.0000 - accuracy: 0.6957 - precision: 0.4400 - recall: 0.8250 - auc: 0.8139 - val_loss: 0.6681 - val_tp: 20.0000 - val_fp: 39.0000 - val_tn: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.5728 - val_precision: 0.3390 - val_recall: 0.8000 - val_auc: 0.6915\n",
      "Calculated mean IoU: 0.3214\n",
      "IoU from saved model: 0.585\n",
      "No Model update.\n",
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/40\n",
      "16/16 [==============================] - 5s 306ms/step - loss: 22.6594 - tp: 100.0000 - fp: 300.0000 - tn: 141.0000 - fn: 45.0000 - accuracy: 0.4113 - precision: 0.2500 - recall: 0.6897 - auc: 0.4910 - val_loss: 0.6900 - val_tp: 12.0000 - val_fp: 10.0000 - val_tn: 68.0000 - val_fn: 13.0000 - val_accuracy: 0.7767 - val_precision: 0.5455 - val_recall: 0.4800 - val_auc: 0.5413\n",
      "Epoch 2/40\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 1.0448 - tp: 58.0000 - fp: 152.0000 - tn: 211.0000 - fn: 62.0000 - accuracy: 0.5569 - precision: 0.2762 - recall: 0.4833 - auc: 0.5080 - val_loss: 0.6899 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5677\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 213ms/step - loss: 1.0431 - tp: 16.0000 - fp: 30.0000 - tn: 333.0000 - fn: 104.0000 - accuracy: 0.7226 - precision: 0.3478 - recall: 0.1333 - auc: 0.5727 - val_loss: 0.6880 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5128\n",
      "Epoch 4/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 1.0374 - tp: 80.0000 - fp: 227.0000 - tn: 136.0000 - fn: 40.0000 - accuracy: 0.4472 - precision: 0.2606 - recall: 0.6667 - auc: 0.5450 - val_loss: 0.7146 - val_tp: 25.0000 - val_fp: 77.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2524 - val_precision: 0.2451 - val_recall: 1.0000 - val_auc: 0.6074\n",
      "Epoch 5/40\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 1.0117 - tp: 78.0000 - fp: 171.0000 - tn: 192.0000 - fn: 42.0000 - accuracy: 0.5590 - precision: 0.3133 - recall: 0.6500 - auc: 0.6193 - val_loss: 0.7782 - val_tp: 25.0000 - val_fp: 71.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3107 - val_precision: 0.2604 - val_recall: 1.0000 - val_auc: 0.6726\n",
      "Epoch 6/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.9680 - tp: 95.0000 - fp: 183.0000 - tn: 180.0000 - fn: 25.0000 - accuracy: 0.5694 - precision: 0.3417 - recall: 0.7917 - auc: 0.6657 - val_loss: 0.6591 - val_tp: 23.0000 - val_fp: 57.0000 - val_tn: 21.0000 - val_fn: 2.0000 - val_accuracy: 0.4272 - val_precision: 0.2875 - val_recall: 0.9200 - val_auc: 0.7062\n",
      "Epoch 7/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 1.0253 - tp: 75.0000 - fp: 185.0000 - tn: 178.0000 - fn: 45.0000 - accuracy: 0.5238 - precision: 0.2885 - recall: 0.6250 - auc: 0.5861 - val_loss: 0.7625 - val_tp: 25.0000 - val_fp: 76.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2621 - val_precision: 0.2475 - val_recall: 1.0000 - val_auc: 0.6485\n",
      "Epoch 8/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 1.0373 - tp: 93.0000 - fp: 241.0000 - tn: 122.0000 - fn: 27.0000 - accuracy: 0.4451 - precision: 0.2784 - recall: 0.7750 - auc: 0.6077 - val_loss: 0.6295 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 78.0000 - val_fn: 25.0000 - val_accuracy: 0.7573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6708\n",
      "Epoch 9/40\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.9767 - tp: 86.0000 - fp: 148.0000 - tn: 215.0000 - fn: 34.0000 - accuracy: 0.6232 - precision: 0.3675 - recall: 0.7167 - auc: 0.6729 - val_loss: 0.7193 - val_tp: 23.0000 - val_fp: 58.0000 - val_tn: 20.0000 - val_fn: 2.0000 - val_accuracy: 0.4175 - val_precision: 0.2840 - val_recall: 0.9200 - val_auc: 0.6972\n",
      "Epoch 10/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.9266 - tp: 77.0000 - fp: 108.0000 - tn: 255.0000 - fn: 43.0000 - accuracy: 0.6874 - precision: 0.4162 - recall: 0.6417 - auc: 0.7298 - val_loss: 0.6969 - val_tp: 22.0000 - val_fp: 48.0000 - val_tn: 30.0000 - val_fn: 3.0000 - val_accuracy: 0.5049 - val_precision: 0.3143 - val_recall: 0.8800 - val_auc: 0.7244\n",
      "Epoch 11/40\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.9263 - tp: 92.0000 - fp: 140.0000 - tn: 223.0000 - fn: 28.0000 - accuracy: 0.6522 - precision: 0.3966 - recall: 0.7667 - auc: 0.7247 - val_loss: 0.7010 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.7336\n",
      "Epoch 12/40\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 0.8794 - tp: 90.0000 - fp: 123.0000 - tn: 240.0000 - fn: 30.0000 - accuracy: 0.6832 - precision: 0.4225 - recall: 0.7500 - auc: 0.7596 - val_loss: 0.7089 - val_tp: 22.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 3.0000 - val_accuracy: 0.4854 - val_precision: 0.3056 - val_recall: 0.8800 - val_auc: 0.7421\n",
      "Epoch 13/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.8909 - tp: 83.0000 - fp: 111.0000 - tn: 252.0000 - fn: 37.0000 - accuracy: 0.6936 - precision: 0.4278 - recall: 0.6917 - auc: 0.7504 - val_loss: 0.7080 - val_tp: 23.0000 - val_fp: 56.0000 - val_tn: 22.0000 - val_fn: 2.0000 - val_accuracy: 0.4369 - val_precision: 0.2911 - val_recall: 0.9200 - val_auc: 0.7536\n",
      "Epoch 14/40\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.8396 - tp: 95.0000 - fp: 147.0000 - tn: 216.0000 - fn: 25.0000 - accuracy: 0.6439 - precision: 0.3926 - recall: 0.7917 - auc: 0.7788 - val_loss: 0.6810 - val_tp: 23.0000 - val_fp: 50.0000 - val_tn: 28.0000 - val_fn: 2.0000 - val_accuracy: 0.4951 - val_precision: 0.3151 - val_recall: 0.9200 - val_auc: 0.7767\n",
      "Epoch 15/40\n",
      "16/16 [==============================] - 3s 216ms/step - loss: 0.8195 - tp: 100.0000 - fp: 135.0000 - tn: 228.0000 - fn: 20.0000 - accuracy: 0.6791 - precision: 0.4255 - recall: 0.8333 - auc: 0.8008 - val_loss: 0.6046 - val_tp: 23.0000 - val_fp: 34.0000 - val_tn: 44.0000 - val_fn: 2.0000 - val_accuracy: 0.6505 - val_precision: 0.4035 - val_recall: 0.9200 - val_auc: 0.8203\n",
      "Epoch 16/40\n",
      "16/16 [==============================] - 3s 208ms/step - loss: 0.7931 - tp: 88.0000 - fp: 108.0000 - tn: 255.0000 - fn: 32.0000 - accuracy: 0.7101 - precision: 0.4490 - recall: 0.7333 - auc: 0.8091 - val_loss: 0.5752 - val_tp: 18.0000 - val_fp: 19.0000 - val_tn: 59.0000 - val_fn: 7.0000 - val_accuracy: 0.7476 - val_precision: 0.4865 - val_recall: 0.7200 - val_auc: 0.7938\n",
      "Epoch 17/40\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 0.8224 - tp: 86.0000 - fp: 100.0000 - tn: 263.0000 - fn: 34.0000 - accuracy: 0.7226 - precision: 0.4624 - recall: 0.7167 - auc: 0.7987 - val_loss: 0.6824 - val_tp: 22.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 3.0000 - val_accuracy: 0.6019 - val_precision: 0.3667 - val_recall: 0.8800 - val_auc: 0.8187\n",
      "Epoch 18/40\n",
      "16/16 [==============================] - 3s 216ms/step - loss: 0.8156 - tp: 101.0000 - fp: 94.0000 - tn: 269.0000 - fn: 19.0000 - accuracy: 0.7660 - precision: 0.5179 - recall: 0.8417 - auc: 0.8238 - val_loss: 0.6057 - val_tp: 23.0000 - val_fp: 26.0000 - val_tn: 52.0000 - val_fn: 2.0000 - val_accuracy: 0.7282 - val_precision: 0.4694 - val_recall: 0.9200 - val_auc: 0.8456\n",
      "Epoch 19/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.7674 - tp: 87.0000 - fp: 86.0000 - tn: 277.0000 - fn: 33.0000 - accuracy: 0.7536 - precision: 0.5029 - recall: 0.7250 - auc: 0.8343 - val_loss: 0.6203 - val_tp: 22.0000 - val_fp: 24.0000 - val_tn: 54.0000 - val_fn: 3.0000 - val_accuracy: 0.7379 - val_precision: 0.4783 - val_recall: 0.8800 - val_auc: 0.8405\n",
      "Epoch 20/40\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.7163 - tp: 105.0000 - fp: 110.0000 - tn: 253.0000 - fn: 15.0000 - accuracy: 0.7412 - precision: 0.4884 - recall: 0.8750 - auc: 0.8514 - val_loss: 0.6021 - val_tp: 21.0000 - val_fp: 23.0000 - val_tn: 55.0000 - val_fn: 4.0000 - val_accuracy: 0.7379 - val_precision: 0.4773 - val_recall: 0.8400 - val_auc: 0.8290\n",
      "Epoch 21/40\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.7007 - tp: 106.0000 - fp: 88.0000 - tn: 275.0000 - fn: 14.0000 - accuracy: 0.7888 - precision: 0.5464 - recall: 0.8833 - auc: 0.8673 - val_loss: 0.6066 - val_tp: 21.0000 - val_fp: 22.0000 - val_tn: 56.0000 - val_fn: 4.0000 - val_accuracy: 0.7476 - val_precision: 0.4884 - val_recall: 0.8400 - val_auc: 0.8138\n",
      "Epoch 22/40\n",
      "16/16 [==============================] - 3s 216ms/step - loss: 0.6175 - tp: 103.0000 - fp: 61.0000 - tn: 302.0000 - fn: 17.0000 - accuracy: 0.8385 - precision: 0.6280 - recall: 0.8583 - auc: 0.8944 - val_loss: 0.5765 - val_tp: 21.0000 - val_fp: 21.0000 - val_tn: 57.0000 - val_fn: 4.0000 - val_accuracy: 0.7573 - val_precision: 0.5000 - val_recall: 0.8400 - val_auc: 0.8023\n",
      "Epoch 23/40\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.6956 - tp: 102.0000 - fp: 79.0000 - tn: 284.0000 - fn: 18.0000 - accuracy: 0.7992 - precision: 0.5635 - recall: 0.8500 - auc: 0.8649 - val_loss: 0.5980 - val_tp: 21.0000 - val_fp: 21.0000 - val_tn: 57.0000 - val_fn: 4.0000 - val_accuracy: 0.7573 - val_precision: 0.5000 - val_recall: 0.8400 - val_auc: 0.8195\n",
      "Epoch 24/40\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.6600 - tp: 103.0000 - fp: 78.0000 - tn: 285.0000 - fn: 17.0000 - accuracy: 0.8033 - precision: 0.5691 - recall: 0.8583 - auc: 0.8746 - val_loss: 0.5630 - val_tp: 17.0000 - val_fp: 16.0000 - val_tn: 62.0000 - val_fn: 8.0000 - val_accuracy: 0.7670 - val_precision: 0.5152 - val_recall: 0.6800 - val_auc: 0.8108\n",
      "Epoch 25/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.6357 - tp: 104.0000 - fp: 62.0000 - tn: 301.0000 - fn: 16.0000 - accuracy: 0.8385 - precision: 0.6265 - recall: 0.8667 - auc: 0.8915 - val_loss: 0.6172 - val_tp: 22.0000 - val_fp: 27.0000 - val_tn: 51.0000 - val_fn: 3.0000 - val_accuracy: 0.7087 - val_precision: 0.4490 - val_recall: 0.8800 - val_auc: 0.8062\n",
      "Epoch 26/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.5612 - tp: 106.0000 - fp: 75.0000 - tn: 288.0000 - fn: 14.0000 - accuracy: 0.8157 - precision: 0.5856 - recall: 0.8833 - auc: 0.9105 - val_loss: 0.6764 - val_tp: 22.0000 - val_fp: 32.0000 - val_tn: 46.0000 - val_fn: 3.0000 - val_accuracy: 0.6602 - val_precision: 0.4074 - val_recall: 0.8800 - val_auc: 0.7579\n",
      "Epoch 27/40\n",
      "16/16 [==============================] - 4s 222ms/step - loss: 0.5755 - tp: 104.0000 - fp: 62.0000 - tn: 301.0000 - fn: 16.0000 - accuracy: 0.8385 - precision: 0.6265 - recall: 0.8667 - auc: 0.9056 - val_loss: 0.5567 - val_tp: 21.0000 - val_fp: 22.0000 - val_tn: 56.0000 - val_fn: 4.0000 - val_accuracy: 0.7476 - val_precision: 0.4884 - val_recall: 0.8400 - val_auc: 0.8241\n",
      "Epoch 28/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.5619 - tp: 102.0000 - fp: 57.0000 - tn: 306.0000 - fn: 18.0000 - accuracy: 0.8447 - precision: 0.6415 - recall: 0.8500 - auc: 0.9198 - val_loss: 0.5927 - val_tp: 21.0000 - val_fp: 22.0000 - val_tn: 56.0000 - val_fn: 4.0000 - val_accuracy: 0.7476 - val_precision: 0.4884 - val_recall: 0.8400 - val_auc: 0.8200\n",
      "Epoch 29/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.5495 - tp: 110.0000 - fp: 79.0000 - tn: 284.0000 - fn: 10.0000 - accuracy: 0.8157 - precision: 0.5820 - recall: 0.9167 - auc: 0.9228 - val_loss: 0.6179 - val_tp: 20.0000 - val_fp: 28.0000 - val_tn: 50.0000 - val_fn: 5.0000 - val_accuracy: 0.6796 - val_precision: 0.4167 - val_recall: 0.8000 - val_auc: 0.7749\n",
      "Epoch 30/40\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.5292 - tp: 109.0000 - fp: 68.0000 - tn: 295.0000 - fn: 11.0000 - accuracy: 0.8364 - precision: 0.6158 - recall: 0.9083 - auc: 0.9221 - val_loss: 0.6624 - val_tp: 18.0000 - val_fp: 20.0000 - val_tn: 58.0000 - val_fn: 7.0000 - val_accuracy: 0.7379 - val_precision: 0.4737 - val_recall: 0.7200 - val_auc: 0.7805\n",
      "Epoch 31/40\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 0.5841 - tp: 99.0000 - fp: 73.0000 - tn: 290.0000 - fn: 21.0000 - accuracy: 0.8054 - precision: 0.5756 - recall: 0.8250 - auc: 0.9092 - val_loss: 0.8517 - val_tp: 20.0000 - val_fp: 46.0000 - val_tn: 32.0000 - val_fn: 5.0000 - val_accuracy: 0.5049 - val_precision: 0.3030 - val_recall: 0.8000 - val_auc: 0.7177\n",
      "Epoch 32/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.6148 - tp: 97.0000 - fp: 54.0000 - tn: 309.0000 - fn: 23.0000 - accuracy: 0.8406 - precision: 0.6424 - recall: 0.8083 - auc: 0.8980 - val_loss: 0.8128 - val_tp: 21.0000 - val_fp: 38.0000 - val_tn: 40.0000 - val_fn: 4.0000 - val_accuracy: 0.5922 - val_precision: 0.3559 - val_recall: 0.8400 - val_auc: 0.7362\n",
      "Epoch 33/40\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.5192 - tp: 106.0000 - fp: 56.0000 - tn: 307.0000 - fn: 14.0000 - accuracy: 0.8551 - precision: 0.6543 - recall: 0.8833 - auc: 0.9293 - val_loss: 0.6588 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 65.0000 - val_fn: 11.0000 - val_accuracy: 0.7670 - val_precision: 0.5185 - val_recall: 0.5600 - val_auc: 0.7621\n",
      "Epoch 34/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.5830 - tp: 100.0000 - fp: 56.0000 - tn: 307.0000 - fn: 20.0000 - accuracy: 0.8427 - precision: 0.6410 - recall: 0.8333 - auc: 0.9122 - val_loss: 0.6688 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 62.0000 - val_fn: 9.0000 - val_accuracy: 0.7573 - val_precision: 0.5000 - val_recall: 0.6400 - val_auc: 0.7331\n",
      "Epoch 35/40\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.5226 - tp: 108.0000 - fp: 65.0000 - tn: 298.0000 - fn: 12.0000 - accuracy: 0.8406 - precision: 0.6243 - recall: 0.9000 - auc: 0.9312 - val_loss: 0.8266 - val_tp: 21.0000 - val_fp: 28.0000 - val_tn: 50.0000 - val_fn: 4.0000 - val_accuracy: 0.6893 - val_precision: 0.4286 - val_recall: 0.8400 - val_auc: 0.7328\n",
      "Epoch 36/40\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.4729 - tp: 109.0000 - fp: 64.0000 - tn: 299.0000 - fn: 11.0000 - accuracy: 0.8447 - precision: 0.6301 - recall: 0.9083 - auc: 0.9413 - val_loss: 0.7946 - val_tp: 16.0000 - val_fp: 21.0000 - val_tn: 57.0000 - val_fn: 9.0000 - val_accuracy: 0.7087 - val_precision: 0.4324 - val_recall: 0.6400 - val_auc: 0.7115\n",
      "Epoch 37/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.4559 - tp: 103.0000 - fp: 45.0000 - tn: 318.0000 - fn: 17.0000 - accuracy: 0.8716 - precision: 0.6959 - recall: 0.8583 - auc: 0.9445 - val_loss: 0.7302 - val_tp: 18.0000 - val_fp: 20.0000 - val_tn: 58.0000 - val_fn: 7.0000 - val_accuracy: 0.7379 - val_precision: 0.4737 - val_recall: 0.7200 - val_auc: 0.7236\n",
      "Epoch 38/40\n",
      "16/16 [==============================] - 4s 223ms/step - loss: 0.4175 - tp: 104.0000 - fp: 38.0000 - tn: 325.0000 - fn: 16.0000 - accuracy: 0.8882 - precision: 0.7324 - recall: 0.8667 - auc: 0.9534 - val_loss: 0.7794 - val_tp: 18.0000 - val_fp: 21.0000 - val_tn: 57.0000 - val_fn: 7.0000 - val_accuracy: 0.7282 - val_precision: 0.4615 - val_recall: 0.7200 - val_auc: 0.7082\n",
      "Epoch 39/40\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 0.3655 - tp: 112.0000 - fp: 45.0000 - tn: 318.0000 - fn: 8.0000 - accuracy: 0.8903 - precision: 0.7134 - recall: 0.9333 - auc: 0.9647 - val_loss: 1.0289 - val_tp: 13.0000 - val_fp: 21.0000 - val_tn: 57.0000 - val_fn: 12.0000 - val_accuracy: 0.6796 - val_precision: 0.3824 - val_recall: 0.5200 - val_auc: 0.6138\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.3837 - tp: 105.0000 - fp: 33.0000 - tn: 330.0000 - fn: 15.0000 - accuracy: 0.9006 - precision: 0.7609 - recall: 0.8750 - auc: 0.9595 - val_loss: 0.9496 - val_tp: 19.0000 - val_fp: 24.0000 - val_tn: 54.0000 - val_fn: 6.0000 - val_accuracy: 0.7087 - val_precision: 0.4419 - val_recall: 0.7600 - val_auc: 0.7367\n",
      "Calculated mean IoU: 0.4695\n",
      "IoU from saved model: 0.585\n",
      "No Model update.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'base'\n",
    "last_conv_layer_name = \"last_conv_layer\"\n",
    "\n",
    "# model_name = 'vgg'\n",
    "# last_conv_layer_name = 'block5_conv3'\n",
    "\n",
    "heatmap_size = (14,14) # for base model\n",
    "# heatmap_size = (56,56) # for VGG model\n",
    "\n",
    "iou_model_path = os.path.join(saved_model_path, model_name)\n",
    "for i in range(20):\n",
    "    model, history = run_test_harness(model_name=model_name, batch_size=32, epochs=40, verbose=1)\n",
    "    iou_scores = []\n",
    "    for json_file_name in json_files:\n",
    "        img_name = get_json_img_name(json_file_name)\n",
    "        image_id = \"_\".join(img_name.split('_')[:3])\n",
    "        json_img = draw_json_polygons(img_name, json_file_name, ROOT_DIR, IMAGE_SIZE)\n",
    "        pred_heatmap = cam_pipeline(ROOT_DIR, img_name, json_img, IMAGE_SIZE, model, last_conv_layer_name, display=False, text=False)\n",
    "        predicted_binary_heatmap = np.where(pred_heatmap > 0.01, 1, 0)\n",
    "        heatmap_size = predicted_binary_heatmap.shape\n",
    "        \n",
    "        # search for corresponding labeled .npy file:\n",
    "        for file in os.listdir(true_label_folder):\n",
    "            if image_id in file:\n",
    "                ground_truth_heatmap = np.load(os.path.join(true_label_folder, file))\n",
    "                ground_truth_heatmap = resize(ground_truth_heatmap, heatmap_size)\n",
    "                iou_score = calc_iou_score(ground_truth_heatmap, predicted_binary_heatmap)\n",
    "                iou_scores.append(iou_score)\n",
    "    \n",
    "    mean_iou = np.mean(iou_scores)\n",
    "    current_best_iou = 0\n",
    "    # check if a model already exists and get it's IoU score\n",
    "    for fname in os.listdir(iou_model_path):\n",
    "        if fname.endswith('.h5'):\n",
    "            current_best_iou = float(fname.split('_')[-2])\n",
    "    print(f\"Calculated mean IoU: {mean_iou:.4f}\")\n",
    "    print(f\"IoU from saved model: {current_best_iou}\")\n",
    "    if mean_iou > current_best_iou:\n",
    "        os.remove(f\"{iou_model_path}/{fname}\")\n",
    "        model.save(f\"{iou_model_path}/{model_name}_model_iou_{mean_iou:.4f}_.h5\", overwrite=True)\n",
    "        print(f\"Model with updated IoU has been saved.\")\n",
    "    else:\n",
    "        print(\"No Model update.\")\n",
    "    reset_gpu_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91492388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 483 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n",
      "\n",
      "Classes: {'non-olivine': 0, 'olivine': 1}\n",
      "Class Weights: {0: 1.0, 1: 3.025}\n",
      "Class Distribution: {0: 363, 1: 120}\n",
      "\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 7s 419ms/step - loss: 2.6488 - accuracy: 0.5880 - val_loss: 0.6380 - val_accuracy: 0.8058\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 1.1491 - accuracy: 0.7598 - val_loss: 2.3312 - val_accuracy: 0.3689\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.8988 - accuracy: 0.7723 - val_loss: 0.8782 - val_accuracy: 0.6796\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.4917 - accuracy: 0.8634 - val_loss: 0.5636 - val_accuracy: 0.8252s: 0.2941 \n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 4s 230ms/step - loss: 0.4615 - accuracy: 0.8861 - val_loss: 0.5112 - val_accuracy: 0.8252\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.1709 - accuracy: 0.9545 - val_loss: 0.4928 - val_accuracy: 0.8252\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 4s 230ms/step - loss: 0.0880 - accuracy: 0.9959 - val_loss: 0.4723 - val_accuracy: 0.8350\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 4s 226ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.8350\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.8252\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 4s 230ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.8350\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 4s 231ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.4784 - val_accuracy: 0.8447\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.8252\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 4s 256ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.8252\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.8252\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.8252\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.8252\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.8350\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.8252\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.8350\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.5214 - val_accuracy: 0.8252\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.8252\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.8252\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.8350\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.8350\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5379 - val_accuracy: 0.8252\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.8252\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.8252\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 4s 246ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5530 - val_accuracy: 0.8252\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.8350\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 4s 222ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5840 - val_accuracy: 0.8350\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 3s 216ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5328 - val_accuracy: 0.8252\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 3s 208ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5343 - val_accuracy: 0.8350\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5611 - val_accuracy: 0.8350\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.5539 - val_accuracy: 0.8350\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.5575 - val_accuracy: 0.8350\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5620 - val_accuracy: 0.8350\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.5590 - val_accuracy: 0.8350\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 4s 252ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.8350\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5615 - val_accuracy: 0.8350\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5729 - val_accuracy: 0.8350\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 4s 268ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5818 - val_accuracy: 0.8350\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 5s 298ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5742 - val_accuracy: 0.8350\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 4s 256ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5722 - val_accuracy: 0.8350\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 4s 255ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5779 - val_accuracy: 0.8350\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.8350\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5907 - val_accuracy: 0.8350\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5637 - val_accuracy: 0.8155\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6091 - val_accuracy: 0.8350\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5842 - val_accuracy: 0.8350\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5990 - val_accuracy: 0.8350\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5983 - val_accuracy: 0.8350\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 4s 223ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5993 - val_accuracy: 0.8350\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 4s 265ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5993 - val_accuracy: 0.8350\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 4s 229ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6173 - val_accuracy: 0.8350\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 4s 249ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5936 - val_accuracy: 0.8350\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6149 - val_accuracy: 0.8350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/60\n",
      "16/16 [==============================] - 4s 226ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6001 - val_accuracy: 0.8350\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 4s 265ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6120 - val_accuracy: 0.8350\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6078 - val_accuracy: 0.8350\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6149 - val_accuracy: 0.8350\n"
     ]
    }
   ],
   "source": [
    "vgg_model, vgg_history = run_test_harness(model_name='vgg', batch_size=32, epochs=60, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aabea5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.save(\"./saved_models/my_awesome_test_vgg.h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d515778",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8636c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue')\n",
    "    plt.plot(history.history['val_loss'], color='orange')\n",
    "    plt.legend(['train', 'val'])\n",
    "    \n",
    "    # plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='blue')\n",
    "    plt.plot(history.history['val_accuracy'], color='orange')\n",
    "    plt.legend(['train', 'val']) \n",
    "    \n",
    "    plt.subplots_adjust(top=1.6, right=1.2)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57a9b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(model, test_generator, batch_divisor=1):    \n",
    "    test_steps_per_epoch = np.math.ceil(test_generator.samples / test_generator.batch_size)\n",
    "\n",
    "    predictions = model.predict(test_generator, steps=test_steps_per_epoch)\n",
    "    predicted_classes = [1 * (x[0]>=0.5) for x in predictions]\n",
    "    \n",
    "    true_classes = test_generator.classes\n",
    "    class_labels = list(test_generator.class_indices.keys()) \n",
    "    \n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    \n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    \n",
    "    report = sklearn.metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "    print(report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5273457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, history, verbose=1):\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    test_generator = test_datagen.flow_from_directory('thin_section_dataset/test/',\n",
    "                                               class_mode='binary',\n",
    "                                               color_mode='rgb',\n",
    "                                               target_size=(224, 224),\n",
    "                                               batch_size=1,\n",
    "                                               shuffle=False,)\n",
    "    # calculate test set accuracy\n",
    "    _, acc = model.evaluate(test_generator, steps=len(test_generator), verbose=1)\n",
    "    print('\\nAccuracy on test set: %.3f' % (acc * 100.0))\n",
    "    \n",
    "    if verbose:\n",
    "        # plot learning curves\n",
    "        summarize_diagnostics(history)\n",
    "\n",
    "        # plot confusion matrix\n",
    "        show_confusion_matrix(model, test_generator)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24a279b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 104 images belonging to 2 classes.\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 0.5750 - accuracy: 0.6346\n",
      "\n",
      "Accuracy on test set: 63.462\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-olivine       0.77      0.96      0.86        78\n",
      "     olivine       0.57      0.15      0.24        26\n",
      "\n",
      "    accuracy                           0.76       104\n",
      "   macro avg       0.67      0.56      0.55       104\n",
      "weighted avg       0.72      0.76      0.70       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_model(model, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad0028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
